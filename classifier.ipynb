{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where all things come together, where the actual classification task is carried out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define a logger\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EarlyStopping(object):\n",
    "    def __init__(self, patience=100):\n",
    "        self.patience = patience\n",
    "        self.best_valid = np.inf\n",
    "        self.best_valid_epoch = 0\n",
    "        self.best_weights = None\n",
    "\n",
    "    def __call__(self, nn, train_history):\n",
    "        current_valid = train_history[-1]['valid_loss']\n",
    "        current_epoch = train_history[-1]['epoch']\n",
    "        if current_valid < self.best_valid:\n",
    "            self.best_valid = current_valid\n",
    "            self.best_valid_epoch = current_epoch\n",
    "            self.best_weights = nn.get_all_params_values()\n",
    "        elif self.best_valid_epoch + self.patience < current_epoch:\n",
    "            print(\"Early stopping.\")\n",
    "            print(\"Best valid loss was {:.6f} at epoch {}.\".format(\n",
    "                self.best_valid, self.best_valid_epoch))\n",
    "            nn.load_params_from(self.best_weights)\n",
    "            raise StopIteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read model from disk\n",
    "from gensim.models import Doc2Vec\n",
    "import os\n",
    "\n",
    "def loadModel(dim=600):\n",
    "    if(dim not in (100, 300, 600)):\n",
    "        raise ValueError('dim must be 100, 300 or 600')\n",
    "        \n",
    "    modelName = 'allDocs' + str(dim) + 'D.model'\n",
    "    modelBasePath = 'cache'\n",
    "    modelPath = os.path.join(os.getcwd(), modelBasePath, modelName)\n",
    "\n",
    "    logging.info('start loading the model')\n",
    "    model = Doc2Vec.load(modelPath)\n",
    "    logging.info('loading completed')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compile the corpus\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def loadData(model=None, regression=False):\n",
    "    JSONFILESDIR = 'data/json'\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    if regression:\n",
    "        zero = np.array([0,1], dtype=np.int32)\n",
    "        one = np.array([1,0], dtype=np.int32)\n",
    "    else:\n",
    "        zero = np.int32(0)\n",
    "        one = np.int32(1)\n",
    "\n",
    "    logging.info('building corpus...')\n",
    "    filenames = model.docvecs.doctags.keys()\n",
    "    for k in tqdm(filenames):\n",
    "        with open(os.path.join(JSONFILESDIR, k + '.json')) as fh:\n",
    "            jsonFile = json.load(fh)\n",
    "\n",
    "        if jsonFile['lang'] != 'en' or jsonFile['citedBy'] is None:\n",
    "            logging.debug('{f} discarded from corpus.'.format(f=k))\n",
    "            continue\n",
    "\n",
    "        X.append(model.docvecs[k])\n",
    "        isSuccessfull = one if int(jsonFile['citedBy']) > 0 else zero\n",
    "        y.append(isSuccessfull)\n",
    "        logging.debug('{f} absorbed into corpus.'.format(f=k))\n",
    "\n",
    "    # transform to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    logging.info('corpus complete')\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# classifying neural net\n",
    "from lasagne import layers\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from lasagne.nonlinearities import rectify, tanh, softmax, sigmoid\n",
    "\n",
    "def makeLayers(depth=3):\n",
    "    yield ('input', layers.InputLayer)\n",
    "    yield ('hidden0', layers.DenseLayer)\n",
    "    for i in range(1, depth - 2):\n",
    "        yield ('dropout' + str(i-1), layers.DropoutLayer)\n",
    "        yield ('hidden' + str(i), layers.DenseLayer)\n",
    "    yield ('output', layers.DenseLayer)\n",
    "    \n",
    "def makeParameters(arch, dropout_p, nonlinearity):\n",
    "    if len(arch) < 3:\n",
    "        raise ValueError(\"The network must be at least 3 layers deep\")\n",
    "    depth = len(arch)\n",
    "    params = {}\n",
    "    \n",
    "    # the static ones\n",
    "    exec('params[\"{}\"] = ({}, {})'.format('input_shape', \"None\", arch[0]))\n",
    "    exec('params[\"{}\"] = {}'.format('hidden0_num_units', arch[1]))\n",
    "    for i in range(1, depth - 2):\n",
    "        exec('params[\"{}\"] = {}'.format('dropout' + str(i-1) + '_p', dropout_p))\n",
    "        exec('params[\"{}\"] = {}'.format('hidden' + str(i) + '_num_units', arch[i+1]))\n",
    "    \n",
    "    # again some statics ones\n",
    "    exec('params[\"{}\"] = {}'.format('output_num_units', arch[-1]))\n",
    "    exec('params[\"{}\"] = {}'.format('output_nonlinearity', nonlinearity))\n",
    "    return params\n",
    "\n",
    "def loadNN(arch=(100, 400, 160, 2), dropout_p=0.6, epochs=50,\\\n",
    "           nonlinearity=None, regression=False, evalSize=.1):\n",
    "    if not regression and nonlinearity != 'softmax':\n",
    "        nonlinearity = 'softmax'\n",
    "        logging.info(\"nonlinearity was set to 'softmax'. This is\\\n",
    "            the only non-linearity supported by classification\")\n",
    "        \n",
    "    return NeuralNet(\n",
    "        # configuration\n",
    "        layers=[x for x in makeLayers(len(arch))],\n",
    "        **makeParameters(arch, dropout_p, nonlinearity),\n",
    "        \n",
    "        # optimization method:\n",
    "        update=nesterov_momentum,\n",
    "        update_learning_rate=0.01,\n",
    "        update_momentum=0.9,\n",
    "\n",
    "        regression=regression,\n",
    "        max_epochs=epochs,\n",
    "        eval_size=evalSize,\n",
    "        verbose=1,\n",
    "        on_epoch_finished=[EarlyStopping(patience=10)]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NN creating factory\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    model\n",
    "except NameError:\n",
    "    model = {}\n",
    "\n",
    "try:\n",
    "    X\n",
    "    y\n",
    "except NameError:\n",
    "    X, y = {}, {}\n",
    "\n",
    "# returns a trained network and the corresponding training\n",
    "# and test data\n",
    "def genNN(inputDim=600, regression=False, arch=(400, 160, 2), \\\n",
    "            dropout_p=.6, epochs=100, nonlinearity='softmax', \\\n",
    "            evalSize=.1):\n",
    "\n",
    "    TrainTestData = namedtuple(\"TrainTest\", [\"X_train\",\"X_test\",\"y_train\",\"y_test\"])\n",
    "    \n",
    "    # get the persisted model, including the training \n",
    "    # data associated with it. check if already loaded\n",
    "    global model\n",
    "    global X, y\n",
    "    # if currently loaded data doesn't match the required data\n",
    "    if type(X) == np.ndarray and X.shape[1] != inputDim:\n",
    "        model, X, y = {}, {}, {}\n",
    "    if model == {}:\n",
    "        model = loadModel(inputDim)\n",
    "    \n",
    "    # give the data in a convenient format\n",
    "    if any([type(X) != np.ndarray, type(y) != np.ndarray]):\n",
    "        X, y = loadData(model=model, regression=regression)\n",
    "\n",
    "    # add input layer to NN's arch\n",
    "    myArch = list(arch)\n",
    "    myArch.insert(0, inputDim)\n",
    "    \n",
    "    # instanciate the network\n",
    "    net = loadNN(arch=myArch, dropout_p=dropout_p, epochs=epochs, \\\n",
    "                 nonlinearity=nonlinearity, regression=regression,\n",
    "                 evalSize=evalSize)\n",
    "    # carry out train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split( \\\n",
    "        X, y, test_size=evalSize, random_state=42)\n",
    "    \n",
    "    # train the network\n",
    "    net.fit(X_train, y_train)\n",
    "    \n",
    "    return net, TrainTestData(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "EvalResults = namedtuple('EvalResults', ['All','Pos','Neg', 'SuccRate', \n",
    "                         'TrainLoss', 'ValidLoss'])\n",
    "\n",
    "def evalPrediction(net, trainTestData, regression=False):\n",
    "    # predict the test set\n",
    "    predictions = net.predict(trainTestData.X_test)\n",
    "    predictions = predictions.round().astype(np.int32)\n",
    "    \n",
    "    # dealing with the different data representations \n",
    "    # of regression vs classification\n",
    "    if regression:\n",
    "        truthMatrix = trainTestData.y_test[:, 0] == predictions[:, 0]\n",
    "        positiveTestCases = trainTestData.y_test[:, 0].sum()\n",
    "    else:\n",
    "        truthMatrix = trainTestData.y_test == predictions\n",
    "        positiveTestCases = trainTestData.y_test.sum()\n",
    "\n",
    "    testSize = truthMatrix.shape[0]\n",
    "    correct = truthMatrix.sum()\n",
    "    false = testSize - truthMatrix.sum()\n",
    "    train_loss = np.array([i[\"train_loss\"] for i in net.train_history_])\n",
    "    valid_loss = np.array([i[\"valid_loss\"] for i in net.train_history_])\n",
    "    \n",
    "    return EvalResults(testSize, correct, false, correct/float(testSize),\\\n",
    "                       train_loss, valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 10302 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name       size\n",
      "---  -------  ------\n",
      "  0  input       100\n",
      "  1  hidden0     100\n",
      "  2  output        2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m0.65171\u001b[0m       \u001b[32m0.63998\u001b[0m      1.01834      0.63967  0.18s\n",
      "      2       \u001b[36m0.62694\u001b[0m       \u001b[32m0.63346\u001b[0m      0.98971      0.64444  0.20s\n",
      "      3       \u001b[36m0.62147\u001b[0m       \u001b[32m0.63113\u001b[0m      0.98469      0.64577  0.19s\n",
      "      4       \u001b[36m0.61808\u001b[0m       \u001b[32m0.62973\u001b[0m      0.98149      0.64691  0.18s\n",
      "      5       \u001b[36m0.61515\u001b[0m       \u001b[32m0.62847\u001b[0m      0.97881      0.64996  0.18s\n",
      "      6       \u001b[36m0.61243\u001b[0m       \u001b[32m0.62733\u001b[0m      0.97624      0.64996  0.18s\n",
      "      7       \u001b[36m0.60979\u001b[0m       \u001b[32m0.62645\u001b[0m      0.97341      0.64996  0.18s\n",
      "      8       \u001b[36m0.60721\u001b[0m       \u001b[32m0.62581\u001b[0m      0.97028      0.65168  0.19s\n",
      "      9       \u001b[36m0.60465\u001b[0m       \u001b[32m0.62522\u001b[0m      0.96710      0.65015  0.19s\n",
      "     10       \u001b[36m0.60206\u001b[0m       \u001b[32m0.62489\u001b[0m      0.96347      0.65149  0.18s\n",
      "     11       \u001b[36m0.59950\u001b[0m       \u001b[32m0.62463\u001b[0m      0.95977      0.65301  0.19s\n",
      "     12       \u001b[36m0.59700\u001b[0m       \u001b[32m0.62458\u001b[0m      0.95586      0.64863  0.18s\n",
      "     13       \u001b[36m0.59453\u001b[0m       \u001b[32m0.62447\u001b[0m      0.95205      0.64920  0.19s\n",
      "     14       \u001b[36m0.59207\u001b[0m       0.62469      0.94777      0.64920  0.18s\n",
      "     15       \u001b[36m0.58966\u001b[0m       0.62497      0.94350      0.64996  0.18s\n",
      "     16       \u001b[36m0.58731\u001b[0m       0.62537      0.93915      0.64825  0.18s\n",
      "     17       \u001b[36m0.58502\u001b[0m       0.62592      0.93466      0.64577  0.19s\n",
      "     18       \u001b[36m0.58278\u001b[0m       0.62658      0.93009      0.64615  0.18s\n",
      "     19       \u001b[36m0.58057\u001b[0m       0.62737      0.92540      0.64444  0.19s\n",
      "     20       \u001b[36m0.57843\u001b[0m       0.62808      0.92095      0.64748  0.18s\n",
      "     21       \u001b[36m0.57637\u001b[0m       0.62889      0.91649      0.64653  0.18s\n",
      "     22       \u001b[36m0.57432\u001b[0m       0.62953      0.91231      0.64596  0.19s\n",
      "     23       \u001b[36m0.57233\u001b[0m       0.63028      0.90806      0.64710  0.18s\n",
      "Early stopping.\n",
      "Best valid loss was 0.624475 at epoch 13.\n",
      "Loaded parameters to layer 'hidden0' (shape 100x100).\n",
      "Loaded parameters to layer 'hidden0' (shape 100).\n",
      "Loaded parameters to layer 'output' (shape 100x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 30902 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name       size\n",
      "---  -------  ------\n",
      "  0  input       100\n",
      "  1  hidden0     300\n",
      "  2  output        2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m0.64667\u001b[0m       \u001b[32m0.63601\u001b[0m      1.01676      0.63491  0.43s\n",
      "      2       \u001b[36m0.62413\u001b[0m       \u001b[32m0.63028\u001b[0m      0.99025      0.64367  0.46s\n",
      "      3       \u001b[36m0.61897\u001b[0m       \u001b[32m0.62816\u001b[0m      0.98538      0.64177  0.44s\n",
      "      4       \u001b[36m0.61514\u001b[0m       \u001b[32m0.62655\u001b[0m      0.98179      0.64329  0.45s\n",
      "      5       \u001b[36m0.61154\u001b[0m       \u001b[32m0.62510\u001b[0m      0.97830      0.64425  0.45s\n",
      "      6       \u001b[36m0.60801\u001b[0m       \u001b[32m0.62384\u001b[0m      0.97464      0.64463  0.46s\n",
      "      7       \u001b[36m0.60451\u001b[0m       \u001b[32m0.62279\u001b[0m      0.97065      0.64482  0.46s\n",
      "      8       \u001b[36m0.60105\u001b[0m       \u001b[32m0.62208\u001b[0m      0.96620      0.65244  0.46s\n",
      "      9       \u001b[36m0.59759\u001b[0m       \u001b[32m0.62165\u001b[0m      0.96130      0.65434  0.45s\n",
      "     10       \u001b[36m0.59415\u001b[0m       \u001b[32m0.62146\u001b[0m      0.95605      0.65625  0.45s\n",
      "     11       \u001b[36m0.59072\u001b[0m       \u001b[32m0.62140\u001b[0m      0.95063      0.65796  0.45s\n",
      "     12       \u001b[36m0.58730\u001b[0m       0.62156      0.94488      0.65549  0.45s\n",
      "     13       \u001b[36m0.58388\u001b[0m       0.62191      0.93884      0.65587  0.46s\n",
      "     14       \u001b[36m0.58046\u001b[0m       0.62242      0.93259      0.65758  0.43s\n",
      "     15       \u001b[36m0.57705\u001b[0m       0.62307      0.92613      0.65758  0.46s\n",
      "     16       \u001b[36m0.57363\u001b[0m       0.62392      0.91939      0.65415  0.44s\n",
      "     17       \u001b[36m0.57026\u001b[0m       0.62466      0.91291      0.65282  0.45s\n",
      "     18       \u001b[36m0.56686\u001b[0m       0.62564      0.90604      0.65168  0.44s\n",
      "     19       \u001b[36m0.56349\u001b[0m       0.62675      0.89906      0.65111  0.43s\n",
      "     20       \u001b[36m0.56011\u001b[0m       0.62789      0.89205      0.65168  0.45s\n",
      "     21       \u001b[36m0.55674\u001b[0m       0.62911      0.88496      0.65301  0.43s\n",
      "Early stopping.\n",
      "Best valid loss was 0.621398 at epoch 11.\n",
      "Loaded parameters to layer 'hidden0' (shape 100x300).\n",
      "Loaded parameters to layer 'hidden0' (shape 300).\n",
      "Loaded parameters to layer 'output' (shape 300x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 45492 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input        100\n",
      "  1  hidden0      250\n",
      "  2  dropout0     250\n",
      "  3  hidden1       80\n",
      "  4  output         2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m0.66362\u001b[0m       \u001b[32m0.63902\u001b[0m      1.03850      0.63129  0.96s\n",
      "      2       \u001b[36m0.63732\u001b[0m       \u001b[32m0.63088\u001b[0m      1.01021      0.64082  0.97s\n",
      "      3       \u001b[36m0.62910\u001b[0m       \u001b[32m0.62755\u001b[0m      1.00246      0.64596  0.98s\n",
      "      4       \u001b[36m0.62507\u001b[0m       \u001b[32m0.62570\u001b[0m      0.99900      0.64844  0.96s\n",
      "      5       \u001b[36m0.62177\u001b[0m       \u001b[32m0.62501\u001b[0m      0.99481      0.64958  0.98s\n",
      "      6       \u001b[36m0.61886\u001b[0m       \u001b[32m0.62455\u001b[0m      0.99089      0.65339  0.96s\n",
      "      7       \u001b[36m0.61660\u001b[0m       \u001b[32m0.62357\u001b[0m      0.98882      0.65187  0.97s\n",
      "      8       \u001b[36m0.61401\u001b[0m       \u001b[32m0.62322\u001b[0m      0.98521      0.65263  0.96s\n",
      "      9       \u001b[36m0.61281\u001b[0m       \u001b[32m0.62203\u001b[0m      0.98518      0.65434  0.97s\n",
      "     10       \u001b[36m0.60972\u001b[0m       \u001b[32m0.62142\u001b[0m      0.98118      0.65663  0.96s\n",
      "     11       \u001b[36m0.60922\u001b[0m       \u001b[32m0.62049\u001b[0m      0.98184      0.65739  0.96s\n",
      "     12       \u001b[36m0.60625\u001b[0m       0.62077      0.97660      0.65777  0.97s\n",
      "     13       \u001b[36m0.60372\u001b[0m       \u001b[32m0.62010\u001b[0m      0.97359      0.65873  0.97s\n",
      "     14       \u001b[36m0.60080\u001b[0m       \u001b[32m0.61985\u001b[0m      0.96926      0.66120  0.97s\n",
      "     15       0.60094       \u001b[32m0.61949\u001b[0m      0.97006      0.65873  0.97s\n",
      "     16       \u001b[36m0.59839\u001b[0m       0.61999      0.96517      0.66139  0.97s\n",
      "     17       \u001b[36m0.59614\u001b[0m       0.62001      0.96151      0.65720  0.97s\n",
      "     18       \u001b[36m0.59482\u001b[0m       0.61999      0.95940      0.66044  0.96s\n",
      "     19       \u001b[36m0.59190\u001b[0m       0.62041      0.95405      0.65873  0.94s\n",
      "     20       \u001b[36m0.59089\u001b[0m       0.62048      0.95231      0.65720  0.97s\n",
      "     21       \u001b[36m0.58935\u001b[0m       0.62066      0.94956      0.65625  0.99s\n",
      "     22       \u001b[36m0.58794\u001b[0m       0.62119      0.94648      0.65892  0.96s\n",
      "     23       \u001b[36m0.58453\u001b[0m       0.62120      0.94097      0.65968  0.96s\n",
      "     24       \u001b[36m0.58325\u001b[0m       0.62104      0.93914      0.66006  0.96s\n",
      "     25       \u001b[36m0.58184\u001b[0m       0.62167      0.93594      0.66082  0.96s\n",
      "Early stopping.\n",
      "Best valid loss was 0.619487 at epoch 15.\n",
      "Loaded parameters to layer 'hidden0' (shape 100x250).\n",
      "Loaded parameters to layer 'hidden0' (shape 250).\n",
      "Loaded parameters to layer 'hidden1' (shape 250x80).\n",
      "Loaded parameters to layer 'hidden1' (shape 80).\n",
      "Loaded parameters to layer 'output' (shape 80x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 130982 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input        100\n",
      "  1  hidden0      500\n",
      "  2  dropout0     500\n",
      "  3  hidden1      160\n",
      "  4  output         2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m0.64992\u001b[0m       \u001b[32m0.63275\u001b[0m      1.02714      0.63605  2.29s\n",
      "      2       \u001b[36m0.62897\u001b[0m       \u001b[32m0.62615\u001b[0m      1.00451      0.64463  2.34s\n",
      "      3       \u001b[36m0.62339\u001b[0m       \u001b[32m0.62397\u001b[0m      0.99906      0.64710  2.37s\n",
      "      4       \u001b[36m0.62014\u001b[0m       \u001b[32m0.62221\u001b[0m      0.99667      0.65149  2.34s\n",
      "      5       \u001b[36m0.61652\u001b[0m       \u001b[32m0.62041\u001b[0m      0.99374      0.65358  2.37s\n",
      "      6       \u001b[36m0.61342\u001b[0m       \u001b[32m0.61914\u001b[0m      0.99077      0.65739  2.33s\n",
      "      7       \u001b[36m0.60996\u001b[0m       \u001b[32m0.61831\u001b[0m      0.98650      0.65949  2.36s\n",
      "      8       \u001b[36m0.60746\u001b[0m       0.61831      0.98244      0.66101  2.32s\n",
      "      9       \u001b[36m0.60419\u001b[0m       \u001b[32m0.61721\u001b[0m      0.97890      0.66349  2.32s\n",
      "     10       \u001b[36m0.60235\u001b[0m       0.61752      0.97544      0.66406  2.33s\n",
      "     11       \u001b[36m0.59874\u001b[0m       \u001b[32m0.61650\u001b[0m      0.97119      0.66540  2.38s\n",
      "     12       \u001b[36m0.59518\u001b[0m       \u001b[32m0.61607\u001b[0m      0.96609      0.66330  2.31s\n",
      "     13       \u001b[36m0.59339\u001b[0m       0.61642      0.96265      0.66711  2.37s\n",
      "     14       \u001b[36m0.59043\u001b[0m       \u001b[32m0.61601\u001b[0m      0.95847      0.66692  2.34s\n",
      "     15       \u001b[36m0.58745\u001b[0m       0.61640      0.95303      0.66368  2.29s\n",
      "     16       \u001b[36m0.58480\u001b[0m       0.61763      0.94684      0.66711  2.37s\n",
      "     17       \u001b[36m0.58222\u001b[0m       0.61754      0.94279      0.66654  2.36s\n",
      "     18       \u001b[36m0.58049\u001b[0m       0.61745      0.94013      0.66101  2.34s\n",
      "     19       \u001b[36m0.57535\u001b[0m       0.61713      0.93229      0.67016  2.33s\n",
      "     20       \u001b[36m0.57394\u001b[0m       0.61810      0.92857      0.65796  2.32s\n",
      "     21       \u001b[36m0.57110\u001b[0m       0.61806      0.92401      0.66864  2.33s\n",
      "     22       \u001b[36m0.56848\u001b[0m       0.61972      0.91732      0.66768  2.32s\n",
      "     23       \u001b[36m0.56443\u001b[0m       0.61965      0.91089      0.67054  2.31s\n",
      "     24       \u001b[36m0.56234\u001b[0m       0.61900      0.90847      0.66883  2.28s\n",
      "Early stopping.\n",
      "Best valid loss was 0.616014 at epoch 14.\n",
      "Loaded parameters to layer 'hidden0' (shape 100x500).\n",
      "Loaded parameters to layer 'hidden0' (shape 500).\n",
      "Loaded parameters to layer 'hidden1' (shape 500x160).\n",
      "Loaded parameters to layer 'hidden1' (shape 160).\n",
      "Loaded parameters to layer 'output' (shape 160x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 106672 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input        100\n",
      "  1  hidden0      400\n",
      "  2  dropout0     400\n",
      "  3  hidden1      150\n",
      "  4  dropout1     150\n",
      "  5  hidden2       40\n",
      "  6  output         2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m0.66777\u001b[0m       \u001b[32m0.63864\u001b[0m      1.04562      0.62843  2.14s\n",
      "      2       \u001b[36m0.63965\u001b[0m       \u001b[32m0.63039\u001b[0m      1.01469      0.64272  2.10s\n",
      "      3       \u001b[36m0.63211\u001b[0m       \u001b[32m0.62687\u001b[0m      1.00835      0.64062  2.16s\n",
      "      4       \u001b[36m0.62824\u001b[0m       \u001b[32m0.62553\u001b[0m      1.00432      0.64062  2.14s\n",
      "      5       \u001b[36m0.62379\u001b[0m       \u001b[32m0.62416\u001b[0m      0.99941      0.64634  2.14s\n",
      "      6       \u001b[36m0.62158\u001b[0m       \u001b[32m0.62292\u001b[0m      0.99784      0.64882  2.12s\n",
      "      7       \u001b[36m0.61820\u001b[0m       \u001b[32m0.62242\u001b[0m      0.99323      0.64672  2.14s\n",
      "      8       \u001b[36m0.61650\u001b[0m       \u001b[32m0.62179\u001b[0m      0.99149      0.64882  2.13s\n",
      "      9       \u001b[36m0.61525\u001b[0m       \u001b[32m0.62091\u001b[0m      0.99088      0.65206  2.14s\n",
      "     10       \u001b[36m0.61345\u001b[0m       \u001b[32m0.62069\u001b[0m      0.98833      0.65015  2.12s\n",
      "     11       \u001b[36m0.61071\u001b[0m       \u001b[32m0.62013\u001b[0m      0.98480      0.65225  2.13s\n",
      "     12       \u001b[36m0.60915\u001b[0m       \u001b[32m0.61877\u001b[0m      0.98445      0.65625  2.16s\n",
      "     13       \u001b[36m0.60762\u001b[0m       0.61878      0.98196      0.65587  2.16s\n",
      "     14       \u001b[36m0.60674\u001b[0m       \u001b[32m0.61827\u001b[0m      0.98136      0.65873  2.12s\n",
      "     15       \u001b[36m0.60324\u001b[0m       \u001b[32m0.61810\u001b[0m      0.97596      0.65949  2.13s\n",
      "     16       \u001b[36m0.60089\u001b[0m       \u001b[32m0.61763\u001b[0m      0.97290      0.65968  2.11s\n",
      "     17       \u001b[36m0.59900\u001b[0m       0.61795      0.96933      0.65911  2.16s\n",
      "     18       \u001b[36m0.59726\u001b[0m       0.61882      0.96516      0.65911  2.12s\n",
      "     19       \u001b[36m0.59519\u001b[0m       0.61856      0.96222      0.65854  2.11s\n",
      "     20       \u001b[36m0.59346\u001b[0m       0.61818      0.96001      0.66139  2.12s\n",
      "     21       \u001b[36m0.59090\u001b[0m       0.61929      0.95416      0.65911  2.10s\n",
      "     22       \u001b[36m0.58948\u001b[0m       0.61970      0.95123      0.66216  2.10s\n",
      "     23       \u001b[36m0.58699\u001b[0m       0.61897      0.94833      0.66368  2.14s\n",
      "     24       \u001b[36m0.58461\u001b[0m       0.61923      0.94409      0.66349  2.11s\n",
      "     25       \u001b[36m0.58275\u001b[0m       0.61999      0.93993      0.66235  2.10s\n",
      "     26       \u001b[36m0.57926\u001b[0m       0.62120      0.93248      0.65816  2.14s\n",
      "Early stopping.\n",
      "Best valid loss was 0.617626 at epoch 16.\n",
      "Loaded parameters to layer 'hidden0' (shape 100x400).\n",
      "Loaded parameters to layer 'hidden0' (shape 400).\n",
      "Loaded parameters to layer 'hidden1' (shape 400x150).\n",
      "Loaded parameters to layer 'hidden1' (shape 150).\n",
      "Loaded parameters to layer 'hidden2' (shape 150x40).\n",
      "Loaded parameters to layer 'hidden2' (shape 40).\n",
      "Loaded parameters to layer 'output' (shape 40x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 10302 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name       size\n",
      "---  -------  ------\n",
      "  0  input       100\n",
      "  1  hidden0     100\n",
      "  2  output        2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m0.64879\u001b[0m       \u001b[32m0.63667\u001b[0m      1.01903      0.63167  0.18s\n",
      "      2       \u001b[36m0.62564\u001b[0m       \u001b[32m0.63059\u001b[0m      0.99215      0.64082  0.18s\n",
      "      3       \u001b[36m0.62033\u001b[0m       \u001b[32m0.62909\u001b[0m      0.98608      0.64139  0.19s\n",
      "      4       \u001b[36m0.61711\u001b[0m       \u001b[32m0.62819\u001b[0m      0.98237      0.64501  0.18s\n",
      "      5       \u001b[36m0.61429\u001b[0m       \u001b[32m0.62764\u001b[0m      0.97873      0.64482  0.19s\n",
      "      6       \u001b[36m0.61160\u001b[0m       \u001b[32m0.62726\u001b[0m      0.97504      0.64672  0.19s\n",
      "      7       \u001b[36m0.60901\u001b[0m       \u001b[32m0.62710\u001b[0m      0.97114      0.64882  0.18s\n",
      "      8       \u001b[36m0.60649\u001b[0m       \u001b[32m0.62709\u001b[0m      0.96716      0.64787  0.18s\n",
      "      9       \u001b[36m0.60398\u001b[0m       0.62723      0.96294      0.64672  0.19s\n",
      "     10       \u001b[36m0.60147\u001b[0m       0.62747      0.95857      0.64748  0.18s\n",
      "     11       \u001b[36m0.59899\u001b[0m       0.62767      0.95430      0.64672  0.19s\n",
      "     12       \u001b[36m0.59650\u001b[0m       0.62794      0.94993      0.64748  0.18s\n",
      "     13       \u001b[36m0.59402\u001b[0m       0.62818      0.94562      0.65015  0.19s\n",
      "     14       \u001b[36m0.59154\u001b[0m       0.62866      0.94094      0.65130  0.19s\n",
      "     15       \u001b[36m0.58904\u001b[0m       0.62922      0.93614      0.64558  0.19s\n",
      "     16       \u001b[36m0.58662\u001b[0m       0.62980      0.93143      0.64520  0.18s\n",
      "     17       \u001b[36m0.58426\u001b[0m       0.63048      0.92669      0.64787  0.19s\n",
      "     18       \u001b[36m0.58193\u001b[0m       0.63127      0.92184      0.64806  0.18s\n",
      "Early stopping.\n",
      "Best valid loss was 0.627087 at epoch 8.\n",
      "Loaded parameters to layer 'hidden0' (shape 100x100).\n",
      "Loaded parameters to layer 'hidden0' (shape 100).\n",
      "Loaded parameters to layer 'output' (shape 100x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 30902 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name       size\n",
      "---  -------  ------\n",
      "  0  input       100\n",
      "  1  hidden0     300\n",
      "  2  output        2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m0.64486\u001b[0m       \u001b[32m0.63671\u001b[0m      1.01279      0.63091  0.49s\n",
      "      2       \u001b[36m0.62326\u001b[0m       \u001b[32m0.63105\u001b[0m      0.98766      0.63948  0.43s\n",
      "      3       \u001b[36m0.61808\u001b[0m       \u001b[32m0.62871\u001b[0m      0.98308      0.64253  0.44s\n",
      "      4       \u001b[36m0.61417\u001b[0m       \u001b[32m0.62698\u001b[0m      0.97957      0.64177  0.44s\n",
      "      5       \u001b[36m0.61051\u001b[0m       \u001b[32m0.62548\u001b[0m      0.97607      0.64196  0.43s\n",
      "      6       \u001b[36m0.60689\u001b[0m       \u001b[32m0.62429\u001b[0m      0.97214      0.64425  0.45s\n",
      "      7       \u001b[36m0.60329\u001b[0m       \u001b[32m0.62330\u001b[0m      0.96790      0.64405  0.43s\n",
      "      8       \u001b[36m0.59968\u001b[0m       \u001b[32m0.62275\u001b[0m      0.96296      0.64520  0.45s\n",
      "      9       \u001b[36m0.59607\u001b[0m       \u001b[32m0.62224\u001b[0m      0.95795      0.64539  0.44s\n",
      "     10       \u001b[36m0.59247\u001b[0m       \u001b[32m0.62215\u001b[0m      0.95229      0.64367  0.43s\n",
      "     11       \u001b[36m0.58884\u001b[0m       0.62228      0.94627      0.64539  0.45s\n",
      "     12       \u001b[36m0.58525\u001b[0m       0.62269      0.93988      0.65130  0.43s\n",
      "     13       \u001b[36m0.58166\u001b[0m       0.62308      0.93352      0.65015  0.44s\n",
      "     14       \u001b[36m0.57808\u001b[0m       0.62366      0.92693      0.65263  0.47s\n",
      "     15       \u001b[36m0.57453\u001b[0m       0.62417      0.92047      0.64958  0.44s\n",
      "     16       \u001b[36m0.57097\u001b[0m       0.62481      0.91383      0.65720  0.44s\n",
      "     17       \u001b[36m0.56744\u001b[0m       0.62556      0.90710      0.65682  0.45s\n",
      "     18       \u001b[36m0.56396\u001b[0m       0.62646      0.90023      0.65682  0.44s\n",
      "     19       \u001b[36m0.56053\u001b[0m       0.62762      0.89310      0.65473  0.44s\n",
      "     20       \u001b[36m0.55713\u001b[0m       0.62881      0.88601      0.65396  0.45s\n",
      "Early stopping.\n",
      "Best valid loss was 0.622147 at epoch 10.\n",
      "Loaded parameters to layer 'hidden0' (shape 100x300).\n",
      "Loaded parameters to layer 'hidden0' (shape 300).\n",
      "Loaded parameters to layer 'output' (shape 300x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 45492 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input        100\n",
      "  1  hidden0      250\n",
      "  2  dropout0     250\n",
      "  3  hidden1       80\n",
      "  4  output         2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m0.66582\u001b[0m       \u001b[32m0.64252\u001b[0m      1.03626      0.63472  1.03s\n",
      "      2       \u001b[36m0.64212\u001b[0m       \u001b[32m0.63331\u001b[0m      1.01390      0.63967  1.00s\n",
      "      3       \u001b[36m0.63590\u001b[0m       \u001b[32m0.62937\u001b[0m      1.01038      0.64425  0.99s\n",
      "      4       \u001b[36m0.63202\u001b[0m       \u001b[32m0.62717\u001b[0m      1.00774      0.64748  0.98s\n",
      "      5       \u001b[36m0.62879\u001b[0m       \u001b[32m0.62665\u001b[0m      1.00341      0.65206  0.99s\n",
      "      6       \u001b[36m0.62650\u001b[0m       \u001b[32m0.62545\u001b[0m      1.00167      0.64958  0.98s\n",
      "      7       \u001b[36m0.62466\u001b[0m       \u001b[32m0.62467\u001b[0m      0.99998      0.64920  0.98s\n",
      "      8       \u001b[36m0.62292\u001b[0m       \u001b[32m0.62374\u001b[0m      0.99868      0.65091  0.98s\n",
      "      9       \u001b[36m0.62075\u001b[0m       \u001b[32m0.62333\u001b[0m      0.99586      0.65434  1.00s\n",
      "     10       \u001b[36m0.62040\u001b[0m       \u001b[32m0.62231\u001b[0m      0.99693      0.65473  1.00s\n",
      "     11       \u001b[36m0.61738\u001b[0m       \u001b[32m0.62216\u001b[0m      0.99232      0.65434  0.99s\n",
      "     12       \u001b[36m0.61698\u001b[0m       \u001b[32m0.62100\u001b[0m      0.99354      0.65511  1.01s\n",
      "     13       \u001b[36m0.61553\u001b[0m       0.62110      0.99104      0.65739  1.00s\n",
      "     14       \u001b[36m0.61452\u001b[0m       \u001b[32m0.62017\u001b[0m      0.99089      0.65758  0.96s\n",
      "     15       \u001b[36m0.61268\u001b[0m       0.62020      0.98787      0.65663  0.97s\n",
      "     16       \u001b[36m0.61158\u001b[0m       \u001b[32m0.61896\u001b[0m      0.98808      0.65720  0.96s\n",
      "     17       \u001b[36m0.60897\u001b[0m       \u001b[32m0.61833\u001b[0m      0.98485      0.65968  0.96s\n",
      "     18       \u001b[36m0.60888\u001b[0m       0.61835      0.98468      0.65758  0.98s\n",
      "     19       \u001b[36m0.60716\u001b[0m       \u001b[32m0.61805\u001b[0m      0.98238      0.66120  0.96s\n",
      "     20       \u001b[36m0.60583\u001b[0m       \u001b[32m0.61743\u001b[0m      0.98121      0.66006  0.96s\n",
      "     21       \u001b[36m0.60563\u001b[0m       \u001b[32m0.61662\u001b[0m      0.98218      0.66082  0.96s\n",
      "     22       \u001b[36m0.60311\u001b[0m       0.61692      0.97762      0.66197  0.98s\n",
      "     23       \u001b[36m0.60289\u001b[0m       0.61663      0.97772      0.66025  0.96s\n",
      "     24       \u001b[36m0.60157\u001b[0m       0.61671      0.97546      0.66197  0.97s\n",
      "     25       \u001b[36m0.60073\u001b[0m       \u001b[32m0.61578\u001b[0m      0.97557      0.66254  0.96s\n",
      "     26       \u001b[36m0.60019\u001b[0m       0.61665      0.97331      0.66235  0.97s\n",
      "     27       \u001b[36m0.59908\u001b[0m       0.61695      0.97103      0.66425  0.97s\n",
      "     28       \u001b[36m0.59671\u001b[0m       0.61641      0.96803      0.66216  0.96s\n",
      "     29       \u001b[36m0.59581\u001b[0m       0.61610      0.96707      0.66387  0.97s\n",
      "     30       \u001b[36m0.59536\u001b[0m       \u001b[32m0.61575\u001b[0m      0.96689      0.66425  0.97s\n",
      "     31       \u001b[36m0.59367\u001b[0m       0.61640      0.96312      0.66425  0.96s\n",
      "     32       \u001b[36m0.59278\u001b[0m       \u001b[32m0.61523\u001b[0m      0.96350      0.66502  0.97s\n",
      "     33       \u001b[36m0.59211\u001b[0m       0.61566      0.96174      0.66654  0.96s\n",
      "     34       \u001b[36m0.59045\u001b[0m       0.61612      0.95834      0.66502  0.98s\n",
      "     35       \u001b[36m0.58854\u001b[0m       0.61584      0.95567      0.66349  0.96s\n",
      "     36       0.59008       0.61692      0.95649      0.66139  0.95s\n",
      "     37       \u001b[36m0.58760\u001b[0m       0.61643      0.95322      0.66482  0.98s\n",
      "     38       \u001b[36m0.58689\u001b[0m       0.61592      0.95286      0.66254  0.95s\n",
      "     39       \u001b[36m0.58433\u001b[0m       0.61619      0.94830      0.66178  0.96s\n",
      "     40       \u001b[36m0.58409\u001b[0m       0.61652      0.94739      0.65796  0.96s\n",
      "     41       \u001b[36m0.58292\u001b[0m       0.61692      0.94489      0.65892  0.97s\n",
      "     42       \u001b[36m0.58213\u001b[0m       0.61765      0.94249      0.65930  0.95s\n",
      "Early stopping.\n",
      "Best valid loss was 0.615229 at epoch 32.\n",
      "Loaded parameters to layer 'hidden0' (shape 100x250).\n",
      "Loaded parameters to layer 'hidden0' (shape 250).\n",
      "Loaded parameters to layer 'hidden1' (shape 250x80).\n",
      "Loaded parameters to layer 'hidden1' (shape 80).\n",
      "Loaded parameters to layer 'output' (shape 80x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 130982 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input        100\n",
      "  1  hidden0      500\n",
      "  2  dropout0     500\n",
      "  3  hidden1      160\n",
      "  4  output         2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m0.65910\u001b[0m       \u001b[32m0.63568\u001b[0m      1.03685      0.63415  2.40s\n",
      "      2       \u001b[36m0.63580\u001b[0m       \u001b[32m0.62787\u001b[0m      1.01264      0.64005  2.35s\n",
      "      3       \u001b[36m0.63007\u001b[0m       \u001b[32m0.62484\u001b[0m      1.00837      0.64367  2.37s\n",
      "      4       \u001b[36m0.62625\u001b[0m       \u001b[32m0.62231\u001b[0m      1.00632      0.64939  2.37s\n",
      "      5       \u001b[36m0.62275\u001b[0m       \u001b[32m0.62131\u001b[0m      1.00232      0.65168  2.40s\n",
      "      6       \u001b[36m0.62103\u001b[0m       \u001b[32m0.62075\u001b[0m      1.00044      0.65282  2.35s\n",
      "      7       \u001b[36m0.61724\u001b[0m       \u001b[32m0.61983\u001b[0m      0.99582      0.65473  2.43s\n",
      "      8       \u001b[36m0.61659\u001b[0m       \u001b[32m0.61954\u001b[0m      0.99524      0.65549  2.37s\n",
      "      9       \u001b[36m0.61429\u001b[0m       \u001b[32m0.61858\u001b[0m      0.99306      0.65606  2.39s\n",
      "     10       \u001b[36m0.61347\u001b[0m       \u001b[32m0.61816\u001b[0m      0.99240      0.65682  2.35s\n",
      "     11       \u001b[36m0.61106\u001b[0m       \u001b[32m0.61767\u001b[0m      0.98931      0.65777  2.38s\n",
      "     12       \u001b[36m0.60994\u001b[0m       \u001b[32m0.61698\u001b[0m      0.98860      0.65835  2.37s\n",
      "     13       \u001b[36m0.60845\u001b[0m       \u001b[32m0.61642\u001b[0m      0.98708      0.65873  2.40s\n",
      "     14       \u001b[36m0.60526\u001b[0m       \u001b[32m0.61568\u001b[0m      0.98308      0.65739  2.37s\n",
      "     15       \u001b[36m0.60319\u001b[0m       \u001b[32m0.61507\u001b[0m      0.98068      0.65796  2.37s\n",
      "     16       \u001b[36m0.60235\u001b[0m       0.61513      0.97924      0.65835  2.33s\n",
      "     17       \u001b[36m0.59903\u001b[0m       \u001b[32m0.61473\u001b[0m      0.97446      0.65911  2.33s\n",
      "     18       \u001b[36m0.59800\u001b[0m       0.61488      0.97255      0.65968  2.37s\n",
      "     19       \u001b[36m0.59665\u001b[0m       0.61494      0.97026      0.65930  2.38s\n",
      "     20       \u001b[36m0.59603\u001b[0m       0.61579      0.96790      0.66063  2.39s\n",
      "     21       \u001b[36m0.59446\u001b[0m       \u001b[32m0.61462\u001b[0m      0.96721      0.66025  2.39s\n",
      "     22       \u001b[36m0.59193\u001b[0m       0.61547      0.96176      0.66235  2.36s\n",
      "     23       \u001b[36m0.59129\u001b[0m       0.61524      0.96107      0.66178  2.35s\n",
      "     24       \u001b[36m0.58857\u001b[0m       0.61601      0.95545      0.65930  2.36s\n",
      "     25       \u001b[36m0.58721\u001b[0m       0.61534      0.95429      0.66197  2.33s\n",
      "     26       \u001b[36m0.58585\u001b[0m       0.61519      0.95232      0.66540  2.32s\n",
      "     27       \u001b[36m0.58241\u001b[0m       0.61576      0.94583      0.66349  2.31s\n",
      "     28       \u001b[36m0.58195\u001b[0m       0.61678      0.94354      0.66387  2.35s\n",
      "     29       \u001b[36m0.57958\u001b[0m       0.61705      0.93928      0.66482  2.33s\n",
      "     30       \u001b[36m0.57715\u001b[0m       0.61711      0.93525      0.66254  2.34s\n",
      "     31       \u001b[36m0.57690\u001b[0m       0.61758      0.93413      0.66235  2.32s\n",
      "Early stopping.\n",
      "Best valid loss was 0.614615 at epoch 21.\n",
      "Loaded parameters to layer 'hidden0' (shape 100x500).\n",
      "Loaded parameters to layer 'hidden0' (shape 500).\n",
      "Loaded parameters to layer 'hidden1' (shape 500x160).\n",
      "Loaded parameters to layer 'hidden1' (shape 160).\n",
      "Loaded parameters to layer 'output' (shape 160x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 106672 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input        100\n",
      "  1  hidden0      400\n",
      "  2  dropout0     400\n",
      "  3  hidden1      150\n",
      "  4  dropout1     150\n",
      "  5  hidden2       40\n",
      "  6  output         2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m0.68158\u001b[0m       \u001b[32m0.65267\u001b[0m      1.04430      0.61319  2.19s\n",
      "      2       \u001b[36m0.65569\u001b[0m       \u001b[32m0.63928\u001b[0m      1.02567      0.62386  2.17s\n",
      "      3       \u001b[36m0.64598\u001b[0m       \u001b[32m0.63322\u001b[0m      1.02015      0.63205  2.21s\n",
      "      4       \u001b[36m0.64112\u001b[0m       \u001b[32m0.63048\u001b[0m      1.01686      0.63662  2.20s\n",
      "      5       \u001b[36m0.63597\u001b[0m       \u001b[32m0.62855\u001b[0m      1.01181      0.64005  2.22s\n",
      "      6       \u001b[36m0.63269\u001b[0m       \u001b[32m0.62758\u001b[0m      1.00815      0.64272  2.21s\n",
      "      7       \u001b[36m0.63082\u001b[0m       \u001b[32m0.62604\u001b[0m      1.00762      0.64558  2.21s\n",
      "      8       \u001b[36m0.62758\u001b[0m       \u001b[32m0.62537\u001b[0m      1.00353      0.64501  2.17s\n",
      "      9       \u001b[36m0.62565\u001b[0m       \u001b[32m0.62439\u001b[0m      1.00202      0.64558  2.21s\n",
      "     10       \u001b[36m0.62529\u001b[0m       \u001b[32m0.62420\u001b[0m      1.00174      0.64520  2.17s\n",
      "     11       \u001b[36m0.62209\u001b[0m       \u001b[32m0.62376\u001b[0m      0.99731      0.64653  2.17s\n",
      "     12       \u001b[36m0.62186\u001b[0m       \u001b[32m0.62347\u001b[0m      0.99742      0.64691  2.15s\n",
      "     13       \u001b[36m0.61978\u001b[0m       \u001b[32m0.62321\u001b[0m      0.99450      0.64844  2.21s\n",
      "     14       0.62017       \u001b[32m0.62247\u001b[0m      0.99630      0.65091  2.12s\n",
      "     15       \u001b[36m0.61908\u001b[0m       \u001b[32m0.62232\u001b[0m      0.99480      0.65187  2.17s\n",
      "     16       \u001b[36m0.61723\u001b[0m       \u001b[32m0.62173\u001b[0m      0.99277      0.65187  2.20s\n",
      "     17       \u001b[36m0.61643\u001b[0m       \u001b[32m0.62154\u001b[0m      0.99178      0.65091  2.19s\n",
      "     18       \u001b[36m0.61484\u001b[0m       \u001b[32m0.62116\u001b[0m      0.98982      0.65244  2.12s\n",
      "     19       \u001b[36m0.61479\u001b[0m       \u001b[32m0.62051\u001b[0m      0.99079      0.65396  2.20s\n",
      "     20       \u001b[36m0.61188\u001b[0m       \u001b[32m0.61988\u001b[0m      0.98709      0.65549  2.16s\n",
      "     21       \u001b[36m0.61062\u001b[0m       0.62002      0.98484      0.65149  2.18s\n",
      "     22       0.61063       0.62001      0.98489      0.65244  2.15s\n",
      "     23       \u001b[36m0.60996\u001b[0m       \u001b[32m0.61972\u001b[0m      0.98425      0.65206  2.18s\n",
      "     24       \u001b[36m0.60925\u001b[0m       \u001b[32m0.61941\u001b[0m      0.98360      0.65320  2.14s\n",
      "     25       \u001b[36m0.60707\u001b[0m       \u001b[32m0.61920\u001b[0m      0.98041      0.65434  2.21s\n",
      "     26       \u001b[36m0.60643\u001b[0m       \u001b[32m0.61869\u001b[0m      0.98019      0.65511  2.18s\n",
      "     27       \u001b[36m0.60388\u001b[0m       \u001b[32m0.61866\u001b[0m      0.97612      0.65777  2.20s\n",
      "     28       \u001b[36m0.60371\u001b[0m       \u001b[32m0.61856\u001b[0m      0.97599      0.65568  2.16s\n",
      "     29       \u001b[36m0.60300\u001b[0m       0.61896      0.97421      0.65625  2.16s\n",
      "     30       \u001b[36m0.60171\u001b[0m       \u001b[32m0.61842\u001b[0m      0.97298      0.65587  2.18s\n",
      "     31       \u001b[36m0.59974\u001b[0m       0.61909      0.96874      0.65816  2.16s\n",
      "     32       0.60102       \u001b[32m0.61837\u001b[0m      0.97194      0.65835  2.13s\n",
      "     33       \u001b[36m0.59905\u001b[0m       \u001b[32m0.61834\u001b[0m      0.96880      0.65492  2.18s\n",
      "     34       \u001b[36m0.59771\u001b[0m       0.61846      0.96645      0.65415  2.17s\n",
      "     35       \u001b[36m0.59688\u001b[0m       \u001b[32m0.61830\u001b[0m      0.96535      0.65568  2.15s\n",
      "     36       \u001b[36m0.59441\u001b[0m       0.61856      0.96095      0.65644  2.16s\n",
      "     37       \u001b[36m0.59289\u001b[0m       \u001b[32m0.61799\u001b[0m      0.95937      0.65854  2.14s\n",
      "     38       0.59295       \u001b[32m0.61741\u001b[0m      0.96038      0.66044  2.16s\n",
      "     39       \u001b[36m0.58970\u001b[0m       0.61899      0.95267      0.66006  2.21s\n",
      "     40       \u001b[36m0.58959\u001b[0m       0.61768      0.95452      0.66006  2.21s\n",
      "     41       \u001b[36m0.58751\u001b[0m       0.61889      0.94929      0.65892  2.14s\n",
      "     42       \u001b[36m0.58637\u001b[0m       0.61961      0.94637      0.65644  2.15s\n",
      "     43       \u001b[36m0.58535\u001b[0m       0.61862      0.94623      0.65835  2.17s\n",
      "     44       \u001b[36m0.58352\u001b[0m       0.61907      0.94256      0.65854  2.17s\n",
      "     45       \u001b[36m0.58114\u001b[0m       0.61857      0.93950      0.65816  2.16s\n",
      "     46       0.58141       0.61927      0.93886      0.66082  2.14s\n",
      "     47       \u001b[36m0.58050\u001b[0m       0.61815      0.93909      0.65682  2.14s\n",
      "     48       \u001b[36m0.57985\u001b[0m       0.61765      0.93881      0.66159  2.12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/projekte/anaconda3/envs/ipynb/lib/python3.5/site-packages/nolearn/lasagne/base.py:250: UserWarning: The 'eval_size' argument has been deprecated, please use the 'train_split' parameter instead, e.g.\n",
      "train_split=TrainSplit(eval_size=0.4)\n",
      "  warn(\"The 'eval_size' argument has been deprecated, please use \"\n",
      "INFO:root:start loading the model\n",
      "INFO:gensim.utils:loading Doc2Vec object from /home/user/projekte/econstorModelling/cache/allDocs300D.model\n",
      "INFO:gensim.utils:loading docvecs recursively from /home/user/projekte/econstorModelling/cache/allDocs300D.model.docvecs.* with mmap=None\n",
      "INFO:gensim.utils:loading doctag_syn0 from /home/user/projekte/econstorModelling/cache/allDocs300D.model.docvecs.doctag_syn0.npy with mmap=None\n",
      "INFO:gensim.utils:loading syn0 from /home/user/projekte/econstorModelling/cache/allDocs300D.model.syn0.npy with mmap=None\n",
      "INFO:gensim.utils:loading syn1 from /home/user/projekte/econstorModelling/cache/allDocs300D.model.syn1.npy with mmap=None\n",
      "INFO:gensim.utils:setting ignored attribute syn0norm to None\n",
      "INFO:gensim.utils:setting ignored attribute cum_table to None\n",
      "INFO:root:loading completed\n",
      "INFO:root:building corpus...\n",
      "INFO:root:corpus complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping.\n",
      "Best valid loss was 0.617407 at epoch 38.\n",
      "Loaded parameters to layer 'hidden0' (shape 100x400).\n",
      "Loaded parameters to layer 'hidden0' (shape 400).\n",
      "Loaded parameters to layer 'hidden1' (shape 400x150).\n",
      "Loaded parameters to layer 'hidden1' (shape 150).\n",
      "Loaded parameters to layer 'hidden2' (shape 150x40).\n",
      "Loaded parameters to layer 'hidden2' (shape 40).\n",
      "Loaded parameters to layer 'output' (shape 40x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 30302 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name       size\n",
      "---  -------  ------\n",
      "  0  input       300\n",
      "  1  hidden0     100\n",
      "  2  output        2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m0.65630\u001b[0m       \u001b[32m0.62976\u001b[0m      1.04216      0.63720  0.41s\n",
      "      2       \u001b[36m0.61977\u001b[0m       \u001b[32m0.61844\u001b[0m      1.00215      0.65015  0.33s\n",
      "      3       \u001b[36m0.60920\u001b[0m       \u001b[32m0.61562\u001b[0m      0.98957      0.64501  0.36s\n",
      "      4       \u001b[36m0.60385\u001b[0m       \u001b[32m0.61424\u001b[0m      0.98308      0.65015  0.34s\n",
      "      5       \u001b[36m0.59983\u001b[0m       \u001b[32m0.61321\u001b[0m      0.97817      0.65434  0.34s\n",
      "      6       \u001b[36m0.59614\u001b[0m       \u001b[32m0.61219\u001b[0m      0.97378      0.65739  0.37s\n",
      "      7       \u001b[36m0.59250\u001b[0m       \u001b[32m0.61132\u001b[0m      0.96921      0.65911  0.34s\n",
      "      8       \u001b[36m0.58873\u001b[0m       \u001b[32m0.61056\u001b[0m      0.96423      0.66006  0.33s\n",
      "      9       \u001b[36m0.58474\u001b[0m       \u001b[32m0.60979\u001b[0m      0.95891      0.66216  0.34s\n",
      "     10       \u001b[36m0.58049\u001b[0m       \u001b[32m0.60907\u001b[0m      0.95308      0.66082  0.33s\n",
      "     11       \u001b[36m0.57593\u001b[0m       \u001b[32m0.60844\u001b[0m      0.94657      0.66025  0.36s\n",
      "     12       \u001b[36m0.57109\u001b[0m       \u001b[32m0.60791\u001b[0m      0.93944      0.66025  0.34s\n",
      "     13       \u001b[36m0.56592\u001b[0m       \u001b[32m0.60765\u001b[0m      0.93133      0.65873  0.33s\n",
      "     14       \u001b[36m0.56041\u001b[0m       0.60770      0.92217      0.66120  0.35s\n",
      "     15       \u001b[36m0.55458\u001b[0m       0.60803      0.91209      0.66120  0.35s\n",
      "     16       \u001b[36m0.54844\u001b[0m       0.60887      0.90075      0.65949  0.34s\n",
      "     17       \u001b[36m0.54200\u001b[0m       0.60998      0.88856      0.65930  0.33s\n",
      "     18       \u001b[36m0.53529\u001b[0m       0.61165      0.87516      0.66597  0.34s\n",
      "     19       \u001b[36m0.52834\u001b[0m       0.61366      0.86097      0.66502  0.34s\n",
      "     20       \u001b[36m0.52119\u001b[0m       0.61596      0.84615      0.66673  0.33s\n",
      "     21       \u001b[36m0.51382\u001b[0m       0.61881      0.83034      0.66521  0.34s\n",
      "     22       \u001b[36m0.50634\u001b[0m       0.62222      0.81376      0.66330  0.35s\n",
      "     23       \u001b[36m0.49877\u001b[0m       0.62602      0.79672      0.66082  0.34s\n",
      "Early stopping.\n",
      "Best valid loss was 0.607649 at epoch 13.\n",
      "Loaded parameters to layer 'hidden0' (shape 300x100).\n",
      "Loaded parameters to layer 'hidden0' (shape 100).\n",
      "Loaded parameters to layer 'output' (shape 100x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 90902 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name       size\n",
      "---  -------  ------\n",
      "  0  input       300\n",
      "  1  hidden0     300\n",
      "  2  output        2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m0.64592\u001b[0m       \u001b[32m0.62407\u001b[0m      1.03502      0.64139  0.95s\n",
      "      2       \u001b[36m0.61404\u001b[0m       \u001b[32m0.61600\u001b[0m      0.99682      0.65091  0.94s\n",
      "      3       \u001b[36m0.60545\u001b[0m       \u001b[32m0.61404\u001b[0m      0.98602      0.65282  0.99s\n",
      "      4       \u001b[36m0.60022\u001b[0m       \u001b[32m0.61285\u001b[0m      0.97940      0.65225  0.95s\n",
      "      5       \u001b[36m0.59562\u001b[0m       \u001b[32m0.61193\u001b[0m      0.97335      0.65244  0.97s\n",
      "      6       \u001b[36m0.59099\u001b[0m       \u001b[32m0.61093\u001b[0m      0.96736      0.65587  0.96s\n",
      "      7       \u001b[36m0.58606\u001b[0m       \u001b[32m0.60991\u001b[0m      0.96090      0.65682  0.95s\n",
      "      8       \u001b[36m0.58067\u001b[0m       \u001b[32m0.60898\u001b[0m      0.95352      0.65835  0.96s\n",
      "      9       \u001b[36m0.57473\u001b[0m       \u001b[32m0.60806\u001b[0m      0.94519      0.66082  0.98s\n",
      "     10       \u001b[36m0.56820\u001b[0m       \u001b[32m0.60733\u001b[0m      0.93557      0.66311  0.95s\n",
      "     11       \u001b[36m0.56102\u001b[0m       \u001b[32m0.60662\u001b[0m      0.92483      0.66311  0.95s\n",
      "     12       \u001b[36m0.55314\u001b[0m       \u001b[32m0.60601\u001b[0m      0.91275      0.66216  0.96s\n",
      "     13       \u001b[36m0.54458\u001b[0m       \u001b[32m0.60588\u001b[0m      0.89882      0.66044  0.95s\n",
      "     14       \u001b[36m0.53535\u001b[0m       0.60631      0.88296      0.66044  0.96s\n",
      "     15       \u001b[36m0.52548\u001b[0m       0.60718      0.86544      0.66159  1.00s\n",
      "     16       \u001b[36m0.51507\u001b[0m       0.60861      0.84632      0.66254  0.96s\n",
      "     17       \u001b[36m0.50421\u001b[0m       0.61070      0.82562      0.66197  0.96s\n",
      "     18       \u001b[36m0.49286\u001b[0m       0.61322      0.80372      0.66406  0.96s\n",
      "     19       \u001b[36m0.48111\u001b[0m       0.61625      0.78072      0.66311  0.95s\n",
      "     20       \u001b[36m0.46908\u001b[0m       0.61977      0.75686      0.66120  0.98s\n",
      "     21       \u001b[36m0.45684\u001b[0m       0.62360      0.73259      0.65949  0.97s\n",
      "     22       \u001b[36m0.44446\u001b[0m       0.62801      0.70772      0.65911  0.94s\n",
      "     23       \u001b[36m0.43202\u001b[0m       0.63321      0.68227      0.65835  0.97s\n",
      "Early stopping.\n",
      "Best valid loss was 0.605884 at epoch 13.\n",
      "Loaded parameters to layer 'hidden0' (shape 300x300).\n",
      "Loaded parameters to layer 'hidden0' (shape 300).\n",
      "Loaded parameters to layer 'output' (shape 300x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 95492 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input        300\n",
      "  1  hidden0      250\n",
      "  2  dropout0     250\n",
      "  3  hidden1       80\n",
      "  4  output         2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m0.65890\u001b[0m       \u001b[32m0.62685\u001b[0m      1.05113      0.63643  1.44s\n",
      "      2       \u001b[36m0.62648\u001b[0m       \u001b[32m0.61846\u001b[0m      1.01297      0.65053  1.42s\n",
      "      3       \u001b[36m0.61758\u001b[0m       \u001b[32m0.61495\u001b[0m      1.00427      0.65320  1.43s\n",
      "      4       \u001b[36m0.61078\u001b[0m       \u001b[32m0.61391\u001b[0m      0.99489      0.65015  1.41s\n",
      "      5       \u001b[36m0.60600\u001b[0m       \u001b[32m0.61271\u001b[0m      0.98905      0.65339  1.43s\n",
      "      6       \u001b[36m0.60255\u001b[0m       0.61272      0.98342      0.65606  1.40s\n",
      "      7       \u001b[36m0.59694\u001b[0m       \u001b[32m0.61191\u001b[0m      0.97554      0.66197  1.43s\n",
      "      8       \u001b[36m0.59517\u001b[0m       0.61193      0.97262      0.66349  1.42s\n",
      "      9       \u001b[36m0.59152\u001b[0m       0.61211      0.96635      0.65492  1.42s\n",
      "     10       \u001b[36m0.58625\u001b[0m       \u001b[32m0.61158\u001b[0m      0.95858      0.65968  1.43s\n",
      "     11       \u001b[36m0.58314\u001b[0m       \u001b[32m0.61128\u001b[0m      0.95398      0.65968  1.41s\n",
      "     12       \u001b[36m0.57745\u001b[0m       0.61254      0.94272      0.65816  1.45s\n",
      "     13       \u001b[36m0.57419\u001b[0m       0.61280      0.93699      0.65987  1.43s\n",
      "     14       \u001b[36m0.57019\u001b[0m       0.61483      0.92739      0.65892  1.44s\n",
      "     15       \u001b[36m0.56391\u001b[0m       0.61291      0.92006      0.66063  1.43s\n",
      "     16       \u001b[36m0.56000\u001b[0m       0.61418      0.91180      0.66101  1.41s\n",
      "     17       \u001b[36m0.55315\u001b[0m       0.61471      0.89987      0.66044  1.42s\n",
      "     18       \u001b[36m0.54799\u001b[0m       0.61768      0.88717      0.65911  1.42s\n",
      "     19       \u001b[36m0.54140\u001b[0m       0.61680      0.87776      0.66178  1.41s\n",
      "     20       \u001b[36m0.53632\u001b[0m       0.61677      0.86956      0.66120  1.44s\n",
      "     21       \u001b[36m0.52856\u001b[0m       0.62378      0.84734      0.65987  1.44s\n",
      "Early stopping.\n",
      "Best valid loss was 0.611275 at epoch 11.\n",
      "Loaded parameters to layer 'hidden0' (shape 300x250).\n",
      "Loaded parameters to layer 'hidden0' (shape 250).\n",
      "Loaded parameters to layer 'hidden1' (shape 250x80).\n",
      "Loaded parameters to layer 'hidden1' (shape 80).\n",
      "Loaded parameters to layer 'output' (shape 80x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 230982 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input        300\n",
      "  1  hidden0      500\n",
      "  2  dropout0     500\n",
      "  3  hidden1      160\n",
      "  4  output         2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m0.65680\u001b[0m       \u001b[32m0.62579\u001b[0m      1.04956      0.63491  3.46s\n",
      "      2       \u001b[36m0.62393\u001b[0m       \u001b[32m0.61666\u001b[0m      1.01178      0.64520  3.30s\n",
      "      3       \u001b[36m0.61360\u001b[0m       \u001b[32m0.61373\u001b[0m      0.99979      0.65225  3.31s\n",
      "      4       \u001b[36m0.60806\u001b[0m       \u001b[32m0.61292\u001b[0m      0.99207      0.65454  3.30s\n",
      "      5       \u001b[36m0.60110\u001b[0m       \u001b[32m0.61175\u001b[0m      0.98259      0.65949  3.35s\n",
      "      6       \u001b[36m0.59842\u001b[0m       \u001b[32m0.61080\u001b[0m      0.97973      0.66273  3.27s\n",
      "      7       \u001b[36m0.59312\u001b[0m       \u001b[32m0.61060\u001b[0m      0.97137      0.66025  3.30s\n",
      "      8       \u001b[36m0.58867\u001b[0m       \u001b[32m0.61011\u001b[0m      0.96486      0.66139  3.32s\n",
      "      9       \u001b[36m0.58277\u001b[0m       \u001b[32m0.60948\u001b[0m      0.95618      0.66235  3.37s\n",
      "     10       \u001b[36m0.57858\u001b[0m       \u001b[32m0.60902\u001b[0m      0.95001      0.66311  3.29s\n",
      "     11       \u001b[36m0.57174\u001b[0m       \u001b[32m0.60827\u001b[0m      0.93994      0.66292  3.32s\n",
      "     12       \u001b[36m0.56389\u001b[0m       0.60869      0.92640      0.66120  3.31s\n",
      "     13       \u001b[36m0.55793\u001b[0m       \u001b[32m0.60826\u001b[0m      0.91725      0.66159  3.26s\n",
      "     14       \u001b[36m0.55046\u001b[0m       0.61072      0.90133      0.66044  3.31s\n",
      "     15       \u001b[36m0.54184\u001b[0m       0.61145      0.88616      0.66216  3.31s\n",
      "     16       \u001b[36m0.53353\u001b[0m       0.61394      0.86903      0.65968  3.28s\n",
      "     17       \u001b[36m0.52566\u001b[0m       0.61484      0.85495      0.66101  3.26s\n",
      "     18       \u001b[36m0.51494\u001b[0m       0.61703      0.83454      0.66063  3.33s\n",
      "     19       \u001b[36m0.50393\u001b[0m       0.62171      0.81056      0.65968  3.29s\n",
      "     20       \u001b[36m0.48832\u001b[0m       0.62951      0.77570      0.66197  3.32s\n",
      "     21       \u001b[36m0.47905\u001b[0m       0.64279      0.74527      0.66044  3.32s\n",
      "     22       \u001b[36m0.47199\u001b[0m       0.64385      0.73307      0.65644  3.29s\n",
      "     23       \u001b[36m0.45826\u001b[0m       0.65037      0.70462      0.66178  3.31s\n",
      "Early stopping.\n",
      "Best valid loss was 0.608263 at epoch 13.\n",
      "Loaded parameters to layer 'hidden0' (shape 300x500).\n",
      "Loaded parameters to layer 'hidden0' (shape 500).\n",
      "Loaded parameters to layer 'hidden1' (shape 500x160).\n",
      "Loaded parameters to layer 'hidden1' (shape 160).\n",
      "Loaded parameters to layer 'output' (shape 160x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 186672 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input        300\n",
      "  1  hidden0      400\n",
      "  2  dropout0     400\n",
      "  3  hidden1      150\n",
      "  4  dropout1     150\n",
      "  5  hidden2       40\n",
      "  6  output         2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m0.66644\u001b[0m       \u001b[32m0.62649\u001b[0m      1.06377      0.63872  2.92s\n",
      "      2       \u001b[36m0.63341\u001b[0m       \u001b[32m0.61711\u001b[0m      1.02642      0.64596  2.85s\n",
      "      3       \u001b[36m0.62177\u001b[0m       \u001b[32m0.61385\u001b[0m      1.01290      0.65339  2.81s\n",
      "      4       \u001b[36m0.61428\u001b[0m       \u001b[32m0.61196\u001b[0m      1.00379      0.65987  2.84s\n",
      "      5       \u001b[36m0.60953\u001b[0m       \u001b[32m0.61086\u001b[0m      0.99783      0.65873  2.85s\n",
      "      6       \u001b[36m0.60650\u001b[0m       0.61194      0.99110      0.65796  2.85s\n",
      "      7       \u001b[36m0.60269\u001b[0m       0.61088      0.98659      0.65930  2.82s\n",
      "      8       \u001b[36m0.59797\u001b[0m       \u001b[32m0.61051\u001b[0m      0.97945      0.66101  2.82s\n",
      "      9       \u001b[36m0.59529\u001b[0m       \u001b[32m0.60866\u001b[0m      0.97804      0.66044  2.81s\n",
      "     10       \u001b[36m0.59118\u001b[0m       \u001b[32m0.60835\u001b[0m      0.97177      0.65911  2.82s\n",
      "     11       \u001b[36m0.58698\u001b[0m       0.60861      0.96447      0.66273  2.80s\n",
      "     12       \u001b[36m0.58267\u001b[0m       \u001b[32m0.60757\u001b[0m      0.95901      0.66444  2.83s\n",
      "     13       \u001b[36m0.57819\u001b[0m       \u001b[32m0.60629\u001b[0m      0.95365      0.66540  2.79s\n",
      "     14       \u001b[36m0.57317\u001b[0m       0.60630      0.94536      0.66406  2.88s\n",
      "     15       \u001b[36m0.56724\u001b[0m       0.60681      0.93480      0.66254  2.84s\n",
      "     16       \u001b[36m0.56208\u001b[0m       0.60787      0.92468      0.66349  2.82s\n",
      "     17       \u001b[36m0.55585\u001b[0m       0.60758      0.91486      0.66273  2.81s\n",
      "     18       \u001b[36m0.54846\u001b[0m       0.60979      0.89943      0.66273  2.84s\n",
      "     19       \u001b[36m0.54226\u001b[0m       0.61009      0.88882      0.66235  2.80s\n",
      "     20       \u001b[36m0.52985\u001b[0m       0.61518      0.86130      0.66273  2.83s\n",
      "     21       \u001b[36m0.52124\u001b[0m       0.61955      0.84132      0.65873  2.81s\n",
      "     22       \u001b[36m0.51183\u001b[0m       0.62015      0.82534      0.66082  2.77s\n",
      "     23       \u001b[36m0.50261\u001b[0m       0.62541      0.80365      0.66425  2.78s\n",
      "Early stopping.\n",
      "Best valid loss was 0.606285 at epoch 13.\n",
      "Loaded parameters to layer 'hidden0' (shape 300x400).\n",
      "Loaded parameters to layer 'hidden0' (shape 400).\n",
      "Loaded parameters to layer 'hidden1' (shape 400x150).\n",
      "Loaded parameters to layer 'hidden1' (shape 150).\n",
      "Loaded parameters to layer 'hidden2' (shape 150x40).\n",
      "Loaded parameters to layer 'hidden2' (shape 40).\n",
      "Loaded parameters to layer 'output' (shape 40x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 30302 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name       size\n",
      "---  -------  ------\n",
      "  0  input       300\n",
      "  1  hidden0     100\n",
      "  2  output        2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m0.64803\u001b[0m       \u001b[32m0.62558\u001b[0m      1.03588      0.63777  0.45s\n",
      "      2       \u001b[36m0.61573\u001b[0m       \u001b[32m0.61657\u001b[0m      0.99863      0.64901  0.35s\n",
      "      3       \u001b[36m0.60726\u001b[0m       \u001b[32m0.61502\u001b[0m      0.98738      0.64348  0.36s\n",
      "      4       \u001b[36m0.60288\u001b[0m       \u001b[32m0.61450\u001b[0m      0.98109      0.64425  0.33s\n",
      "      5       \u001b[36m0.59934\u001b[0m       \u001b[32m0.61400\u001b[0m      0.97612      0.64520  0.35s\n",
      "      6       \u001b[36m0.59589\u001b[0m       \u001b[32m0.61348\u001b[0m      0.97132      0.64653  0.34s\n",
      "      7       \u001b[36m0.59229\u001b[0m       \u001b[32m0.61310\u001b[0m      0.96606      0.64787  0.34s\n",
      "      8       \u001b[36m0.58848\u001b[0m       \u001b[32m0.61272\u001b[0m      0.96044      0.64825  0.35s\n",
      "      9       \u001b[36m0.58441\u001b[0m       \u001b[32m0.61260\u001b[0m      0.95398      0.64825  0.34s\n",
      "     10       \u001b[36m0.58005\u001b[0m       \u001b[32m0.61250\u001b[0m      0.94702      0.65111  0.35s\n",
      "     11       \u001b[36m0.57533\u001b[0m       \u001b[32m0.61241\u001b[0m      0.93945      0.65263  0.34s\n",
      "     12       \u001b[36m0.57023\u001b[0m       0.61264      0.93078      0.65225  0.34s\n",
      "     13       \u001b[36m0.56480\u001b[0m       0.61303      0.92133      0.65244  0.34s\n",
      "     14       \u001b[36m0.55907\u001b[0m       0.61373      0.91094      0.65111  0.34s\n",
      "     15       \u001b[36m0.55310\u001b[0m       0.61460      0.89994      0.65130  0.34s\n",
      "     16       \u001b[36m0.54690\u001b[0m       0.61572      0.88823      0.65854  0.34s\n",
      "     17       \u001b[36m0.54049\u001b[0m       0.61754      0.87523      0.65777  0.35s\n",
      "     18       \u001b[36m0.53383\u001b[0m       0.61964      0.86152      0.65663  0.34s\n",
      "     19       \u001b[36m0.52699\u001b[0m       0.62174      0.84760      0.65492  0.35s\n",
      "     20       \u001b[36m0.52009\u001b[0m       0.62430      0.83307      0.65644  0.36s\n",
      "     21       \u001b[36m0.51303\u001b[0m       0.62714      0.81804      0.65663  0.35s\n",
      "Early stopping.\n",
      "Best valid loss was 0.612409 at epoch 11.\n",
      "Loaded parameters to layer 'hidden0' (shape 300x100).\n",
      "Loaded parameters to layer 'hidden0' (shape 100).\n",
      "Loaded parameters to layer 'output' (shape 100x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 90902 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name       size\n",
      "---  -------  ------\n",
      "  0  input       300\n",
      "  1  hidden0     300\n",
      "  2  output        2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m0.64771\u001b[0m       \u001b[32m0.62245\u001b[0m      1.04057      0.64177  0.97s\n",
      "      2       \u001b[36m0.61355\u001b[0m       \u001b[32m0.61474\u001b[0m      0.99807      0.65091  0.98s\n",
      "      3       \u001b[36m0.60452\u001b[0m       \u001b[32m0.61347\u001b[0m      0.98541      0.65168  0.97s\n",
      "      4       \u001b[36m0.59902\u001b[0m       \u001b[32m0.61289\u001b[0m      0.97738      0.65625  0.98s\n",
      "      5       \u001b[36m0.59414\u001b[0m       \u001b[32m0.61247\u001b[0m      0.97008      0.65530  0.98s\n",
      "      6       \u001b[36m0.58923\u001b[0m       \u001b[32m0.61189\u001b[0m      0.96298      0.65739  0.99s\n",
      "      7       \u001b[36m0.58405\u001b[0m       \u001b[32m0.61142\u001b[0m      0.95525      0.65968  0.98s\n",
      "      8       \u001b[36m0.57845\u001b[0m       \u001b[32m0.61096\u001b[0m      0.94679      0.66120  0.98s\n",
      "      9       \u001b[36m0.57233\u001b[0m       \u001b[32m0.61044\u001b[0m      0.93757      0.66387  0.97s\n",
      "     10       \u001b[36m0.56566\u001b[0m       \u001b[32m0.61016\u001b[0m      0.92707      0.66406  0.98s\n",
      "     11       \u001b[36m0.55831\u001b[0m       0.61018      0.91499      0.66692  0.98s\n",
      "     12       \u001b[36m0.55027\u001b[0m       0.61056      0.90126      0.66711  0.97s\n",
      "     13       \u001b[36m0.54155\u001b[0m       0.61140      0.88574      0.66463  0.97s\n",
      "     14       \u001b[36m0.53215\u001b[0m       0.61277      0.86843      0.66444  0.99s\n",
      "     15       \u001b[36m0.52216\u001b[0m       0.61473      0.84941      0.66692  0.99s\n",
      "     16       \u001b[36m0.51166\u001b[0m       0.61744      0.82869      0.66806  0.96s\n",
      "     17       \u001b[36m0.50073\u001b[0m       0.62081      0.80657      0.66597  0.99s\n",
      "     18       \u001b[36m0.48941\u001b[0m       0.62457      0.78359      0.66311  0.98s\n",
      "     19       \u001b[36m0.47777\u001b[0m       0.62915      0.75938      0.66254  0.97s\n",
      "     20       \u001b[36m0.46591\u001b[0m       0.63397      0.73491      0.66139  0.99s\n",
      "Early stopping.\n",
      "Best valid loss was 0.610160 at epoch 10.\n",
      "Loaded parameters to layer 'hidden0' (shape 300x300).\n",
      "Loaded parameters to layer 'hidden0' (shape 300).\n",
      "Loaded parameters to layer 'output' (shape 300x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 95492 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input        300\n",
      "  1  hidden0      250\n",
      "  2  dropout0     250\n",
      "  3  hidden1       80\n",
      "  4  output         2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m0.66267\u001b[0m       \u001b[32m0.63307\u001b[0m      1.04676      0.63700  1.45s\n",
      "      2       \u001b[36m0.63785\u001b[0m       \u001b[32m0.62311\u001b[0m      1.02366      0.64101  1.45s\n",
      "      3       \u001b[36m0.62706\u001b[0m       \u001b[32m0.62001\u001b[0m      1.01137      0.63796  1.46s\n",
      "      4       \u001b[36m0.62109\u001b[0m       \u001b[32m0.61781\u001b[0m      1.00532      0.64425  1.45s\n",
      "      5       \u001b[36m0.61656\u001b[0m       \u001b[32m0.61746\u001b[0m      0.99854      0.64386  1.43s\n",
      "      6       \u001b[36m0.61298\u001b[0m       \u001b[32m0.61689\u001b[0m      0.99365      0.64234  1.45s\n",
      "      7       \u001b[36m0.60883\u001b[0m       \u001b[32m0.61679\u001b[0m      0.98710      0.64367  1.44s\n",
      "      8       \u001b[36m0.60679\u001b[0m       \u001b[32m0.61496\u001b[0m      0.98671      0.64748  1.48s\n",
      "      9       \u001b[36m0.60224\u001b[0m       \u001b[32m0.61450\u001b[0m      0.98004      0.64539  1.44s\n",
      "     10       \u001b[36m0.60103\u001b[0m       \u001b[32m0.61345\u001b[0m      0.97976      0.64729  1.48s\n",
      "     11       \u001b[36m0.59842\u001b[0m       0.61360      0.97525      0.64710  1.45s\n",
      "     12       \u001b[36m0.59645\u001b[0m       0.61388      0.97160      0.65396  1.45s\n",
      "     13       \u001b[36m0.59288\u001b[0m       0.61351      0.96639      0.65149  1.46s\n",
      "     14       \u001b[36m0.59086\u001b[0m       0.61360      0.96293      0.65816  1.43s\n",
      "     15       \u001b[36m0.58708\u001b[0m       \u001b[32m0.61297\u001b[0m      0.95776      0.65892  1.46s\n",
      "     16       \u001b[36m0.58660\u001b[0m       0.61404      0.95530      0.65968  1.48s\n",
      "     17       \u001b[36m0.58305\u001b[0m       \u001b[32m0.61291\u001b[0m      0.95128      0.66082  1.45s\n",
      "     18       \u001b[36m0.58034\u001b[0m       0.61401      0.94516      0.65796  1.46s\n",
      "     19       \u001b[36m0.57728\u001b[0m       \u001b[32m0.61127\u001b[0m      0.94439      0.66101  1.46s\n",
      "     20       \u001b[36m0.57370\u001b[0m       0.61264      0.93644      0.66006  1.47s\n",
      "     21       \u001b[36m0.57120\u001b[0m       0.61150      0.93410      0.66006  1.44s\n",
      "     22       \u001b[36m0.56863\u001b[0m       0.61131      0.93018      0.66273  1.46s\n",
      "     23       \u001b[36m0.56460\u001b[0m       0.61267      0.92154      0.66178  1.46s\n",
      "     24       \u001b[36m0.56111\u001b[0m       \u001b[32m0.61118\u001b[0m      0.91808      0.66311  1.46s\n",
      "     25       \u001b[36m0.55814\u001b[0m       0.61187      0.91219      0.65930  1.45s\n",
      "     26       \u001b[36m0.55556\u001b[0m       0.61215      0.90756      0.66425  1.43s\n",
      "     27       \u001b[36m0.55111\u001b[0m       0.61419      0.89729      0.66063  1.43s\n",
      "     28       \u001b[36m0.54610\u001b[0m       0.61524      0.88763      0.66730  1.43s\n",
      "     29       \u001b[36m0.54318\u001b[0m       0.61585      0.88200      0.66082  1.43s\n",
      "     30       \u001b[36m0.54056\u001b[0m       0.61550      0.87824      0.65835  1.45s\n",
      "     31       \u001b[36m0.53876\u001b[0m       0.61473      0.87642      0.66502  1.44s\n",
      "     32       \u001b[36m0.53153\u001b[0m       0.61920      0.85841      0.66806  1.45s\n",
      "     33       \u001b[36m0.52929\u001b[0m       0.61932      0.85463      0.65987  1.42s\n",
      "     34       \u001b[36m0.52459\u001b[0m       0.62410      0.84056      0.66139  1.44s\n",
      "Early stopping.\n",
      "Best valid loss was 0.611177 at epoch 24.\n",
      "Loaded parameters to layer 'hidden0' (shape 300x250).\n",
      "Loaded parameters to layer 'hidden0' (shape 250).\n",
      "Loaded parameters to layer 'hidden1' (shape 250x80).\n",
      "Loaded parameters to layer 'hidden1' (shape 80).\n",
      "Loaded parameters to layer 'output' (shape 80x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 230982 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input        300\n",
      "  1  hidden0      500\n",
      "  2  dropout0     500\n",
      "  3  hidden1      160\n",
      "  4  output         2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m0.66022\u001b[0m       \u001b[32m0.62690\u001b[0m      1.05316      0.64024  3.30s\n",
      "      2       \u001b[36m0.62999\u001b[0m       \u001b[32m0.61685\u001b[0m      1.02129      0.64501  3.26s\n",
      "      3       \u001b[36m0.62079\u001b[0m       \u001b[32m0.61528\u001b[0m      1.00896      0.65111  3.38s\n",
      "      4       \u001b[36m0.61421\u001b[0m       \u001b[32m0.61310\u001b[0m      1.00180      0.65320  3.24s\n",
      "      5       \u001b[36m0.61106\u001b[0m       \u001b[32m0.61263\u001b[0m      0.99743      0.65434  3.36s\n",
      "      6       \u001b[36m0.60665\u001b[0m       \u001b[32m0.61249\u001b[0m      0.99046      0.65644  3.25s\n",
      "      7       \u001b[36m0.60285\u001b[0m       \u001b[32m0.61098\u001b[0m      0.98669      0.65454  3.36s\n",
      "      8       \u001b[36m0.59973\u001b[0m       \u001b[32m0.61049\u001b[0m      0.98238      0.65663  3.20s\n",
      "      9       \u001b[36m0.59669\u001b[0m       \u001b[32m0.60990\u001b[0m      0.97833      0.65911  3.31s\n",
      "     10       \u001b[36m0.59243\u001b[0m       0.61007      0.97109      0.65930  3.23s\n",
      "     11       \u001b[36m0.59000\u001b[0m       \u001b[32m0.60855\u001b[0m      0.96951      0.65758  3.24s\n",
      "     12       \u001b[36m0.58808\u001b[0m       0.60929      0.96519      0.65892  3.38s\n",
      "     13       \u001b[36m0.58354\u001b[0m       0.60878      0.95855      0.66101  3.32s\n",
      "     14       \u001b[36m0.57975\u001b[0m       \u001b[32m0.60841\u001b[0m      0.95290      0.65987  3.35s\n",
      "     15       \u001b[36m0.57661\u001b[0m       0.60878      0.94716      0.66159  3.22s\n",
      "     16       \u001b[36m0.57130\u001b[0m       0.60943      0.93744      0.66368  3.21s\n",
      "     17       \u001b[36m0.56874\u001b[0m       0.60916      0.93365      0.66101  3.20s\n",
      "     18       \u001b[36m0.56407\u001b[0m       0.60937      0.92567      0.66482  3.21s\n",
      "     19       \u001b[36m0.55994\u001b[0m       0.60913      0.91924      0.66425  3.22s\n",
      "     20       \u001b[36m0.55332\u001b[0m       0.61021      0.90677      0.66463  3.23s\n",
      "     21       \u001b[36m0.54903\u001b[0m       0.60886      0.90173      0.66997  3.19s\n",
      "     22       \u001b[36m0.54262\u001b[0m       0.61161      0.88719      0.66845  3.22s\n",
      "     23       \u001b[36m0.53566\u001b[0m       0.61222      0.87495      0.66902  3.24s\n",
      "     24       \u001b[36m0.53013\u001b[0m       0.61252      0.86549      0.66787  3.20s\n",
      "Early stopping.\n",
      "Best valid loss was 0.608409 at epoch 14.\n",
      "Loaded parameters to layer 'hidden0' (shape 300x500).\n",
      "Loaded parameters to layer 'hidden0' (shape 500).\n",
      "Loaded parameters to layer 'hidden1' (shape 500x160).\n",
      "Loaded parameters to layer 'hidden1' (shape 160).\n",
      "Loaded parameters to layer 'output' (shape 160x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 186672 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input        300\n",
      "  1  hidden0      400\n",
      "  2  dropout0     400\n",
      "  3  hidden1      150\n",
      "  4  dropout1     150\n",
      "  5  hidden2       40\n",
      "  6  output         2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m0.68233\u001b[0m       \u001b[32m0.65259\u001b[0m      1.04559      0.60880  2.82s\n",
      "      2       \u001b[36m0.65431\u001b[0m       \u001b[32m0.63663\u001b[0m      1.02776      0.61928  2.82s\n",
      "      3       \u001b[36m0.64125\u001b[0m       \u001b[32m0.62817\u001b[0m      1.02082      0.63396  2.79s\n",
      "      4       \u001b[36m0.63256\u001b[0m       \u001b[32m0.62235\u001b[0m      1.01641      0.64405  2.82s\n",
      "      5       \u001b[36m0.62824\u001b[0m       \u001b[32m0.62078\u001b[0m      1.01201      0.64653  2.80s\n",
      "      6       \u001b[36m0.62285\u001b[0m       \u001b[32m0.61894\u001b[0m      1.00632      0.64787  2.83s\n",
      "      7       \u001b[36m0.61858\u001b[0m       \u001b[32m0.61744\u001b[0m      1.00185      0.64996  2.85s\n",
      "      8       \u001b[36m0.61466\u001b[0m       0.61809      0.99444      0.65282  2.79s\n",
      "      9       \u001b[36m0.61298\u001b[0m       \u001b[32m0.61737\u001b[0m      0.99288      0.65187  2.83s\n",
      "     10       \u001b[36m0.61000\u001b[0m       \u001b[32m0.61714\u001b[0m      0.98843      0.65415  2.80s\n",
      "     11       \u001b[36m0.60793\u001b[0m       0.61814      0.98348      0.65568  2.88s\n",
      "     12       \u001b[36m0.60617\u001b[0m       \u001b[32m0.61630\u001b[0m      0.98356      0.65358  2.82s\n",
      "     13       \u001b[36m0.60359\u001b[0m       0.61697      0.97831      0.65454  2.80s\n",
      "     14       \u001b[36m0.60286\u001b[0m       0.61741      0.97644      0.65625  3.42s\n",
      "     15       \u001b[36m0.59809\u001b[0m       \u001b[32m0.61520\u001b[0m      0.97219      0.65911  2.83s\n",
      "     16       \u001b[36m0.59702\u001b[0m       \u001b[32m0.61516\u001b[0m      0.97051      0.65892  2.85s\n",
      "     17       \u001b[36m0.59507\u001b[0m       0.61529      0.96715      0.65911  2.85s\n",
      "     18       \u001b[36m0.59229\u001b[0m       \u001b[32m0.61413\u001b[0m      0.96444      0.66025  2.83s\n",
      "     19       \u001b[36m0.58818\u001b[0m       0.61439      0.95733      0.66082  2.84s\n",
      "     20       \u001b[36m0.58602\u001b[0m       0.61608      0.95120      0.66063  2.78s\n",
      "     21       \u001b[36m0.58243\u001b[0m       0.61476      0.94741      0.66349  2.79s\n",
      "     22       \u001b[36m0.58042\u001b[0m       \u001b[32m0.61400\u001b[0m      0.94531      0.66463  2.85s\n",
      "     23       \u001b[36m0.57920\u001b[0m       \u001b[32m0.61392\u001b[0m      0.94345      0.66330  2.78s\n",
      "     24       \u001b[36m0.57306\u001b[0m       0.61558      0.93092      0.65873  2.81s\n",
      "     25       \u001b[36m0.57085\u001b[0m       0.61544      0.92754      0.66120  2.81s\n",
      "     26       \u001b[36m0.56755\u001b[0m       \u001b[32m0.61342\u001b[0m      0.92523      0.66482  2.86s\n",
      "     27       \u001b[36m0.56229\u001b[0m       0.61563      0.91335      0.66559  2.80s\n",
      "     28       \u001b[36m0.55963\u001b[0m       0.61354      0.91212      0.66730  2.80s\n",
      "     29       \u001b[36m0.55575\u001b[0m       0.61559      0.90279      0.66463  2.79s\n",
      "     30       \u001b[36m0.54948\u001b[0m       0.61999      0.88628      0.66349  2.80s\n",
      "     31       \u001b[36m0.54276\u001b[0m       0.62233      0.87214      0.66578  2.80s\n",
      "     32       \u001b[36m0.53997\u001b[0m       0.61910      0.87219      0.66387  2.75s\n",
      "     33       \u001b[36m0.53388\u001b[0m       0.62152      0.85898      0.66578  2.79s\n",
      "     34       \u001b[36m0.52593\u001b[0m       0.62447      0.84220      0.66559  2.79s\n",
      "     35       \u001b[36m0.52412\u001b[0m       0.62559      0.83780      0.66673  2.82s\n",
      "     36       \u001b[36m0.51729\u001b[0m       0.63068      0.82021      0.66521  2.81s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:start loading the model\n",
      "INFO:gensim.utils:loading Doc2Vec object from /home/user/projekte/econstorModelling/cache/allDocs600D.model\n",
      "INFO:gensim.utils:loading docvecs recursively from /home/user/projekte/econstorModelling/cache/allDocs600D.model.docvecs.* with mmap=None\n",
      "INFO:gensim.utils:loading doctag_syn0 from /home/user/projekte/econstorModelling/cache/allDocs600D.model.docvecs.doctag_syn0.npy with mmap=None\n",
      "INFO:gensim.utils:loading syn1 from /home/user/projekte/econstorModelling/cache/allDocs600D.model.syn1.npy with mmap=None\n",
      "INFO:gensim.utils:loading syn0 from /home/user/projekte/econstorModelling/cache/allDocs600D.model.syn0.npy with mmap=None\n",
      "INFO:gensim.utils:setting ignored attribute syn0norm to None\n",
      "INFO:gensim.utils:setting ignored attribute cum_table to None\n",
      "INFO:root:loading completed\n",
      "INFO:root:building corpus...\n",
      "INFO:root:corpus complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping.\n",
      "Best valid loss was 0.613415 at epoch 26.\n",
      "Loaded parameters to layer 'hidden0' (shape 300x400).\n",
      "Loaded parameters to layer 'hidden0' (shape 400).\n",
      "Loaded parameters to layer 'hidden1' (shape 400x150).\n",
      "Loaded parameters to layer 'hidden1' (shape 150).\n",
      "Loaded parameters to layer 'hidden2' (shape 150x40).\n",
      "Loaded parameters to layer 'hidden2' (shape 40).\n",
      "Loaded parameters to layer 'output' (shape 40x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 60302 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name       size\n",
      "---  -------  ------\n",
      "  0  input       600\n",
      "  1  hidden0     100\n",
      "  2  output        2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m0.65563\u001b[0m       \u001b[32m0.61905\u001b[0m      1.05909      0.64844  0.66s\n",
      "      2       \u001b[36m0.61527\u001b[0m       \u001b[32m0.60395\u001b[0m      1.01874      0.66902  0.60s\n",
      "      3       \u001b[36m0.60283\u001b[0m       \u001b[32m0.60038\u001b[0m      1.00407      0.66597  0.61s\n",
      "      4       \u001b[36m0.59604\u001b[0m       \u001b[32m0.59946\u001b[0m      0.99429      0.66254  0.61s\n",
      "      5       \u001b[36m0.59074\u001b[0m       \u001b[32m0.59934\u001b[0m      0.98565      0.66387  0.60s\n",
      "      6       \u001b[36m0.58576\u001b[0m       0.59974      0.97669      0.66482  0.62s\n",
      "      7       \u001b[36m0.58056\u001b[0m       0.60003      0.96755      0.66616  0.60s\n",
      "      8       \u001b[36m0.57493\u001b[0m       0.60023      0.95785      0.66540  0.61s\n",
      "      9       \u001b[36m0.56869\u001b[0m       0.60065      0.94679      0.66635  0.61s\n",
      "     10       \u001b[36m0.56166\u001b[0m       0.60134      0.93400      0.66940  0.61s\n",
      "     11       \u001b[36m0.55381\u001b[0m       0.60269      0.91889      0.67188  0.62s\n",
      "     12       \u001b[36m0.54514\u001b[0m       0.60417      0.90230      0.66825  0.61s\n",
      "     13       \u001b[36m0.53558\u001b[0m       0.60605      0.88372      0.67168  0.62s\n",
      "     14       \u001b[36m0.52512\u001b[0m       0.60829      0.86327      0.66940  0.61s\n",
      "     15       \u001b[36m0.51381\u001b[0m       0.61096      0.84099      0.66806  0.59s\n",
      "Early stopping.\n",
      "Best valid loss was 0.599338 at epoch 5.\n",
      "Loaded parameters to layer 'hidden0' (shape 600x100).\n",
      "Loaded parameters to layer 'hidden0' (shape 100).\n",
      "Loaded parameters to layer 'output' (shape 100x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 180902 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name       size\n",
      "---  -------  ------\n",
      "  0  input       600\n",
      "  1  hidden0     300\n",
      "  2  output        2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m0.64743\u001b[0m       \u001b[32m0.61217\u001b[0m      1.05760      0.65053  1.79s\n",
      "      2       \u001b[36m0.60915\u001b[0m       \u001b[32m0.60067\u001b[0m      1.01411      0.66597  1.82s\n",
      "      3       \u001b[36m0.59730\u001b[0m       \u001b[32m0.59832\u001b[0m      0.99829      0.66806  1.82s\n",
      "      4       \u001b[36m0.58973\u001b[0m       \u001b[32m0.59752\u001b[0m      0.98696      0.66387  1.79s\n",
      "      5       \u001b[36m0.58295\u001b[0m       \u001b[32m0.59727\u001b[0m      0.97603      0.66406  1.79s\n",
      "      6       \u001b[36m0.57593\u001b[0m       \u001b[32m0.59711\u001b[0m      0.96452      0.66654  1.80s\n",
      "      7       \u001b[36m0.56824\u001b[0m       \u001b[32m0.59697\u001b[0m      0.95187      0.66864  1.81s\n",
      "      8       \u001b[36m0.55955\u001b[0m       \u001b[32m0.59676\u001b[0m      0.93764      0.67016  1.82s\n",
      "      9       \u001b[36m0.54956\u001b[0m       \u001b[32m0.59636\u001b[0m      0.92152      0.66902  1.80s\n",
      "     10       \u001b[36m0.53805\u001b[0m       \u001b[32m0.59605\u001b[0m      0.90269      0.67035  1.80s\n",
      "     11       \u001b[36m0.52488\u001b[0m       \u001b[32m0.59596\u001b[0m      0.88073      0.67340  1.77s\n",
      "     12       \u001b[36m0.51006\u001b[0m       0.59630      0.85537      0.67321  1.79s\n",
      "     13       \u001b[36m0.49357\u001b[0m       0.59697      0.82679      0.67168  1.80s\n",
      "     14       \u001b[36m0.47555\u001b[0m       0.59821      0.79496      0.67207  1.82s\n",
      "     15       \u001b[36m0.45626\u001b[0m       0.60014      0.76026      0.67111  1.77s\n",
      "     16       \u001b[36m0.43587\u001b[0m       0.60277      0.72310      0.66959  1.77s\n",
      "     17       \u001b[36m0.41467\u001b[0m       0.60630      0.68394      0.67168  1.78s\n",
      "     18       \u001b[36m0.39301\u001b[0m       0.61089      0.64334      0.67283  1.76s\n",
      "     19       \u001b[36m0.37108\u001b[0m       0.61590      0.60250      0.67340  1.84s\n",
      "     20       \u001b[36m0.34918\u001b[0m       0.62186      0.56150      0.67245  1.80s\n",
      "     21       \u001b[36m0.32759\u001b[0m       0.62887      0.52093      0.66997  1.76s\n",
      "Early stopping.\n",
      "Best valid loss was 0.595959 at epoch 11.\n",
      "Loaded parameters to layer 'hidden0' (shape 600x300).\n",
      "Loaded parameters to layer 'hidden0' (shape 300).\n",
      "Loaded parameters to layer 'output' (shape 300x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 170492 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input        600\n",
      "  1  hidden0      250\n",
      "  2  dropout0     250\n",
      "  3  hidden1       80\n",
      "  4  output         2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m0.66293\u001b[0m       \u001b[32m0.62162\u001b[0m      1.06645      0.64768  2.19s\n",
      "      2       \u001b[36m0.62490\u001b[0m       \u001b[32m0.60565\u001b[0m      1.03178      0.66044  2.18s\n",
      "      3       \u001b[36m0.61207\u001b[0m       \u001b[32m0.60041\u001b[0m      1.01942      0.66502  2.15s\n",
      "      4       \u001b[36m0.60339\u001b[0m       \u001b[32m0.59783\u001b[0m      1.00929      0.66806  2.18s\n",
      "      5       \u001b[36m0.59505\u001b[0m       \u001b[32m0.59579\u001b[0m      0.99875      0.66864  2.15s\n",
      "      6       \u001b[36m0.58921\u001b[0m       0.59655      0.98768      0.66864  2.17s\n",
      "      7       \u001b[36m0.58346\u001b[0m       \u001b[32m0.59525\u001b[0m      0.98019      0.67035  2.16s\n",
      "      8       \u001b[36m0.57622\u001b[0m       \u001b[32m0.59370\u001b[0m      0.97056      0.67188  2.14s\n",
      "      9       \u001b[36m0.57035\u001b[0m       0.59462      0.95918      0.67245  2.20s\n",
      "     10       \u001b[36m0.56030\u001b[0m       0.59670      0.93900      0.67397  2.18s\n",
      "     11       \u001b[36m0.55279\u001b[0m       0.59826      0.92400      0.67073  2.16s\n",
      "     12       \u001b[36m0.54227\u001b[0m       0.60067      0.90277      0.67035  2.25s\n",
      "     13       \u001b[36m0.53245\u001b[0m       0.60104      0.88588      0.67149  2.16s\n",
      "     14       \u001b[36m0.52209\u001b[0m       0.60548      0.86228      0.67073  2.18s\n",
      "     15       \u001b[36m0.50797\u001b[0m       0.60937      0.83360      0.67130  2.17s\n",
      "     16       \u001b[36m0.49536\u001b[0m       0.61372      0.80714      0.66921  2.21s\n",
      "     17       \u001b[36m0.47995\u001b[0m       0.62112      0.77272      0.67588  2.17s\n",
      "     18       \u001b[36m0.46235\u001b[0m       0.62900      0.73507      0.67168  2.16s\n",
      "Early stopping.\n",
      "Best valid loss was 0.593696 at epoch 8.\n",
      "Loaded parameters to layer 'hidden0' (shape 600x250).\n",
      "Loaded parameters to layer 'hidden0' (shape 250).\n",
      "Loaded parameters to layer 'hidden1' (shape 250x80).\n",
      "Loaded parameters to layer 'hidden1' (shape 80).\n",
      "Loaded parameters to layer 'output' (shape 80x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 380982 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input        600\n",
      "  1  hidden0      500\n",
      "  2  dropout0     500\n",
      "  3  hidden1      160\n",
      "  4  output         2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m0.65745\u001b[0m       \u001b[32m0.61375\u001b[0m      1.07120      0.65930  4.53s\n",
      "      2       \u001b[36m0.61912\u001b[0m       \u001b[32m0.59965\u001b[0m      1.03246      0.66692  4.50s\n",
      "      3       \u001b[36m0.60552\u001b[0m       \u001b[32m0.59597\u001b[0m      1.01603      0.67207  4.55s\n",
      "      4       \u001b[36m0.59651\u001b[0m       \u001b[32m0.59488\u001b[0m      1.00275      0.67188  4.52s\n",
      "      5       \u001b[36m0.58936\u001b[0m       \u001b[32m0.59454\u001b[0m      0.99129      0.67207  4.57s\n",
      "      6       \u001b[36m0.58182\u001b[0m       \u001b[32m0.59437\u001b[0m      0.97889      0.67321  4.54s\n",
      "      7       \u001b[36m0.57470\u001b[0m       0.59497      0.96593      0.66730  4.59s\n",
      "      8       \u001b[36m0.56411\u001b[0m       0.59598      0.94654      0.66864  4.57s\n",
      "      9       \u001b[36m0.55539\u001b[0m       0.59628      0.93141      0.67130  4.57s\n",
      "     10       \u001b[36m0.54111\u001b[0m       0.59779      0.90519      0.67397  4.53s\n",
      "     11       \u001b[36m0.52881\u001b[0m       0.59830      0.88385      0.67664  4.56s\n",
      "     12       \u001b[36m0.51066\u001b[0m       0.60518      0.84382      0.67092  4.59s\n",
      "     13       \u001b[36m0.49228\u001b[0m       0.60970      0.80742      0.67816  4.56s\n",
      "     14       \u001b[36m0.47149\u001b[0m       0.61942      0.76118      0.67092  4.52s\n",
      "     15       \u001b[36m0.44998\u001b[0m       0.62452      0.72053      0.67264  4.54s\n",
      "     16       \u001b[36m0.42545\u001b[0m       0.63925      0.66554      0.66997  4.50s\n",
      "Early stopping.\n",
      "Best valid loss was 0.594369 at epoch 6.\n",
      "Loaded parameters to layer 'hidden0' (shape 600x500).\n",
      "Loaded parameters to layer 'hidden0' (shape 500).\n",
      "Loaded parameters to layer 'hidden1' (shape 500x160).\n",
      "Loaded parameters to layer 'hidden1' (shape 160).\n",
      "Loaded parameters to layer 'output' (shape 160x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 306672 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input        600\n",
      "  1  hidden0      400\n",
      "  2  dropout0     400\n",
      "  3  hidden1      150\n",
      "  4  dropout1     150\n",
      "  5  hidden2       40\n",
      "  6  output         2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m0.67421\u001b[0m       \u001b[32m0.62548\u001b[0m      1.07791      0.64672  3.84s\n",
      "      2       \u001b[36m0.63554\u001b[0m       \u001b[32m0.60673\u001b[0m      1.04749      0.66368  3.92s\n",
      "      3       \u001b[36m0.62024\u001b[0m       \u001b[32m0.60032\u001b[0m      1.03319      0.66730  3.87s\n",
      "      4       \u001b[36m0.60923\u001b[0m       \u001b[32m0.59643\u001b[0m      1.02146      0.67073  3.92s\n",
      "      5       \u001b[36m0.60217\u001b[0m       \u001b[32m0.59616\u001b[0m      1.01009      0.67092  3.95s\n",
      "      6       \u001b[36m0.59586\u001b[0m       \u001b[32m0.59563\u001b[0m      1.00038      0.67188  3.93s\n",
      "      7       \u001b[36m0.59042\u001b[0m       \u001b[32m0.59448\u001b[0m      0.99316      0.67416  3.94s\n",
      "      8       \u001b[36m0.58330\u001b[0m       0.59621      0.97836      0.67607  3.92s\n",
      "      9       \u001b[36m0.57574\u001b[0m       0.59602      0.96598      0.67645  3.95s\n",
      "     10       \u001b[36m0.56724\u001b[0m       0.59657      0.95084      0.67721  3.90s\n",
      "     11       \u001b[36m0.56106\u001b[0m       0.59737      0.93922      0.67188  3.96s\n",
      "     12       \u001b[36m0.54786\u001b[0m       0.59920      0.91432      0.67016  3.93s\n",
      "     13       \u001b[36m0.53759\u001b[0m       0.60100      0.89449      0.67397  3.94s\n",
      "     14       \u001b[36m0.52642\u001b[0m       0.60398      0.87158      0.67607  3.95s\n",
      "     15       \u001b[36m0.51053\u001b[0m       0.61363      0.83199      0.67778  3.95s\n",
      "     16       \u001b[36m0.49432\u001b[0m       0.61630      0.80207      0.68064  3.90s\n",
      "     17       \u001b[36m0.47309\u001b[0m       0.62675      0.75483      0.67511  3.93s\n",
      "Early stopping.\n",
      "Best valid loss was 0.594479 at epoch 7.\n",
      "Loaded parameters to layer 'hidden0' (shape 600x400).\n",
      "Loaded parameters to layer 'hidden0' (shape 400).\n",
      "Loaded parameters to layer 'hidden1' (shape 400x150).\n",
      "Loaded parameters to layer 'hidden1' (shape 150).\n",
      "Loaded parameters to layer 'hidden2' (shape 150x40).\n",
      "Loaded parameters to layer 'hidden2' (shape 40).\n",
      "Loaded parameters to layer 'output' (shape 40x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 60302 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name       size\n",
      "---  -------  ------\n",
      "  0  input       600\n",
      "  1  hidden0     100\n",
      "  2  output        2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m0.64875\u001b[0m       \u001b[32m0.61327\u001b[0m      1.05785      0.65777  0.62s\n",
      "      2       \u001b[36m0.61053\u001b[0m       \u001b[32m0.60144\u001b[0m      1.01511      0.66787  0.60s\n",
      "      3       \u001b[36m0.59986\u001b[0m       \u001b[32m0.59904\u001b[0m      1.00137      0.66692  0.63s\n",
      "      4       \u001b[36m0.59365\u001b[0m       \u001b[32m0.59834\u001b[0m      0.99217      0.66635  0.61s\n",
      "      5       \u001b[36m0.58856\u001b[0m       \u001b[32m0.59813\u001b[0m      0.98400      0.66425  0.63s\n",
      "      6       \u001b[36m0.58352\u001b[0m       \u001b[32m0.59804\u001b[0m      0.97571      0.66197  0.63s\n",
      "      7       \u001b[36m0.57819\u001b[0m       \u001b[32m0.59792\u001b[0m      0.96701      0.66311  0.60s\n",
      "      8       \u001b[36m0.57231\u001b[0m       0.59800      0.95704      0.66311  0.63s\n",
      "      9       \u001b[36m0.56568\u001b[0m       0.59833      0.94543      0.66444  0.62s\n",
      "     10       \u001b[36m0.55827\u001b[0m       0.59876      0.93237      0.66349  0.61s\n",
      "     11       \u001b[36m0.54996\u001b[0m       0.59939      0.91754      0.66444  0.62s\n",
      "     12       \u001b[36m0.54072\u001b[0m       0.60009      0.90107      0.66406  0.60s\n",
      "     13       \u001b[36m0.53055\u001b[0m       0.60112      0.88261      0.66387  0.62s\n",
      "     14       \u001b[36m0.51943\u001b[0m       0.60268      0.86187      0.66387  0.61s\n",
      "     15       \u001b[36m0.50745\u001b[0m       0.60490      0.83891      0.66521  0.60s\n",
      "     16       \u001b[36m0.49468\u001b[0m       0.60796      0.81368      0.66444  0.61s\n",
      "     17       \u001b[36m0.48125\u001b[0m       0.61182      0.78657      0.66902  0.60s\n",
      "Early stopping.\n",
      "Best valid loss was 0.597922 at epoch 7.\n",
      "Loaded parameters to layer 'hidden0' (shape 600x100).\n",
      "Loaded parameters to layer 'hidden0' (shape 100).\n",
      "Loaded parameters to layer 'output' (shape 100x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 180902 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name       size\n",
      "---  -------  ------\n",
      "  0  input       600\n",
      "  1  hidden0     300\n",
      "  2  output        2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m0.64976\u001b[0m       \u001b[32m0.61538\u001b[0m      1.05586      0.65549  1.78s\n",
      "      2       \u001b[36m0.61066\u001b[0m       \u001b[32m0.60160\u001b[0m      1.01506      0.66387  1.75s\n",
      "      3       \u001b[36m0.59825\u001b[0m       \u001b[32m0.59865\u001b[0m      0.99932      0.66482  1.81s\n",
      "      4       \u001b[36m0.59072\u001b[0m       \u001b[32m0.59778\u001b[0m      0.98818      0.66425  1.71s\n",
      "      5       \u001b[36m0.58421\u001b[0m       \u001b[32m0.59746\u001b[0m      0.97783      0.66178  1.81s\n",
      "      6       \u001b[36m0.57765\u001b[0m       \u001b[32m0.59740\u001b[0m      0.96695      0.66349  1.73s\n",
      "      7       \u001b[36m0.57053\u001b[0m       \u001b[32m0.59738\u001b[0m      0.95504      0.66654  1.80s\n",
      "      8       \u001b[36m0.56249\u001b[0m       0.59745      0.94150      0.66806  1.72s\n",
      "      9       \u001b[36m0.55332\u001b[0m       0.59749      0.92608      0.66921  1.73s\n",
      "     10       \u001b[36m0.54281\u001b[0m       0.59760      0.90832      0.67111  1.73s\n",
      "     11       \u001b[36m0.53079\u001b[0m       0.59798      0.88764      0.66959  1.73s\n",
      "     12       \u001b[36m0.51717\u001b[0m       0.59853      0.86408      0.67035  1.72s\n",
      "     13       \u001b[36m0.50194\u001b[0m       0.59959      0.83714      0.67168  1.73s\n",
      "     14       \u001b[36m0.48521\u001b[0m       0.60144      0.80674      0.67340  1.72s\n",
      "     15       \u001b[36m0.46708\u001b[0m       0.60419      0.77308      0.67283  1.71s\n",
      "     16       \u001b[36m0.44780\u001b[0m       0.60797      0.73655      0.67473  1.73s\n",
      "     17       \u001b[36m0.42757\u001b[0m       0.61238      0.69821      0.67397  1.71s\n",
      "Early stopping.\n",
      "Best valid loss was 0.597383 at epoch 7.\n",
      "Loaded parameters to layer 'hidden0' (shape 600x300).\n",
      "Loaded parameters to layer 'hidden0' (shape 300).\n",
      "Loaded parameters to layer 'output' (shape 300x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 170492 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input        600\n",
      "  1  hidden0      250\n",
      "  2  dropout0     250\n",
      "  3  hidden1       80\n",
      "  4  output         2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m0.66879\u001b[0m       \u001b[32m0.63160\u001b[0m      1.05888      0.64272  2.14s\n",
      "      2       \u001b[36m0.63610\u001b[0m       \u001b[32m0.61592\u001b[0m      1.03276      0.65282  2.16s\n",
      "      3       \u001b[36m0.62119\u001b[0m       \u001b[32m0.60531\u001b[0m      1.02623      0.65415  2.15s\n",
      "      4       \u001b[36m0.61390\u001b[0m       \u001b[32m0.60310\u001b[0m      1.01790      0.65949  2.19s\n",
      "      5       \u001b[36m0.60757\u001b[0m       \u001b[32m0.60074\u001b[0m      1.01138      0.66082  2.14s\n",
      "      6       \u001b[36m0.60064\u001b[0m       \u001b[32m0.59987\u001b[0m      1.00128      0.66692  2.16s\n",
      "      7       \u001b[36m0.59662\u001b[0m       \u001b[32m0.59889\u001b[0m      0.99621      0.66825  2.11s\n",
      "      8       \u001b[36m0.59359\u001b[0m       \u001b[32m0.59863\u001b[0m      0.99159      0.67016  2.15s\n",
      "      9       \u001b[36m0.58739\u001b[0m       \u001b[32m0.59766\u001b[0m      0.98282      0.67073  2.14s\n",
      "     10       \u001b[36m0.58276\u001b[0m       \u001b[32m0.59761\u001b[0m      0.97515      0.67130  2.14s\n",
      "     11       \u001b[36m0.57827\u001b[0m       \u001b[32m0.59530\u001b[0m      0.97138      0.66730  2.18s\n",
      "     12       \u001b[36m0.57210\u001b[0m       0.59677      0.95866      0.67245  2.16s\n",
      "     13       \u001b[36m0.56621\u001b[0m       0.59740      0.94779      0.67283  2.14s\n",
      "     14       \u001b[36m0.56054\u001b[0m       0.59895      0.93587      0.67435  2.18s\n",
      "     15       \u001b[36m0.55410\u001b[0m       0.60047      0.92277      0.67149  2.18s\n",
      "     16       \u001b[36m0.54784\u001b[0m       0.59967      0.91357      0.67664  2.14s\n",
      "     17       \u001b[36m0.54170\u001b[0m       0.59905      0.90426      0.67854  2.13s\n",
      "     18       \u001b[36m0.53486\u001b[0m       0.60324      0.88664      0.67893  2.14s\n",
      "     19       \u001b[36m0.52522\u001b[0m       0.60608      0.86658      0.67454  2.17s\n",
      "     20       \u001b[36m0.51731\u001b[0m       0.60393      0.85657      0.67854  2.15s\n",
      "     21       \u001b[36m0.51106\u001b[0m       0.60805      0.84049      0.67893  2.14s\n",
      "Early stopping.\n",
      "Best valid loss was 0.595303 at epoch 11.\n",
      "Loaded parameters to layer 'hidden0' (shape 600x250).\n",
      "Loaded parameters to layer 'hidden0' (shape 250).\n",
      "Loaded parameters to layer 'hidden1' (shape 250x80).\n",
      "Loaded parameters to layer 'hidden1' (shape 80).\n",
      "Loaded parameters to layer 'output' (shape 80x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 380982 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input        600\n",
      "  1  hidden0      500\n",
      "  2  dropout0     500\n",
      "  3  hidden1      160\n",
      "  4  output         2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m0.66395\u001b[0m       \u001b[32m0.61958\u001b[0m      1.07162      0.64520  4.64s\n",
      "      2       \u001b[36m0.62841\u001b[0m       \u001b[32m0.60520\u001b[0m      1.03835      0.66025  5.06s\n",
      "      3       \u001b[36m0.61888\u001b[0m       \u001b[32m0.60077\u001b[0m      1.03015      0.66673  4.79s\n",
      "      4       \u001b[36m0.60760\u001b[0m       \u001b[32m0.59922\u001b[0m      1.01399      0.66883  4.74s\n",
      "      5       \u001b[36m0.60222\u001b[0m       \u001b[32m0.59651\u001b[0m      1.00957      0.67264  4.84s\n",
      "      6       \u001b[36m0.59545\u001b[0m       0.59826      0.99530      0.66902  4.67s\n",
      "      7       \u001b[36m0.59077\u001b[0m       0.59845      0.98717      0.67149  4.88s\n",
      "      8       \u001b[36m0.58613\u001b[0m       0.59756      0.98088      0.67130  4.84s\n",
      "      9       \u001b[36m0.57995\u001b[0m       \u001b[32m0.59631\u001b[0m      0.97256      0.67550  5.73s\n",
      "     10       \u001b[36m0.57415\u001b[0m       0.59713      0.96152      0.67378  6.35s\n",
      "     11       \u001b[36m0.57026\u001b[0m       \u001b[32m0.59602\u001b[0m      0.95678      0.67454  10.42s\n",
      "     12       \u001b[36m0.56228\u001b[0m       \u001b[32m0.59580\u001b[0m      0.94374      0.67511  6.42s\n",
      "     13       \u001b[36m0.55549\u001b[0m       0.59678      0.93082      0.67816  5.00s\n",
      "     14       \u001b[36m0.54745\u001b[0m       0.59733      0.91649      0.67797  7.10s\n",
      "     15       \u001b[36m0.53795\u001b[0m       0.60001      0.89657      0.67645  4.92s\n",
      "     16       \u001b[36m0.52744\u001b[0m       0.59965      0.87958      0.67873  4.83s\n",
      "     17       \u001b[36m0.51727\u001b[0m       0.60521      0.85470      0.67816  5.05s\n",
      "     18       \u001b[36m0.50459\u001b[0m       0.60767      0.83037      0.68083  4.74s\n",
      "     19       \u001b[36m0.49328\u001b[0m       0.61004      0.80861      0.67873  4.74s\n",
      "     20       \u001b[36m0.48197\u001b[0m       0.61172      0.78789      0.68102  4.61s\n",
      "     21       \u001b[36m0.46869\u001b[0m       0.62076      0.75502      0.67873  14.35s\n",
      "     22       \u001b[36m0.45465\u001b[0m       0.62325      0.72948      0.67912  6.65s\n",
      "Early stopping.\n",
      "Best valid loss was 0.595801 at epoch 12.\n",
      "Loaded parameters to layer 'hidden0' (shape 600x500).\n",
      "Loaded parameters to layer 'hidden0' (shape 500).\n",
      "Loaded parameters to layer 'hidden1' (shape 500x160).\n",
      "Loaded parameters to layer 'hidden1' (shape 160).\n",
      "Loaded parameters to layer 'output' (shape 160x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 306672 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input        600\n",
      "  1  hidden0      400\n",
      "  2  dropout0     400\n",
      "  3  hidden1      150\n",
      "  4  dropout1     150\n",
      "  5  hidden2       40\n",
      "  6  output         2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m0.68676\u001b[0m       \u001b[32m0.65873\u001b[0m      1.04254      0.61833  4.86s\n",
      "      2       \u001b[36m0.65576\u001b[0m       \u001b[32m0.62985\u001b[0m      1.04113      0.63643  4.75s\n",
      "      3       \u001b[36m0.63945\u001b[0m       \u001b[32m0.61866\u001b[0m      1.03360      0.64863  4.69s\n",
      "      4       \u001b[36m0.62828\u001b[0m       \u001b[32m0.61291\u001b[0m      1.02508      0.65587  4.82s\n",
      "      5       \u001b[36m0.61990\u001b[0m       \u001b[32m0.60874\u001b[0m      1.01835      0.66216  5.66s\n",
      "      6       \u001b[36m0.61620\u001b[0m       \u001b[32m0.60595\u001b[0m      1.01691      0.65816  5.89s\n",
      "      7       \u001b[36m0.61092\u001b[0m       0.60628      1.00765      0.65473  4.56s\n",
      "      8       \u001b[36m0.60587\u001b[0m       \u001b[32m0.60349\u001b[0m      1.00395      0.66311  6.05s\n",
      "      9       \u001b[36m0.60164\u001b[0m       \u001b[32m0.60314\u001b[0m      0.99751      0.66368  5.31s\n",
      "     10       \u001b[36m0.59691\u001b[0m       \u001b[32m0.60008\u001b[0m      0.99472      0.66635  8.68s\n",
      "     11       \u001b[36m0.59317\u001b[0m       0.60146      0.98621      0.66311  5.23s\n",
      "     12       \u001b[36m0.58875\u001b[0m       \u001b[32m0.59945\u001b[0m      0.98215      0.66540  7.98s\n",
      "     13       \u001b[36m0.58588\u001b[0m       \u001b[32m0.59917\u001b[0m      0.97782      0.66635  7.24s\n",
      "     14       \u001b[36m0.58265\u001b[0m       \u001b[32m0.59865\u001b[0m      0.97327      0.66806  7.60s\n",
      "     15       \u001b[36m0.57811\u001b[0m       \u001b[32m0.59849\u001b[0m      0.96595      0.66825  7.01s\n",
      "     16       \u001b[36m0.57113\u001b[0m       0.59892      0.95361      0.67035  7.03s\n",
      "     17       \u001b[36m0.56681\u001b[0m       \u001b[32m0.59797\u001b[0m      0.94789      0.66997  6.75s\n",
      "     18       \u001b[36m0.56294\u001b[0m       0.60108      0.93656      0.66787  8.21s\n",
      "     19       \u001b[36m0.55557\u001b[0m       0.60332      0.92086      0.67092  8.14s\n",
      "     20       \u001b[36m0.54978\u001b[0m       0.59918      0.91755      0.67130  6.60s\n",
      "     21       \u001b[36m0.54029\u001b[0m       0.60322      0.89567      0.67035  8.34s\n",
      "     22       \u001b[36m0.53217\u001b[0m       0.60037      0.88642      0.67588  6.55s\n",
      "     23       \u001b[36m0.52422\u001b[0m       0.60251      0.87007      0.67492  6.41s\n",
      "     24       \u001b[36m0.51266\u001b[0m       0.60737      0.84407      0.67283  6.81s\n",
      "     25       \u001b[36m0.50436\u001b[0m       0.60921      0.82790      0.67912  6.85s\n",
      "     26       \u001b[36m0.49031\u001b[0m       0.61276      0.80018      0.67950  6.75s\n",
      "     27       \u001b[36m0.47530\u001b[0m       0.62084      0.76558      0.68007  6.77s\n",
      "Early stopping.\n",
      "Best valid loss was 0.597971 at epoch 17.\n",
      "Loaded parameters to layer 'hidden0' (shape 600x400).\n",
      "Loaded parameters to layer 'hidden0' (shape 400).\n",
      "Loaded parameters to layer 'hidden1' (shape 400x150).\n",
      "Loaded parameters to layer 'hidden1' (shape 150).\n",
      "Loaded parameters to layer 'hidden2' (shape 150x40).\n",
      "Loaded parameters to layer 'hidden2' (shape 40).\n",
      "Loaded parameters to layer 'output' (shape 40x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n"
     ]
    }
   ],
   "source": [
    "# automated nn testing\n",
    "from collections import namedtuple\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "NNCandidate = namedtuple('NNCandidate', \\\n",
    "                         ['inputDim', 'dropout', 'arch', 'evalRes'])\n",
    "NNcandidatesPath = os.path.join('cache', 'NNcandidates')\n",
    "\n",
    "# predefined network architectures\n",
    "archs = ((100, 2), (300, 2), (250, 80, 2), (500, 160, 2), (400, 150, 40, 2))\n",
    "\n",
    "for inputDim in (100, 300, 600):\n",
    "    for dropout in (.4, .6):\n",
    "        for arch in archs:\n",
    "            net, trainTestData = genNN(inputDim=inputDim, arch=arch, dropout_p=dropout)\n",
    "            evalRes = evalPrediction(net, trainTestData)\n",
    "            candidate = NNCandidate(inputDim, dropout, arch, evalRes)\n",
    "            with open(NNcandidatesPath, str(inputDim) + str(dropout)\\\n",
    "                                   + str(arch) + '.pickle'), 'wb') as fh:\n",
    "                pickle.dump(candidate, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pick the best performing NN\n",
    "import os\n",
    "import pickle\n",
    "NNcandidatesPath = os.path.join('cache', 'NNcandidates')\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, p in enumerate(os.listdir(NNcandidatesPath)):\n",
    "    with open(os.path.join(NNcandidatesPath, p), 'rb') as fh:\n",
    "        candidate = pickle.load(fh)\n",
    "    results.append(candidate)\n",
    "    \n",
    "results = sorted(results, key=lambda x: x.evalRes.SuccRate)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualize the training progress\n",
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_loss = np.array([i[\"train_loss\"] for i in net.train_history_])\n",
    "valid_loss = np.array([i[\"valid_loss\"] for i in net.train_history_])\n",
    "\n",
    "marginFactor = 1.2\n",
    "train_min = min(train_loss)\n",
    "train_max = max(train_loss)\n",
    "valid_min = min(valid_loss)\n",
    "valid_max = max(valid_loss)\n",
    "y_min = min(train_min, valid_min)\n",
    "y_max = min(train_max, valid_max)\n",
    "\n",
    "plt.plot(train_loss, linewidth=3, label=\"train\")\n",
    "plt.plot(valid_loss, linewidth=3, label=\"valid\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.ylim(y_min * 1/marginFactor, y_max * marginFactor)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import manifold, datasets\n",
    "X_, color = datasets.samples_generator.make_s_curve(X_test.shape[0], random_state=0)\n",
    "\n",
    "tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
    "Y = tsne.fit_transform(X_test)\n",
    "plt.scatter(Y[:, 0], Y[:, 1], c=color, cmap=plt.cm.Spectral)\n",
    "plt.title(\"t-SNE\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
