{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where all things come together, where the actual classification task is carried out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define a logger\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early stopping\n",
    "\n",
    "A class that allows interruption of a NN's training process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EarlyStopping(object):\n",
    "    def __init__(self, patience=100):\n",
    "        self.patience = patience\n",
    "        self.best_valid = np.inf\n",
    "        self.best_valid_epoch = 0\n",
    "        self.best_weights = None\n",
    "\n",
    "    def __call__(self, nn, train_history):\n",
    "        current_valid = train_history[-1]['valid_loss']\n",
    "        current_epoch = train_history[-1]['epoch']\n",
    "        if current_valid < self.best_valid:\n",
    "            self.best_valid = current_valid\n",
    "            self.best_valid_epoch = current_epoch\n",
    "            self.best_weights = nn.get_all_params_values()\n",
    "        elif self.best_valid_epoch + self.patience < current_epoch:\n",
    "            print(\"Early stopping.\")\n",
    "            print(\"Best valid loss was {:.6f} at epoch {}.\".format(\n",
    "                self.best_valid, self.best_valid_epoch))\n",
    "            nn.load_params_from(self.best_weights)\n",
    "            raise StopIteration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read model from disk\n",
    "\n",
    "Assumes files are in a subdir called `cache`. Conventions for the files is `allDocs<DIM>D.model`, where `DIM` is\n",
    "the dimensionality of the embedding. `DIM` is determined by the parameter `dim`. 600 is the default dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:Pattern library is not installed, lemmatization won't be available.\n",
      "INFO:summa.preprocessing.cleaner:'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "# Read model from disk\n",
    "from gensim.models import Doc2Vec\n",
    "import os\n",
    "\n",
    "def loadModel(dim=600):\n",
    "    if(dim not in (100, 300, 600)):\n",
    "        raise ValueError('dim must be 100, 300 or 600')\n",
    "        \n",
    "    modelName = 'allDocs' + str(dim) + 'D.model'\n",
    "    modelBasePath = 'cache'\n",
    "    modelPath = os.path.join(os.getcwd(), modelBasePath, modelName)\n",
    "\n",
    "    logging.info('start loading the model')\n",
    "    model = Doc2Vec.load(modelPath)\n",
    "    logging.info('loading completed')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile corpus\n",
    "\n",
    "Returns corpus prepared in a way appropriate for gensim/scipy models to fit to. \n",
    "The first element of the tuple returned is a matrix of numpy integers representing the doc embedding.\n",
    "The second elements indicates whether a document was cited at all. If `regression` is set to `True` it will be represented by either `[0,1]` (was not cited) or `[1,0]` (was cited). Otherwise it is `0` and `1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "The try-except blocks take care of initializing the variables appropriately.\n",
    "If they are non-existing, they are being initialized with the empty dict.\n",
    "If they exist, they remain untouched. The reason for this is, that they may contain data\n",
    "that was read from disk, which takes a while. \n",
    "The variables ought to contain either the large objects just described of the empty dict.\n",
    "This is convenient when itegation over the data several times.\n",
    "'''\n",
    "try:\n",
    "    model\n",
    "except NameError:\n",
    "    model = {}\n",
    "\n",
    "try:\n",
    "    X\n",
    "    y\n",
    "except NameError:\n",
    "    X, y = {}, {}\n",
    "\n",
    "def loadData(model=None, regression=False):\n",
    "    JSONFILESDIR = 'data/json'\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    if regression:\n",
    "        zero = np.array([0,1], dtype=np.int32)\n",
    "        one = np.array([1,0], dtype=np.int32)\n",
    "    else:\n",
    "        zero = np.int32(0)\n",
    "        one = np.int32(1)\n",
    "\n",
    "    logging.info('building corpus...')\n",
    "    filenames = model.docvecs.doctags.keys()\n",
    "    for k in tqdm(filenames):\n",
    "        with open(os.path.join(JSONFILESDIR, k + '.json')) as fh:\n",
    "            jsonFile = json.load(fh)\n",
    "\n",
    "        if jsonFile['lang'] != 'en' or jsonFile['citedBy'] is None:\n",
    "            logging.debug('{f} discarded from corpus.'.format(f=k))\n",
    "            continue\n",
    "\n",
    "        X.append(model.docvecs[k])\n",
    "        isSuccessfull = one if int(jsonFile['citedBy']) > 0 else zero\n",
    "        y.append(isSuccessfull)\n",
    "        logging.debug('{f} absorbed into corpus.'.format(f=k))\n",
    "\n",
    "    # transform to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    logging.info('corpus complete')\n",
    "    return X, y\n",
    "\n",
    "# This wrapper prevents the data from being loaded again, in case they are\n",
    "# already in place\n",
    "def loadXy(inputDim = 600, regression=False):\n",
    "    # get the persisted model, including the training\n",
    "    # data associated with it. check if already loaded\n",
    "    global model\n",
    "    global X, y\n",
    "    # if currently loaded data doesn't match the requested dimensionality\n",
    "    if type(X) == np.ndarray and X.shape[1] != inputDim:\n",
    "        model, X, y = {}, {}, {}\n",
    "    if model == {}:\n",
    "        model = loadModel(inputDim)\n",
    "    \n",
    "    # give the data in a convenient format\n",
    "    if any([type(X) != np.ndarray, type(y) != np.ndarray]):\n",
    "        X, y = loadData(model=model, regression=regression)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neuronal network factory\n",
    "\n",
    "`loadNN` return neuronal networks in the configuration that is passed to it.\n",
    "\n",
    "In a OOP environment `makeLayers` and `makeParameters` were private methods, only used internally. Here, only `loadNN` needs to use them. They are not supposed to be used by users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/projekte/anaconda3/envs/ipynb/lib/python3.5/site-packages/theano/tensor/signal/downsample.py:5: UserWarning: downsample module has been moved to the pool module.\n",
      "  warnings.warn(\"downsample module has been moved to the pool module.\")\n"
     ]
    }
   ],
   "source": [
    "# classifying neural net\n",
    "from lasagne import layers\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from lasagne.nonlinearities import rectify, tanh, softmax, sigmoid\n",
    "\n",
    "def makeLayers(depth=3):\n",
    "    yield ('input', layers.InputLayer)\n",
    "    yield ('hidden0', layers.DenseLayer)\n",
    "    for i in range(1, depth - 2):\n",
    "        yield ('dropout' + str(i-1), layers.DropoutLayer)\n",
    "        yield ('hidden' + str(i), layers.DenseLayer)\n",
    "    yield ('output', layers.DenseLayer)\n",
    "    \n",
    "def makeParameters(arch, dropout_p, nonlinearity):\n",
    "    if len(arch) < 3:\n",
    "        raise ValueError(\"The network must be at least 3 layers deep\")\n",
    "    depth = len(arch)\n",
    "    params = {}\n",
    "    \n",
    "    # the static ones\n",
    "    exec('params[\"{}\"] = ({}, {})'.format('input_shape', \"None\", arch[0]))\n",
    "    exec('params[\"{}\"] = {}'.format('hidden0_num_units', arch[1]))\n",
    "    for i in range(1, depth - 2):\n",
    "        exec('params[\"{}\"] = {}'.format('dropout' + str(i-1) + '_p', dropout_p))\n",
    "        exec('params[\"{}\"] = {}'.format('hidden' + str(i) + '_num_units', arch[i+1]))\n",
    "    \n",
    "    # again some statics ones\n",
    "    exec('params[\"{}\"] = {}'.format('output_num_units', arch[-1]))\n",
    "    exec('params[\"{}\"] = {}'.format('output_nonlinearity', nonlinearity))\n",
    "    return params\n",
    "\n",
    "def loadNN(arch=(100, 400, 160, 2), dropout_p=0.6, epochs=50,\\\n",
    "           nonlinearity=None, regression=False, evalSize=.1):\n",
    "    if not regression and nonlinearity != 'softmax':\n",
    "        nonlinearity = 'softmax'\n",
    "        logging.info(\"nonlinearity was set to 'softmax'. This is\\\n",
    "            the only non-linearity supported by classification\")\n",
    "        \n",
    "    return NeuralNet(\n",
    "        # configuration\n",
    "        layers=[x for x in makeLayers(len(arch))],\n",
    "        **makeParameters(arch, dropout_p, nonlinearity),\n",
    "        \n",
    "        # optimization method:\n",
    "        update=nesterov_momentum,\n",
    "        update_learning_rate=0.01,\n",
    "        update_momentum=0.9,\n",
    "\n",
    "        regression=regression,\n",
    "        max_epochs=epochs,\n",
    "        eval_size=evalSize,\n",
    "        verbose=1,\n",
    "        on_epoch_finished=[EarlyStopping(patience=10)]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Classifier and fit them to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "\n",
    "TrainTestData = namedtuple(\"TrainTest\", [\"X_train\",\"X_test\",\"y_train\",\"y_test\"])\n",
    "\n",
    "\n",
    "# Generate an SVM classifier\n",
    "def genSVMclf(inputDim=600, evalSize=.1):\n",
    "    clf = svm.SVC()\n",
    "    X, y = loadXy(inputDim=inputDim, regression=False)\n",
    "    # carry out train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split( \\\n",
    "        X, y, test_size=evalSize, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf, TrainTestData(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Generate an KNN classifier\n",
    "def genKNNclf(inputDim, evalSize=.1):\n",
    "    clf = NearestCentroid()\n",
    "    X, y = loadXy(inputDim=inputDim, regression=False)\n",
    "    # carry out train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split( \\\n",
    "        X, y, test_size=evalSize, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf, TrainTestData(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Generate an NN classifier\n",
    "def genNNclf(inputDim=600, regression=False, arch=(400, 160, 2), \\\n",
    "            dropout_p=.6, epochs=100, nonlinearity='softmax', \\\n",
    "            evalSize=.1):\n",
    "\n",
    "    X, y = loadXy(inputDim=inputDim, regression=regression)\n",
    "    # add input layer to NN's arch\n",
    "    myArch = list(arch)\n",
    "    myArch.insert(0, inputDim)\n",
    "    \n",
    "    # instanciate the network\n",
    "    net = loadNN(arch=myArch, dropout_p=dropout_p, epochs=epochs, \\\n",
    "                 nonlinearity=nonlinearity, regression=regression,\n",
    "                 evalSize=evalSize)\n",
    "    # carry out train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split( \\\n",
    "        X, y, test_size=evalSize, random_state=42)\n",
    "    \n",
    "    # train the network\n",
    "    net.fit(X_train, y_train)\n",
    "    \n",
    "    return net, TrainTestData(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NNCandidate = namedtuple('NNCandidate', \\\n",
    "                         ['inputDim', 'dropout', 'arch', 'evalRes'])\n",
    "EvalResults = namedtuple('EvalResults', ['All','Pos','Neg', 'SuccRate', \n",
    "                         'TrainLoss', 'ValidLoss'])\n",
    "NNcandidatesPath = os.path.join('cache', 'NNcandidates')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the results\n",
    "\n",
    "Evaluates the performance of a classifier (requires the `predict` method) using test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from nolearn.lasagne import NeuralNet\n",
    "\n",
    "def evalPrediction(clf, trainTestData, regression=False):\n",
    "    # predict the test set\n",
    "    predictions = clf.predict(trainTestData.X_test)\n",
    "    predictions = predictions.round().astype(np.int32)\n",
    "    \n",
    "    # dealing with the different data representations \n",
    "    # of regression vs classification\n",
    "    if regression:\n",
    "        truthMatrix = trainTestData.y_test[:, 0] == predictions[:, 0]\n",
    "        positiveTestCases = trainTestData.y_test[:, 0].sum()\n",
    "    else:\n",
    "        truthMatrix = trainTestData.y_test == predictions\n",
    "        positiveTestCases = trainTestData.y_test.sum()\n",
    "\n",
    "    testSize = truthMatrix.shape[0]\n",
    "    correct = truthMatrix.sum()\n",
    "    false = testSize - truthMatrix.sum()\n",
    "    if isinstance(clf, NeuralNet):\n",
    "        train_loss = np.array([i[\"train_loss\"] for i in net.train_history_])\n",
    "        valid_loss = np.array([i[\"valid_loss\"] for i in net.train_history_])\n",
    "    else:\n",
    "        train_loss = \"\"\n",
    "        valid_loss = \"\"\n",
    "    \n",
    "    return EvalResults(testSize, correct, false, correct/float(testSize),\\\n",
    "                       train_loss, valid_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Hyperspace parameter evaluation\n",
    "\n",
    "Findes the best performing parameters for the NN classifier using brute-force and pickles the results for later inspection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:start loading the model\n",
      "INFO:gensim.utils:loading Doc2Vec object from /home/user/projekte/econstorModelling/cache/allDocs100D.model\n",
      "INFO:gensim.utils:loading docvecs recursively from /home/user/projekte/econstorModelling/cache/allDocs100D.model.docvecs.* with mmap=None\n",
      "INFO:gensim.utils:loading syn0 from /home/user/projekte/econstorModelling/cache/allDocs100D.model.syn0.npy with mmap=None\n",
      "INFO:gensim.utils:loading syn1 from /home/user/projekte/econstorModelling/cache/allDocs100D.model.syn1.npy with mmap=None\n",
      "INFO:gensim.utils:setting ignored attribute syn0norm to None\n",
      "INFO:gensim.utils:setting ignored attribute cum_table to None\n",
      "INFO:root:loading completed\n",
      "INFO:root:building corpus...\n",
      "INFO:root:corpus complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 10302 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name       size\n",
      "---  -------  ------\n",
      "  0  input       100\n",
      "  1  hidden0     100\n",
      "  2  output        2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.23686\u001b[0m       \u001b[32m0.22693\u001b[0m      1.04375  0.30s\n",
      "      2       \u001b[36m0.22369\u001b[0m       \u001b[32m0.22040\u001b[0m      1.01491  0.22s\n",
      "      3       \u001b[36m0.21963\u001b[0m       \u001b[32m0.21772\u001b[0m      1.00877  0.25s\n",
      "      4       \u001b[36m0.21771\u001b[0m       \u001b[32m0.21650\u001b[0m      1.00559  0.25s\n",
      "      5       \u001b[36m0.21658\u001b[0m       \u001b[32m0.21581\u001b[0m      1.00357  0.23s\n",
      "      6       \u001b[36m0.21576\u001b[0m       \u001b[32m0.21532\u001b[0m      1.00204  0.22s\n",
      "      7       \u001b[36m0.21507\u001b[0m       \u001b[32m0.21493\u001b[0m      1.00066  0.26s\n",
      "      8       \u001b[36m0.21444\u001b[0m       \u001b[32m0.21460\u001b[0m      0.99925  0.22s\n",
      "      9       \u001b[36m0.21385\u001b[0m       \u001b[32m0.21434\u001b[0m      0.99768  0.21s\n",
      "     10       \u001b[36m0.21327\u001b[0m       \u001b[32m0.21408\u001b[0m      0.99623  0.22s\n",
      "     11       \u001b[36m0.21270\u001b[0m       \u001b[32m0.21382\u001b[0m      0.99477  0.21s\n",
      "     12       \u001b[36m0.21214\u001b[0m       \u001b[32m0.21358\u001b[0m      0.99328  0.21s\n",
      "     13       \u001b[36m0.21158\u001b[0m       \u001b[32m0.21336\u001b[0m      0.99165  0.24s\n",
      "     14       \u001b[36m0.21101\u001b[0m       \u001b[32m0.21315\u001b[0m      0.98998  0.21s\n",
      "     15       \u001b[36m0.21044\u001b[0m       \u001b[32m0.21294\u001b[0m      0.98826  0.22s\n",
      "     16       \u001b[36m0.20987\u001b[0m       \u001b[32m0.21277\u001b[0m      0.98635  0.27s\n",
      "     17       \u001b[36m0.20930\u001b[0m       \u001b[32m0.21262\u001b[0m      0.98439  0.25s\n",
      "     18       \u001b[36m0.20872\u001b[0m       \u001b[32m0.21245\u001b[0m      0.98243  0.25s\n",
      "     19       \u001b[36m0.20814\u001b[0m       \u001b[32m0.21230\u001b[0m      0.98042  0.24s\n",
      "     20       \u001b[36m0.20757\u001b[0m       \u001b[32m0.21218\u001b[0m      0.97825  0.23s\n",
      "     21       \u001b[36m0.20699\u001b[0m       \u001b[32m0.21208\u001b[0m      0.97604  0.24s\n",
      "     22       \u001b[36m0.20642\u001b[0m       \u001b[32m0.21200\u001b[0m      0.97368  0.22s\n",
      "     23       \u001b[36m0.20585\u001b[0m       \u001b[32m0.21196\u001b[0m      0.97119  0.22s\n",
      "     24       \u001b[36m0.20528\u001b[0m       \u001b[32m0.21192\u001b[0m      0.96867  0.35s\n",
      "     25       \u001b[36m0.20471\u001b[0m       \u001b[32m0.21188\u001b[0m      0.96613  0.25s\n",
      "     26       \u001b[36m0.20413\u001b[0m       \u001b[32m0.21182\u001b[0m      0.96370  0.26s\n",
      "     27       \u001b[36m0.20356\u001b[0m       \u001b[32m0.21176\u001b[0m      0.96128  0.21s\n",
      "     28       \u001b[36m0.20299\u001b[0m       \u001b[32m0.21174\u001b[0m      0.95869  0.23s\n",
      "     29       \u001b[36m0.20242\u001b[0m       \u001b[32m0.21171\u001b[0m      0.95612  0.22s\n",
      "     30       \u001b[36m0.20185\u001b[0m       \u001b[32m0.21170\u001b[0m      0.95349  0.22s\n",
      "     31       \u001b[36m0.20129\u001b[0m       0.21171      0.95080  0.22s\n",
      "     32       \u001b[36m0.20074\u001b[0m       0.21172      0.94812  0.21s\n",
      "     33       \u001b[36m0.20018\u001b[0m       0.21176      0.94534  0.22s\n",
      "     34       \u001b[36m0.19964\u001b[0m       0.21181      0.94254  0.21s\n",
      "     35       \u001b[36m0.19909\u001b[0m       0.21186      0.93973  0.21s\n",
      "     36       \u001b[36m0.19855\u001b[0m       0.21194      0.93681  0.22s\n",
      "     37       \u001b[36m0.19800\u001b[0m       0.21205      0.93374  0.22s\n",
      "     38       \u001b[36m0.19745\u001b[0m       0.21217      0.93063  0.22s\n",
      "     39       \u001b[36m0.19691\u001b[0m       0.21229      0.92759  0.21s\n",
      "     40       \u001b[36m0.19638\u001b[0m       0.21239      0.92461  0.22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/projekte/anaconda3/envs/ipynb/lib/python3.5/site-packages/nolearn/lasagne/base.py:250: UserWarning: The 'eval_size' argument has been deprecated, please use the 'train_split' parameter instead, e.g.\n",
      "train_split=TrainSplit(eval_size=0.4)\n",
      "  warn(\"The 'eval_size' argument has been deprecated, please use \"\n",
      "/home/user/projekte/anaconda3/envs/ipynb/lib/python3.5/site-packages/nolearn/lasagne/base.py:250: UserWarning: The 'eval_size' argument has been deprecated, please use the 'train_split' parameter instead, e.g.\n",
      "train_split=TrainSplit(eval_size=0.4)\n",
      "  warn(\"The 'eval_size' argument has been deprecated, please use \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping.\n",
      "Best valid loss was 0.211700 at epoch 30.\n",
      "Loaded parameters to layer 'hidden0' (shape 100x100).\n",
      "Loaded parameters to layer 'hidden0' (shape 100).\n",
      "Loaded parameters to layer 'output' (shape 100x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 30902 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name       size\n",
      "---  -------  ------\n",
      "  0  input       100\n",
      "  1  hidden0     300\n",
      "  2  output        2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.23349\u001b[0m       \u001b[32m0.22219\u001b[0m      1.05086  0.54s\n",
      "      2       \u001b[36m0.22158\u001b[0m       \u001b[32m0.21701\u001b[0m      1.02109  0.64s\n",
      "      3       \u001b[36m0.21819\u001b[0m       \u001b[32m0.21519\u001b[0m      1.01392  0.54s\n",
      "      4       \u001b[36m0.21658\u001b[0m       \u001b[32m0.21439\u001b[0m      1.01020  0.57s\n",
      "      5       \u001b[36m0.21551\u001b[0m       \u001b[32m0.21390\u001b[0m      1.00750  0.57s\n",
      "      6       \u001b[36m0.21463\u001b[0m       \u001b[32m0.21353\u001b[0m      1.00516  0.55s\n",
      "      7       \u001b[36m0.21383\u001b[0m       \u001b[32m0.21320\u001b[0m      1.00294  0.55s\n",
      "      8       \u001b[36m0.21307\u001b[0m       \u001b[32m0.21289\u001b[0m      1.00085  0.55s\n",
      "      9       \u001b[36m0.21232\u001b[0m       \u001b[32m0.21260\u001b[0m      0.99869  0.57s\n",
      "     10       \u001b[36m0.21158\u001b[0m       \u001b[32m0.21233\u001b[0m      0.99647  0.57s\n",
      "     11       \u001b[36m0.21083\u001b[0m       \u001b[32m0.21207\u001b[0m      0.99414  0.62s\n",
      "     12       \u001b[36m0.21007\u001b[0m       \u001b[32m0.21182\u001b[0m      0.99173  0.62s\n",
      "     13       \u001b[36m0.20931\u001b[0m       \u001b[32m0.21159\u001b[0m      0.98922  0.55s\n",
      "     14       \u001b[36m0.20854\u001b[0m       \u001b[32m0.21138\u001b[0m      0.98656  0.53s\n",
      "     15       \u001b[36m0.20777\u001b[0m       \u001b[32m0.21119\u001b[0m      0.98378  0.56s\n",
      "     16       \u001b[36m0.20698\u001b[0m       \u001b[32m0.21102\u001b[0m      0.98085  0.56s\n",
      "     17       \u001b[36m0.20619\u001b[0m       \u001b[32m0.21086\u001b[0m      0.97784  0.55s\n",
      "     18       \u001b[36m0.20540\u001b[0m       \u001b[32m0.21073\u001b[0m      0.97470  0.57s\n",
      "     19       \u001b[36m0.20460\u001b[0m       \u001b[32m0.21060\u001b[0m      0.97149  0.55s\n",
      "     20       \u001b[36m0.20380\u001b[0m       \u001b[32m0.21051\u001b[0m      0.96810  0.58s\n",
      "     21       \u001b[36m0.20300\u001b[0m       \u001b[32m0.21044\u001b[0m      0.96462  0.64s\n",
      "     22       \u001b[36m0.20220\u001b[0m       \u001b[32m0.21039\u001b[0m      0.96107  0.53s\n",
      "     23       \u001b[36m0.20140\u001b[0m       \u001b[32m0.21036\u001b[0m      0.95740  0.54s\n",
      "     24       \u001b[36m0.20059\u001b[0m       0.21036      0.95358  0.54s\n",
      "     25       \u001b[36m0.19980\u001b[0m       0.21037      0.94973  0.92s\n",
      "     26       \u001b[36m0.19900\u001b[0m       0.21039      0.94587  0.57s\n",
      "     27       \u001b[36m0.19821\u001b[0m       0.21043      0.94193  0.54s\n",
      "     28       \u001b[36m0.19741\u001b[0m       0.21047      0.93795  0.54s\n",
      "     29       \u001b[36m0.19663\u001b[0m       0.21055      0.93387  0.53s\n",
      "     30       \u001b[36m0.19584\u001b[0m       0.21064      0.92978  0.66s\n",
      "     31       \u001b[36m0.19507\u001b[0m       0.21073      0.92565  0.55s\n",
      "     32       \u001b[36m0.19429\u001b[0m       0.21083      0.92154  0.56s\n",
      "     33       \u001b[36m0.19351\u001b[0m       0.21094      0.91738  0.63s\n",
      "Early stopping.\n",
      "Best valid loss was 0.210357 at epoch 23.\n",
      "Loaded parameters to layer 'hidden0' (shape 100x300).\n",
      "Loaded parameters to layer 'hidden0' (shape 300).\n",
      "Loaded parameters to layer 'output' (shape 300x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 45492 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input        100\n",
      "  1  hidden0      250\n",
      "  2  dropout0     250\n",
      "  3  hidden1       80\n",
      "  4  output         2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.23558\u001b[0m       \u001b[32m0.22240\u001b[0m      1.05927  1.20s\n",
      "      2       \u001b[36m0.22525\u001b[0m       \u001b[32m0.21726\u001b[0m      1.03678  1.32s\n",
      "      3       \u001b[36m0.22256\u001b[0m       \u001b[32m0.21549\u001b[0m      1.03280  1.23s\n",
      "      4       \u001b[36m0.22076\u001b[0m       \u001b[32m0.21446\u001b[0m      1.02935  1.20s\n",
      "      5       \u001b[36m0.21985\u001b[0m       \u001b[32m0.21383\u001b[0m      1.02812  1.12s\n",
      "      6       \u001b[36m0.21875\u001b[0m       \u001b[32m0.21343\u001b[0m      1.02493  1.18s\n",
      "      7       \u001b[36m0.21757\u001b[0m       \u001b[32m0.21299\u001b[0m      1.02150  1.25s\n",
      "      8       \u001b[36m0.21724\u001b[0m       \u001b[32m0.21268\u001b[0m      1.02144  1.21s\n",
      "      9       \u001b[36m0.21686\u001b[0m       \u001b[32m0.21246\u001b[0m      1.02071  1.19s\n",
      "     10       \u001b[36m0.21603\u001b[0m       \u001b[32m0.21225\u001b[0m      1.01783  1.21s\n",
      "     11       \u001b[36m0.21545\u001b[0m       \u001b[32m0.21188\u001b[0m      1.01685  1.33s\n",
      "     12       \u001b[36m0.21464\u001b[0m       \u001b[32m0.21161\u001b[0m      1.01435  1.18s\n",
      "     13       \u001b[36m0.21437\u001b[0m       0.21162      1.01295  1.29s\n",
      "     14       \u001b[36m0.21352\u001b[0m       \u001b[32m0.21142\u001b[0m      1.00990  1.22s\n",
      "     15       \u001b[36m0.21304\u001b[0m       \u001b[32m0.21123\u001b[0m      1.00859  1.17s\n",
      "     16       0.21306       \u001b[32m0.21107\u001b[0m      1.00942  1.21s\n",
      "     17       \u001b[36m0.21249\u001b[0m       \u001b[32m0.21090\u001b[0m      1.00756  1.14s\n",
      "     18       \u001b[36m0.21171\u001b[0m       \u001b[32m0.21087\u001b[0m      1.00398  1.26s\n",
      "     19       0.21199       \u001b[32m0.21073\u001b[0m      1.00599  1.33s\n",
      "     20       \u001b[36m0.21089\u001b[0m       \u001b[32m0.21052\u001b[0m      1.00174  1.32s\n",
      "     21       \u001b[36m0.21082\u001b[0m       \u001b[32m0.21050\u001b[0m      1.00154  1.51s\n",
      "     22       \u001b[36m0.21035\u001b[0m       \u001b[32m0.21035\u001b[0m      1.00000  1.14s\n",
      "     23       \u001b[36m0.21019\u001b[0m       \u001b[32m0.21021\u001b[0m      0.99989  1.18s\n",
      "     24       \u001b[36m0.20897\u001b[0m       \u001b[32m0.21011\u001b[0m      0.99458  1.26s\n",
      "     25       \u001b[36m0.20833\u001b[0m       \u001b[32m0.20998\u001b[0m      0.99214  1.38s\n",
      "     26       \u001b[36m0.20811\u001b[0m       0.21009      0.99056  1.13s\n",
      "     27       \u001b[36m0.20799\u001b[0m       0.21016      0.98964  1.15s\n",
      "     28       \u001b[36m0.20759\u001b[0m       \u001b[32m0.20987\u001b[0m      0.98913  1.14s\n",
      "     29       \u001b[36m0.20700\u001b[0m       \u001b[32m0.20975\u001b[0m      0.98688  1.20s\n",
      "     30       \u001b[36m0.20670\u001b[0m       \u001b[32m0.20964\u001b[0m      0.98597  1.15s\n",
      "     31       \u001b[36m0.20614\u001b[0m       \u001b[32m0.20952\u001b[0m      0.98385  1.16s\n",
      "     32       \u001b[36m0.20590\u001b[0m       0.20955      0.98261  1.17s\n",
      "     33       \u001b[36m0.20543\u001b[0m       \u001b[32m0.20940\u001b[0m      0.98104  1.37s\n",
      "     34       \u001b[36m0.20519\u001b[0m       \u001b[32m0.20930\u001b[0m      0.98037  1.19s\n",
      "     35       \u001b[36m0.20447\u001b[0m       0.20933      0.97680  1.17s\n",
      "     36       0.20487       0.20945      0.97816  1.11s\n",
      "     37       \u001b[36m0.20373\u001b[0m       0.20946      0.97262  1.15s\n",
      "     38       \u001b[36m0.20338\u001b[0m       \u001b[32m0.20926\u001b[0m      0.97189  1.27s\n",
      "     39       0.20351       \u001b[32m0.20908\u001b[0m      0.97335  1.13s\n",
      "     40       \u001b[36m0.20300\u001b[0m       \u001b[32m0.20905\u001b[0m      0.97108  1.15s\n",
      "     41       \u001b[36m0.20196\u001b[0m       0.20913      0.96571  1.13s\n",
      "     42       0.20222       0.20908      0.96720  1.15s\n",
      "     43       \u001b[36m0.20164\u001b[0m       0.20909      0.96436  1.27s\n",
      "     44       \u001b[36m0.20058\u001b[0m       \u001b[32m0.20894\u001b[0m      0.96001  1.19s\n",
      "     45       0.20060       0.20895      0.96003  1.27s\n",
      "     46       \u001b[36m0.20044\u001b[0m       0.20896      0.95923  1.19s\n",
      "     47       \u001b[36m0.20033\u001b[0m       0.20925      0.95736  1.67s\n",
      "     48       \u001b[36m0.19906\u001b[0m       0.20901      0.95237  1.24s\n",
      "     49       \u001b[36m0.19877\u001b[0m       0.20897      0.95116  1.15s\n",
      "     50       0.19906       0.20896      0.95263  1.30s\n",
      "     51       \u001b[36m0.19804\u001b[0m       0.20910      0.94709  1.44s\n",
      "     52       \u001b[36m0.19795\u001b[0m       \u001b[32m0.20886\u001b[0m      0.94776  1.19s\n",
      "     53       \u001b[36m0.19701\u001b[0m       0.20904      0.94244  1.15s\n",
      "     54       \u001b[36m0.19680\u001b[0m       0.20913      0.94102  1.13s\n",
      "     55       \u001b[36m0.19677\u001b[0m       0.20906      0.94122  1.33s\n",
      "     56       \u001b[36m0.19614\u001b[0m       0.20919      0.93763  1.14s\n",
      "     57       \u001b[36m0.19601\u001b[0m       0.20896      0.93801  1.19s\n",
      "     58       \u001b[36m0.19587\u001b[0m       0.20917      0.93640  1.16s\n",
      "     59       \u001b[36m0.19502\u001b[0m       0.20912      0.93255  1.14s\n",
      "     60       \u001b[36m0.19458\u001b[0m       0.20888      0.93157  1.26s\n",
      "     61       \u001b[36m0.19350\u001b[0m       0.20925      0.92472  1.12s\n",
      "     62       \u001b[36m0.19346\u001b[0m       0.20940      0.92387  1.15s\n",
      "Early stopping.\n",
      "Best valid loss was 0.208856 at epoch 52.\n",
      "Loaded parameters to layer 'hidden0' (shape 100x250).\n",
      "Loaded parameters to layer 'hidden0' (shape 250).\n",
      "Loaded parameters to layer 'hidden1' (shape 250x80).\n",
      "Loaded parameters to layer 'hidden1' (shape 80).\n",
      "Loaded parameters to layer 'output' (shape 80x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 130982 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input        100\n",
      "  1  hidden0      500\n",
      "  2  dropout0     500\n",
      "  3  hidden1      160\n",
      "  4  output         2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.23567\u001b[0m       \u001b[32m0.22240\u001b[0m      1.05966  2.84s\n",
      "      2       \u001b[36m0.22342\u001b[0m       \u001b[32m0.21705\u001b[0m      1.02933  2.73s\n",
      "      3       \u001b[36m0.22048\u001b[0m       \u001b[32m0.21510\u001b[0m      1.02497  2.93s\n",
      "      4       \u001b[36m0.21854\u001b[0m       \u001b[32m0.21404\u001b[0m      1.02101  2.97s\n",
      "      5       \u001b[36m0.21766\u001b[0m       \u001b[32m0.21341\u001b[0m      1.01989  2.86s\n",
      "      6       \u001b[36m0.21675\u001b[0m       \u001b[32m0.21275\u001b[0m      1.01879  2.97s\n",
      "      7       \u001b[36m0.21549\u001b[0m       \u001b[32m0.21240\u001b[0m      1.01459  2.76s\n",
      "      8       \u001b[36m0.21455\u001b[0m       \u001b[32m0.21216\u001b[0m      1.01127  2.84s\n",
      "      9       \u001b[36m0.21389\u001b[0m       \u001b[32m0.21178\u001b[0m      1.00998  2.70s\n",
      "     10       \u001b[36m0.21269\u001b[0m       \u001b[32m0.21150\u001b[0m      1.00564  2.74s\n",
      "     11       \u001b[36m0.21254\u001b[0m       \u001b[32m0.21116\u001b[0m      1.00651  2.76s\n",
      "     12       \u001b[36m0.21170\u001b[0m       \u001b[32m0.21090\u001b[0m      1.00382  2.84s\n",
      "     13       \u001b[36m0.21064\u001b[0m       \u001b[32m0.21086\u001b[0m      0.99894  2.79s\n",
      "     14       \u001b[36m0.21001\u001b[0m       \u001b[32m0.21079\u001b[0m      0.99633  2.81s\n",
      "     15       \u001b[36m0.20949\u001b[0m       \u001b[32m0.21049\u001b[0m      0.99526  3.13s\n",
      "     16       \u001b[36m0.20858\u001b[0m       \u001b[32m0.21017\u001b[0m      0.99244  2.89s\n",
      "     17       \u001b[36m0.20838\u001b[0m       \u001b[32m0.21002\u001b[0m      0.99220  3.14s\n",
      "     18       \u001b[36m0.20780\u001b[0m       \u001b[32m0.20987\u001b[0m      0.99012  2.83s\n",
      "     19       \u001b[36m0.20763\u001b[0m       \u001b[32m0.20981\u001b[0m      0.98960  2.73s\n",
      "     20       \u001b[36m0.20662\u001b[0m       \u001b[32m0.20972\u001b[0m      0.98524  2.92s\n",
      "     21       \u001b[36m0.20572\u001b[0m       0.20972      0.98092  2.79s\n",
      "     22       \u001b[36m0.20541\u001b[0m       \u001b[32m0.20942\u001b[0m      0.98087  2.96s\n",
      "     23       \u001b[36m0.20471\u001b[0m       0.20961      0.97663  2.91s\n",
      "     24       \u001b[36m0.20326\u001b[0m       0.20953      0.97009  2.86s\n",
      "     25       \u001b[36m0.20313\u001b[0m       0.20967      0.96883  2.87s\n",
      "     26       \u001b[36m0.20253\u001b[0m       0.20979      0.96540  3.28s\n",
      "     27       \u001b[36m0.20128\u001b[0m       0.20960      0.96028  2.84s\n",
      "     28       \u001b[36m0.20086\u001b[0m       0.20966      0.95804  2.89s\n",
      "     29       \u001b[36m0.20019\u001b[0m       0.20981      0.95413  2.93s\n",
      "     30       \u001b[36m0.19987\u001b[0m       0.20987      0.95238  2.83s\n",
      "     31       \u001b[36m0.19932\u001b[0m       0.20973      0.95040  2.82s\n",
      "     32       \u001b[36m0.19821\u001b[0m       0.21010      0.94342  2.81s\n",
      "Early stopping.\n",
      "Best valid loss was 0.209416 at epoch 22.\n",
      "Loaded parameters to layer 'hidden0' (shape 100x500).\n",
      "Loaded parameters to layer 'hidden0' (shape 500).\n",
      "Loaded parameters to layer 'hidden1' (shape 500x160).\n",
      "Loaded parameters to layer 'hidden1' (shape 160).\n",
      "Loaded parameters to layer 'output' (shape 160x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 106672 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input        100\n",
      "  1  hidden0      400\n",
      "  2  dropout0     400\n",
      "  3  hidden1      150\n",
      "  4  dropout1     150\n",
      "  5  hidden2       40\n",
      "  6  output         2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.24233\u001b[0m       \u001b[32m0.22838\u001b[0m      1.06111  2.81s\n",
      "      2       \u001b[36m0.23071\u001b[0m       \u001b[32m0.22109\u001b[0m      1.04355  2.72s\n",
      "      3       \u001b[36m0.22644\u001b[0m       \u001b[32m0.21784\u001b[0m      1.03946  3.02s\n",
      "      4       \u001b[36m0.22328\u001b[0m       \u001b[32m0.21588\u001b[0m      1.03428  2.70s\n",
      "      5       \u001b[36m0.22176\u001b[0m       \u001b[32m0.21469\u001b[0m      1.03294  2.92s\n",
      "      6       \u001b[36m0.22034\u001b[0m       \u001b[32m0.21393\u001b[0m      1.02993  2.71s\n",
      "      7       \u001b[36m0.21998\u001b[0m       \u001b[32m0.21342\u001b[0m      1.03075  2.75s\n",
      "      8       \u001b[36m0.21887\u001b[0m       \u001b[32m0.21290\u001b[0m      1.02806  2.51s\n",
      "      9       \u001b[36m0.21846\u001b[0m       \u001b[32m0.21247\u001b[0m      1.02819  2.63s\n",
      "     10       \u001b[36m0.21740\u001b[0m       \u001b[32m0.21211\u001b[0m      1.02492  2.56s\n",
      "     11       \u001b[36m0.21674\u001b[0m       \u001b[32m0.21199\u001b[0m      1.02242  2.64s\n",
      "     12       \u001b[36m0.21662\u001b[0m       \u001b[32m0.21173\u001b[0m      1.02308  2.89s\n",
      "     13       \u001b[36m0.21549\u001b[0m       \u001b[32m0.21142\u001b[0m      1.01921  2.62s\n",
      "     14       \u001b[36m0.21525\u001b[0m       \u001b[32m0.21124\u001b[0m      1.01900  2.64s\n",
      "     15       \u001b[36m0.21476\u001b[0m       \u001b[32m0.21093\u001b[0m      1.01815  2.83s\n",
      "     16       \u001b[36m0.21370\u001b[0m       \u001b[32m0.21058\u001b[0m      1.01479  2.59s\n",
      "     17       0.21434       \u001b[32m0.21054\u001b[0m      1.01807  2.52s\n",
      "     18       \u001b[36m0.21304\u001b[0m       \u001b[32m0.21014\u001b[0m      1.01379  2.67s\n",
      "     19       \u001b[36m0.21265\u001b[0m       \u001b[32m0.21010\u001b[0m      1.01211  2.56s\n",
      "     20       \u001b[36m0.21233\u001b[0m       \u001b[32m0.20999\u001b[0m      1.01112  2.73s\n",
      "     21       \u001b[36m0.21216\u001b[0m       \u001b[32m0.20973\u001b[0m      1.01160  2.46s\n",
      "     22       \u001b[36m0.21161\u001b[0m       \u001b[32m0.20960\u001b[0m      1.00961  2.63s\n",
      "     23       \u001b[36m0.21121\u001b[0m       \u001b[32m0.20921\u001b[0m      1.00960  2.47s\n",
      "     24       \u001b[36m0.21038\u001b[0m       \u001b[32m0.20914\u001b[0m      1.00595  2.65s\n",
      "     25       \u001b[36m0.21006\u001b[0m       0.20923      1.00393  2.46s\n",
      "     26       0.21014       \u001b[32m0.20908\u001b[0m      1.00505  3.05s\n",
      "     27       \u001b[36m0.20906\u001b[0m       \u001b[32m0.20889\u001b[0m      1.00081  2.51s\n",
      "     28       0.20913       \u001b[32m0.20889\u001b[0m      1.00118  2.72s\n",
      "     29       \u001b[36m0.20872\u001b[0m       \u001b[32m0.20867\u001b[0m      1.00025  2.66s\n",
      "     30       \u001b[36m0.20807\u001b[0m       0.20869      0.99701  2.72s\n",
      "     31       \u001b[36m0.20729\u001b[0m       \u001b[32m0.20864\u001b[0m      0.99354  2.51s\n",
      "     32       \u001b[36m0.20720\u001b[0m       \u001b[32m0.20837\u001b[0m      0.99441  2.56s\n",
      "     33       \u001b[36m0.20585\u001b[0m       \u001b[32m0.20820\u001b[0m      0.98872  2.46s\n",
      "     34       0.20602       \u001b[32m0.20810\u001b[0m      0.98997  2.58s\n",
      "     35       0.20611       0.20817      0.99013  2.55s\n",
      "     36       \u001b[36m0.20536\u001b[0m       \u001b[32m0.20808\u001b[0m      0.98697  2.53s\n",
      "     37       \u001b[36m0.20417\u001b[0m       \u001b[32m0.20785\u001b[0m      0.98226  2.57s\n",
      "     38       0.20461       \u001b[32m0.20763\u001b[0m      0.98545  2.77s\n",
      "     39       \u001b[36m0.20376\u001b[0m       0.20784      0.98035  2.57s\n",
      "     40       \u001b[36m0.20335\u001b[0m       0.20789      0.97815  2.73s\n",
      "     41       \u001b[36m0.20254\u001b[0m       0.20775      0.97497  2.62s\n",
      "     42       \u001b[36m0.20185\u001b[0m       0.20789      0.97094  2.53s\n",
      "     43       \u001b[36m0.20167\u001b[0m       0.20815      0.96888  2.64s\n",
      "     44       \u001b[36m0.20135\u001b[0m       0.20786      0.96867  2.55s\n",
      "     45       \u001b[36m0.20107\u001b[0m       0.20785      0.96739  2.57s\n",
      "     46       \u001b[36m0.19955\u001b[0m       0.20778      0.96040  2.50s\n",
      "     47       \u001b[36m0.19876\u001b[0m       0.20789      0.95607  2.69s\n",
      "     48       0.19921       0.20792      0.95812  2.62s\n",
      "Early stopping.\n",
      "Best valid loss was 0.207634 at epoch 38.\n",
      "Loaded parameters to layer 'hidden0' (shape 100x400).\n",
      "Loaded parameters to layer 'hidden0' (shape 400).\n",
      "Loaded parameters to layer 'hidden1' (shape 400x150).\n",
      "Loaded parameters to layer 'hidden1' (shape 150).\n",
      "Loaded parameters to layer 'hidden2' (shape 150x40).\n",
      "Loaded parameters to layer 'hidden2' (shape 40).\n",
      "Loaded parameters to layer 'output' (shape 40x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 10302 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name       size\n",
      "---  -------  ------\n",
      "  0  input       100\n",
      "  1  hidden0     100\n",
      "  2  output        2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.23549\u001b[0m       \u001b[32m0.22509\u001b[0m      1.04622  0.22s\n",
      "      2       \u001b[36m0.22388\u001b[0m       \u001b[32m0.21886\u001b[0m      1.02293  0.22s\n",
      "      3       \u001b[36m0.21985\u001b[0m       \u001b[32m0.21650\u001b[0m      1.01546  0.22s\n",
      "      4       \u001b[36m0.21797\u001b[0m       \u001b[32m0.21561\u001b[0m      1.01096  0.23s\n",
      "      5       \u001b[36m0.21691\u001b[0m       \u001b[32m0.21519\u001b[0m      1.00799  0.56s\n",
      "      6       \u001b[36m0.21616\u001b[0m       \u001b[32m0.21492\u001b[0m      1.00579  0.25s\n",
      "      7       \u001b[36m0.21555\u001b[0m       \u001b[32m0.21471\u001b[0m      1.00390  0.24s\n",
      "      8       \u001b[36m0.21499\u001b[0m       \u001b[32m0.21454\u001b[0m      1.00211  0.23s\n",
      "      9       \u001b[36m0.21447\u001b[0m       \u001b[32m0.21436\u001b[0m      1.00050  0.26s\n",
      "     10       \u001b[36m0.21396\u001b[0m       \u001b[32m0.21419\u001b[0m      0.99893  0.24s\n",
      "     11       \u001b[36m0.21347\u001b[0m       \u001b[32m0.21403\u001b[0m      0.99739  0.23s\n",
      "     12       \u001b[36m0.21298\u001b[0m       \u001b[32m0.21386\u001b[0m      0.99589  0.22s\n",
      "     13       \u001b[36m0.21249\u001b[0m       \u001b[32m0.21371\u001b[0m      0.99431  0.22s\n",
      "     14       \u001b[36m0.21200\u001b[0m       \u001b[32m0.21356\u001b[0m      0.99269  0.23s\n",
      "     15       \u001b[36m0.21150\u001b[0m       \u001b[32m0.21342\u001b[0m      0.99100  0.35s\n",
      "     16       \u001b[36m0.21101\u001b[0m       \u001b[32m0.21330\u001b[0m      0.98924  0.23s\n",
      "     17       \u001b[36m0.21051\u001b[0m       \u001b[32m0.21318\u001b[0m      0.98744  0.22s\n",
      "     18       \u001b[36m0.21000\u001b[0m       \u001b[32m0.21308\u001b[0m      0.98555  0.25s\n",
      "     19       \u001b[36m0.20949\u001b[0m       \u001b[32m0.21299\u001b[0m      0.98358  0.24s\n",
      "     20       \u001b[36m0.20898\u001b[0m       \u001b[32m0.21293\u001b[0m      0.98147  0.21s\n",
      "     21       \u001b[36m0.20847\u001b[0m       \u001b[32m0.21287\u001b[0m      0.97930  0.22s\n",
      "     22       \u001b[36m0.20794\u001b[0m       \u001b[32m0.21283\u001b[0m      0.97705  0.24s\n",
      "     23       \u001b[36m0.20742\u001b[0m       \u001b[32m0.21280\u001b[0m      0.97471  0.21s\n",
      "     24       \u001b[36m0.20689\u001b[0m       \u001b[32m0.21277\u001b[0m      0.97232  0.22s\n",
      "     25       \u001b[36m0.20635\u001b[0m       \u001b[32m0.21275\u001b[0m      0.96993  0.49s\n",
      "     26       \u001b[36m0.20581\u001b[0m       \u001b[32m0.21275\u001b[0m      0.96740  0.24s\n",
      "     27       \u001b[36m0.20527\u001b[0m       0.21275      0.96483  0.24s\n",
      "     28       \u001b[36m0.20473\u001b[0m       0.21275      0.96230  0.23s\n",
      "     29       \u001b[36m0.20419\u001b[0m       0.21276      0.95969  0.23s\n",
      "     30       \u001b[36m0.20365\u001b[0m       0.21279      0.95704  0.22s\n",
      "     31       \u001b[36m0.20311\u001b[0m       0.21283      0.95429  0.21s\n",
      "     32       \u001b[36m0.20257\u001b[0m       0.21289      0.95151  0.23s\n",
      "     33       \u001b[36m0.20204\u001b[0m       0.21296      0.94873  0.22s\n",
      "     34       \u001b[36m0.20152\u001b[0m       0.21303      0.94595  0.23s\n",
      "     35       \u001b[36m0.20099\u001b[0m       0.21310      0.94319  0.22s\n",
      "     36       \u001b[36m0.20048\u001b[0m       0.21320      0.94034  0.22s\n",
      "Early stopping.\n",
      "Best valid loss was 0.212746 at epoch 26.\n",
      "Loaded parameters to layer 'hidden0' (shape 100x100).\n",
      "Loaded parameters to layer 'hidden0' (shape 100).\n",
      "Loaded parameters to layer 'output' (shape 100x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 30902 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name       size\n",
      "---  -------  ------\n",
      "  0  input       100\n",
      "  1  hidden0     300\n",
      "  2  output        2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.23270\u001b[0m       \u001b[32m0.22115\u001b[0m      1.05219  0.57s\n",
      "      2       \u001b[36m0.22123\u001b[0m       \u001b[32m0.21601\u001b[0m      1.02418  0.59s\n",
      "      3       \u001b[36m0.21810\u001b[0m       \u001b[32m0.21427\u001b[0m      1.01788  0.59s\n",
      "      4       \u001b[36m0.21652\u001b[0m       \u001b[32m0.21347\u001b[0m      1.01430  0.59s\n",
      "      5       \u001b[36m0.21544\u001b[0m       \u001b[32m0.21298\u001b[0m      1.01152  0.56s\n",
      "      6       \u001b[36m0.21453\u001b[0m       \u001b[32m0.21261\u001b[0m      1.00905  0.66s\n",
      "      7       \u001b[36m0.21370\u001b[0m       \u001b[32m0.21227\u001b[0m      1.00671  0.61s\n",
      "      8       \u001b[36m0.21289\u001b[0m       \u001b[32m0.21198\u001b[0m      1.00429  0.57s\n",
      "      9       \u001b[36m0.21210\u001b[0m       \u001b[32m0.21170\u001b[0m      1.00189  0.60s\n",
      "     10       \u001b[36m0.21130\u001b[0m       \u001b[32m0.21144\u001b[0m      0.99934  0.58s\n",
      "     11       \u001b[36m0.21050\u001b[0m       \u001b[32m0.21122\u001b[0m      0.99662  0.59s\n",
      "     12       \u001b[36m0.20970\u001b[0m       \u001b[32m0.21100\u001b[0m      0.99385  0.57s\n",
      "     13       \u001b[36m0.20891\u001b[0m       \u001b[32m0.21080\u001b[0m      0.99104  0.57s\n",
      "     14       \u001b[36m0.20810\u001b[0m       \u001b[32m0.21060\u001b[0m      0.98811  0.56s\n",
      "     15       \u001b[36m0.20729\u001b[0m       \u001b[32m0.21044\u001b[0m      0.98503  0.63s\n",
      "     16       \u001b[36m0.20648\u001b[0m       \u001b[32m0.21027\u001b[0m      0.98194  0.53s\n",
      "     17       \u001b[36m0.20566\u001b[0m       \u001b[32m0.21013\u001b[0m      0.97873  0.54s\n",
      "     18       \u001b[36m0.20485\u001b[0m       \u001b[32m0.21001\u001b[0m      0.97541  0.53s\n",
      "     19       \u001b[36m0.20403\u001b[0m       \u001b[32m0.20992\u001b[0m      0.97193  0.52s\n",
      "     20       \u001b[36m0.20321\u001b[0m       \u001b[32m0.20987\u001b[0m      0.96827  0.56s\n",
      "     21       \u001b[36m0.20239\u001b[0m       \u001b[32m0.20984\u001b[0m      0.96451  0.54s\n",
      "     22       \u001b[36m0.20159\u001b[0m       \u001b[32m0.20984\u001b[0m      0.96066  0.53s\n",
      "     23       \u001b[36m0.20078\u001b[0m       0.20987      0.95669  0.53s\n",
      "     24       \u001b[36m0.19997\u001b[0m       0.20990      0.95269  0.57s\n",
      "     25       \u001b[36m0.19917\u001b[0m       0.20996      0.94862  0.65s\n",
      "     26       \u001b[36m0.19837\u001b[0m       0.21002      0.94452  0.53s\n",
      "     27       \u001b[36m0.19758\u001b[0m       0.21010      0.94042  0.60s\n",
      "     28       \u001b[36m0.19679\u001b[0m       0.21020      0.93621  0.54s\n",
      "     29       \u001b[36m0.19601\u001b[0m       0.21032      0.93193  0.55s\n",
      "     30       \u001b[36m0.19523\u001b[0m       0.21045      0.92765  0.56s\n",
      "     31       \u001b[36m0.19445\u001b[0m       0.21061      0.92327  0.60s\n",
      "     32       \u001b[36m0.19369\u001b[0m       0.21081      0.91879  0.56s\n",
      "Early stopping.\n",
      "Best valid loss was 0.209841 at epoch 22.\n",
      "Loaded parameters to layer 'hidden0' (shape 100x300).\n",
      "Loaded parameters to layer 'hidden0' (shape 300).\n",
      "Loaded parameters to layer 'output' (shape 300x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 45492 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input        100\n",
      "  1  hidden0      250\n",
      "  2  dropout0     250\n",
      "  3  hidden1       80\n",
      "  4  output         2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.24264\u001b[0m       \u001b[32m0.22594\u001b[0m      1.07392  1.80s\n",
      "      2       \u001b[36m0.23055\u001b[0m       \u001b[32m0.21956\u001b[0m      1.05006  1.21s\n",
      "      3       \u001b[36m0.22647\u001b[0m       \u001b[32m0.21701\u001b[0m      1.04361  1.20s\n",
      "      4       \u001b[36m0.22440\u001b[0m       \u001b[32m0.21525\u001b[0m      1.04254  1.23s\n",
      "      5       \u001b[36m0.22277\u001b[0m       \u001b[32m0.21442\u001b[0m      1.03893  1.30s\n",
      "      6       \u001b[36m0.22165\u001b[0m       \u001b[32m0.21390\u001b[0m      1.03626  1.20s\n",
      "      7       0.22174       \u001b[32m0.21366\u001b[0m      1.03780  1.14s\n",
      "      8       \u001b[36m0.22045\u001b[0m       \u001b[32m0.21324\u001b[0m      1.03380  1.16s\n",
      "      9       \u001b[36m0.22020\u001b[0m       \u001b[32m0.21295\u001b[0m      1.03405  1.24s\n",
      "     10       \u001b[36m0.21960\u001b[0m       \u001b[32m0.21266\u001b[0m      1.03259  1.19s\n",
      "     11       \u001b[36m0.21861\u001b[0m       \u001b[32m0.21241\u001b[0m      1.02916  1.17s\n",
      "     12       \u001b[36m0.21853\u001b[0m       \u001b[32m0.21218\u001b[0m      1.02992  1.21s\n",
      "     13       \u001b[36m0.21784\u001b[0m       \u001b[32m0.21187\u001b[0m      1.02816  1.25s\n",
      "     14       \u001b[36m0.21751\u001b[0m       \u001b[32m0.21173\u001b[0m      1.02728  1.28s\n",
      "     15       \u001b[36m0.21663\u001b[0m       \u001b[32m0.21162\u001b[0m      1.02369  1.19s\n",
      "     16       \u001b[36m0.21657\u001b[0m       \u001b[32m0.21152\u001b[0m      1.02389  1.25s\n",
      "     17       \u001b[36m0.21643\u001b[0m       \u001b[32m0.21124\u001b[0m      1.02461  1.29s\n",
      "     18       \u001b[36m0.21600\u001b[0m       \u001b[32m0.21119\u001b[0m      1.02276  1.31s\n",
      "     19       \u001b[36m0.21556\u001b[0m       \u001b[32m0.21099\u001b[0m      1.02168  1.21s\n",
      "     20       \u001b[36m0.21525\u001b[0m       \u001b[32m0.21084\u001b[0m      1.02091  1.23s\n",
      "     21       \u001b[36m0.21515\u001b[0m       \u001b[32m0.21073\u001b[0m      1.02100  1.21s\n",
      "     22       \u001b[36m0.21472\u001b[0m       \u001b[32m0.21070\u001b[0m      1.01905  1.38s\n",
      "     23       \u001b[36m0.21451\u001b[0m       \u001b[32m0.21064\u001b[0m      1.01840  1.17s\n",
      "     24       \u001b[36m0.21365\u001b[0m       \u001b[32m0.21039\u001b[0m      1.01550  1.12s\n",
      "     25       0.21387       \u001b[32m0.21028\u001b[0m      1.01710  1.35s\n",
      "     26       0.21387       \u001b[32m0.21026\u001b[0m      1.01716  1.53s\n",
      "     27       \u001b[36m0.21343\u001b[0m       \u001b[32m0.21007\u001b[0m      1.01598  1.19s\n",
      "     28       \u001b[36m0.21288\u001b[0m       \u001b[32m0.21006\u001b[0m      1.01342  1.24s\n",
      "     29       \u001b[36m0.21271\u001b[0m       0.21008      1.01253  1.24s\n",
      "     30       \u001b[36m0.21235\u001b[0m       \u001b[32m0.21004\u001b[0m      1.01099  1.49s\n",
      "     31       \u001b[36m0.21221\u001b[0m       \u001b[32m0.20983\u001b[0m      1.01136  1.36s\n",
      "     32       \u001b[36m0.21166\u001b[0m       \u001b[32m0.20980\u001b[0m      1.00887  1.20s\n",
      "     33       \u001b[36m0.21153\u001b[0m       \u001b[32m0.20974\u001b[0m      1.00853  1.23s\n",
      "     34       \u001b[36m0.21142\u001b[0m       \u001b[32m0.20973\u001b[0m      1.00805  1.23s\n",
      "     35       \u001b[36m0.21092\u001b[0m       0.20976      1.00553  1.26s\n",
      "     36       0.21126       \u001b[32m0.20959\u001b[0m      1.00795  1.20s\n",
      "     37       \u001b[36m0.21075\u001b[0m       \u001b[32m0.20959\u001b[0m      1.00557  1.15s\n",
      "     38       \u001b[36m0.21011\u001b[0m       \u001b[32m0.20958\u001b[0m      1.00252  1.16s\n",
      "     39       0.21015       \u001b[32m0.20954\u001b[0m      1.00292  1.17s\n",
      "     40       \u001b[36m0.21005\u001b[0m       \u001b[32m0.20942\u001b[0m      1.00299  1.25s\n",
      "     41       0.21010       \u001b[32m0.20941\u001b[0m      1.00327  1.17s\n",
      "     42       \u001b[36m0.20966\u001b[0m       \u001b[32m0.20919\u001b[0m      1.00223  1.15s\n",
      "     43       \u001b[36m0.20883\u001b[0m       0.20921      0.99817  1.20s\n",
      "     44       \u001b[36m0.20854\u001b[0m       \u001b[32m0.20897\u001b[0m      0.99798  1.37s\n",
      "     45       0.20863       0.20897      0.99840  1.26s\n",
      "     46       \u001b[36m0.20830\u001b[0m       \u001b[32m0.20896\u001b[0m      0.99687  1.29s\n",
      "     47       \u001b[36m0.20808\u001b[0m       \u001b[32m0.20873\u001b[0m      0.99689  1.19s\n",
      "     48       0.20831       0.20874      0.99794  1.27s\n",
      "     49       \u001b[36m0.20737\u001b[0m       \u001b[32m0.20864\u001b[0m      0.99392  1.19s\n",
      "     50       0.20782       \u001b[32m0.20857\u001b[0m      0.99638  1.46s\n",
      "     51       0.20789       0.20860      0.99660  1.15s\n",
      "     52       0.20743       0.20863      0.99427  1.17s\n",
      "     53       \u001b[36m0.20722\u001b[0m       0.20875      0.99266  1.35s\n",
      "     54       \u001b[36m0.20651\u001b[0m       \u001b[32m0.20852\u001b[0m      0.99035  1.29s\n",
      "     55       \u001b[36m0.20600\u001b[0m       0.20859      0.98762  1.19s\n",
      "     56       0.20655       0.20854      0.99048  1.18s\n",
      "     57       0.20615       \u001b[32m0.20851\u001b[0m      0.98867  1.24s\n",
      "     58       0.20649       \u001b[32m0.20850\u001b[0m      0.99038  1.17s\n",
      "     59       \u001b[36m0.20598\u001b[0m       0.20865      0.98720  1.17s\n",
      "     60       \u001b[36m0.20549\u001b[0m       0.20872      0.98453  1.17s\n",
      "     61       \u001b[36m0.20529\u001b[0m       0.20854      0.98438  1.14s\n",
      "     62       \u001b[36m0.20498\u001b[0m       0.20868      0.98225  1.31s\n",
      "     63       0.20525       \u001b[32m0.20844\u001b[0m      0.98469  1.46s\n",
      "     64       \u001b[36m0.20438\u001b[0m       \u001b[32m0.20832\u001b[0m      0.98109  1.27s\n",
      "     65       \u001b[36m0.20418\u001b[0m       \u001b[32m0.20827\u001b[0m      0.98035  1.23s\n",
      "     66       \u001b[36m0.20323\u001b[0m       0.20840      0.97516  1.27s\n",
      "     67       0.20390       0.20844      0.97820  1.19s\n",
      "     68       0.20339       0.20859      0.97505  1.15s\n",
      "     69       0.20369       0.20853      0.97678  1.15s\n",
      "     70       0.20367       \u001b[32m0.20825\u001b[0m      0.97799  1.43s\n",
      "     71       \u001b[36m0.20250\u001b[0m       \u001b[32m0.20811\u001b[0m      0.97303  1.32s\n",
      "     72       0.20286       0.20819      0.97440  1.22s\n",
      "     73       \u001b[36m0.20206\u001b[0m       0.20846      0.96930  1.17s\n",
      "     74       \u001b[36m0.20203\u001b[0m       0.20824      0.97016  1.57s\n",
      "     75       \u001b[36m0.20115\u001b[0m       0.20842      0.96513  1.18s\n",
      "     76       0.20138       0.20838      0.96642  1.15s\n",
      "     77       0.20127       0.20835      0.96600  1.14s\n",
      "     78       \u001b[36m0.20099\u001b[0m       0.20854      0.96377  1.15s\n",
      "     79       0.20119       0.20846      0.96513  1.38s\n",
      "     80       \u001b[36m0.20048\u001b[0m       0.20841      0.96197  1.18s\n",
      "     81       \u001b[36m0.20015\u001b[0m       0.20833      0.96076  1.23s\n",
      "Early stopping.\n",
      "Best valid loss was 0.208113 at epoch 71.\n",
      "Loaded parameters to layer 'hidden0' (shape 100x250).\n",
      "Loaded parameters to layer 'hidden0' (shape 250).\n",
      "Loaded parameters to layer 'hidden1' (shape 250x80).\n",
      "Loaded parameters to layer 'hidden1' (shape 80).\n",
      "Loaded parameters to layer 'output' (shape 80x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 130982 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input        100\n",
      "  1  hidden0      500\n",
      "  2  dropout0     500\n",
      "  3  hidden1      160\n",
      "  4  output         2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.23842\u001b[0m       \u001b[32m0.22379\u001b[0m      1.06540  2.90s\n",
      "      2       \u001b[36m0.22742\u001b[0m       \u001b[32m0.21804\u001b[0m      1.04302  2.78s\n",
      "      3       \u001b[36m0.22374\u001b[0m       \u001b[32m0.21569\u001b[0m      1.03733  2.88s\n",
      "      4       \u001b[36m0.22162\u001b[0m       \u001b[32m0.21467\u001b[0m      1.03237  2.89s\n",
      "      5       \u001b[36m0.22063\u001b[0m       \u001b[32m0.21424\u001b[0m      1.02984  2.89s\n",
      "      6       \u001b[36m0.21901\u001b[0m       \u001b[32m0.21362\u001b[0m      1.02526  2.91s\n",
      "      7       \u001b[36m0.21860\u001b[0m       \u001b[32m0.21316\u001b[0m      1.02550  3.08s\n",
      "      8       \u001b[36m0.21824\u001b[0m       \u001b[32m0.21288\u001b[0m      1.02517  2.78s\n",
      "      9       \u001b[36m0.21726\u001b[0m       \u001b[32m0.21258\u001b[0m      1.02200  2.92s\n",
      "     10       \u001b[36m0.21699\u001b[0m       \u001b[32m0.21238\u001b[0m      1.02170  2.89s\n",
      "     11       \u001b[36m0.21572\u001b[0m       \u001b[32m0.21230\u001b[0m      1.01613  2.84s\n",
      "     12       \u001b[36m0.21535\u001b[0m       \u001b[32m0.21222\u001b[0m      1.01475  2.90s\n",
      "     13       \u001b[36m0.21466\u001b[0m       \u001b[32m0.21190\u001b[0m      1.01300  2.83s\n",
      "     14       0.21470       \u001b[32m0.21179\u001b[0m      1.01372  2.76s\n",
      "     15       \u001b[36m0.21389\u001b[0m       \u001b[32m0.21168\u001b[0m      1.01045  2.76s\n",
      "     16       0.21406       \u001b[32m0.21157\u001b[0m      1.01174  2.89s\n",
      "     17       \u001b[36m0.21320\u001b[0m       \u001b[32m0.21140\u001b[0m      1.00850  2.84s\n",
      "     18       \u001b[36m0.21290\u001b[0m       \u001b[32m0.21114\u001b[0m      1.00835  3.22s\n",
      "     19       \u001b[36m0.21250\u001b[0m       \u001b[32m0.21110\u001b[0m      1.00665  2.93s\n",
      "     20       \u001b[36m0.21192\u001b[0m       \u001b[32m0.21107\u001b[0m      1.00401  3.00s\n",
      "     21       \u001b[36m0.21170\u001b[0m       \u001b[32m0.21103\u001b[0m      1.00316  2.86s\n",
      "     22       \u001b[36m0.21108\u001b[0m       \u001b[32m0.21080\u001b[0m      1.00130  2.80s\n",
      "     23       \u001b[36m0.21063\u001b[0m       0.21081      0.99915  2.93s\n",
      "     24       \u001b[36m0.21011\u001b[0m       \u001b[32m0.21068\u001b[0m      0.99728  2.81s\n",
      "     25       \u001b[36m0.21011\u001b[0m       \u001b[32m0.21044\u001b[0m      0.99839  2.74s\n",
      "     26       \u001b[36m0.20949\u001b[0m       0.21052      0.99511  2.95s\n",
      "     27       \u001b[36m0.20938\u001b[0m       \u001b[32m0.21043\u001b[0m      0.99497  3.03s\n",
      "     28       \u001b[36m0.20860\u001b[0m       \u001b[32m0.21032\u001b[0m      0.99186  3.11s\n",
      "     29       \u001b[36m0.20833\u001b[0m       \u001b[32m0.21003\u001b[0m      0.99188  2.91s\n",
      "     30       \u001b[36m0.20766\u001b[0m       0.21014      0.98819  2.95s\n",
      "     31       \u001b[36m0.20740\u001b[0m       \u001b[32m0.21001\u001b[0m      0.98758  3.01s\n",
      "     32       0.20753       0.21018      0.98742  2.75s\n",
      "     33       \u001b[36m0.20687\u001b[0m       0.21007      0.98475  2.87s\n",
      "     34       \u001b[36m0.20645\u001b[0m       0.21005      0.98290  2.78s\n",
      "     35       \u001b[36m0.20605\u001b[0m       0.21005      0.98096  2.77s\n",
      "     36       \u001b[36m0.20568\u001b[0m       0.21008      0.97908  2.74s\n",
      "     37       \u001b[36m0.20487\u001b[0m       \u001b[32m0.21000\u001b[0m      0.97558  2.88s\n",
      "     38       0.20493       \u001b[32m0.20989\u001b[0m      0.97637  2.72s\n",
      "     39       \u001b[36m0.20459\u001b[0m       \u001b[32m0.20983\u001b[0m      0.97503  3.11s\n",
      "     40       \u001b[36m0.20318\u001b[0m       \u001b[32m0.20976\u001b[0m      0.96863  2.96s\n",
      "     41       0.20339       0.20997      0.96869  2.92s\n",
      "     42       0.20394       0.20986      0.97180  2.83s\n",
      "     43       \u001b[36m0.20289\u001b[0m       0.20989      0.96664  2.74s\n",
      "     44       0.20301       0.20983      0.96750  2.95s\n",
      "     45       \u001b[36m0.20212\u001b[0m       0.20978      0.96348  2.91s\n",
      "     46       \u001b[36m0.20144\u001b[0m       0.21010      0.95879  2.99s\n",
      "     47       \u001b[36m0.20140\u001b[0m       0.21012      0.95850  2.94s\n",
      "     48       \u001b[36m0.20064\u001b[0m       0.21027      0.95421  3.17s\n",
      "     49       \u001b[36m0.20025\u001b[0m       0.21024      0.95248  3.12s\n",
      "     50       0.20055       0.20978      0.95601  3.26s\n",
      "Early stopping.\n",
      "Best valid loss was 0.209761 at epoch 40.\n",
      "Loaded parameters to layer 'hidden0' (shape 100x500).\n",
      "Loaded parameters to layer 'hidden0' (shape 500).\n",
      "Loaded parameters to layer 'hidden1' (shape 500x160).\n",
      "Loaded parameters to layer 'hidden1' (shape 160).\n",
      "Loaded parameters to layer 'output' (shape 160x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 106672 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input        100\n",
      "  1  hidden0      400\n",
      "  2  dropout0     400\n",
      "  3  hidden1      150\n",
      "  4  dropout1     150\n",
      "  5  hidden2       40\n",
      "  6  output         2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.24808\u001b[0m       \u001b[32m0.23903\u001b[0m      1.03785  2.59s\n",
      "      2       \u001b[36m0.23914\u001b[0m       \u001b[32m0.22953\u001b[0m      1.04185  2.73s\n",
      "      3       \u001b[36m0.23339\u001b[0m       \u001b[32m0.22510\u001b[0m      1.03687  2.43s\n",
      "      4       \u001b[36m0.23005\u001b[0m       \u001b[32m0.22231\u001b[0m      1.03480  2.57s\n",
      "      5       \u001b[36m0.22825\u001b[0m       \u001b[32m0.22050\u001b[0m      1.03517  3.11s\n",
      "      6       \u001b[36m0.22673\u001b[0m       \u001b[32m0.21943\u001b[0m      1.03324  2.69s\n",
      "      7       \u001b[36m0.22547\u001b[0m       \u001b[32m0.21819\u001b[0m      1.03335  2.47s\n",
      "      8       \u001b[36m0.22419\u001b[0m       \u001b[32m0.21748\u001b[0m      1.03086  2.77s\n",
      "      9       \u001b[36m0.22347\u001b[0m       \u001b[32m0.21693\u001b[0m      1.03013  2.44s\n",
      "     10       \u001b[36m0.22249\u001b[0m       \u001b[32m0.21628\u001b[0m      1.02870  2.65s\n",
      "     11       \u001b[36m0.22110\u001b[0m       \u001b[32m0.21586\u001b[0m      1.02428  2.43s\n",
      "     12       0.22135       \u001b[32m0.21579\u001b[0m      1.02577  2.53s\n",
      "     13       \u001b[36m0.22047\u001b[0m       \u001b[32m0.21515\u001b[0m      1.02470  2.49s\n",
      "     14       \u001b[36m0.22019\u001b[0m       0.21515      1.02342  2.66s\n",
      "     15       \u001b[36m0.21952\u001b[0m       \u001b[32m0.21489\u001b[0m      1.02157  2.58s\n",
      "     16       0.21959       0.21489      1.02185  2.52s\n",
      "     17       \u001b[36m0.21877\u001b[0m       \u001b[32m0.21444\u001b[0m      1.02017  2.56s\n",
      "     18       \u001b[36m0.21829\u001b[0m       \u001b[32m0.21420\u001b[0m      1.01907  2.52s\n",
      "     19       0.21848       0.21427      1.01966  2.50s\n",
      "     20       \u001b[36m0.21778\u001b[0m       \u001b[32m0.21404\u001b[0m      1.01746  2.75s\n",
      "     21       \u001b[36m0.21758\u001b[0m       \u001b[32m0.21402\u001b[0m      1.01665  2.51s\n",
      "     22       \u001b[36m0.21687\u001b[0m       \u001b[32m0.21376\u001b[0m      1.01458  2.62s\n",
      "     23       0.21711       \u001b[32m0.21375\u001b[0m      1.01576  2.57s\n",
      "     24       \u001b[36m0.21651\u001b[0m       \u001b[32m0.21337\u001b[0m      1.01473  2.56s\n",
      "     25       \u001b[36m0.21623\u001b[0m       \u001b[32m0.21315\u001b[0m      1.01445  2.55s\n",
      "     26       \u001b[36m0.21540\u001b[0m       \u001b[32m0.21305\u001b[0m      1.01100  2.46s\n",
      "     27       0.21613       0.21323      1.01361  2.52s\n",
      "     28       0.21575       \u001b[32m0.21290\u001b[0m      1.01339  2.46s\n",
      "     29       0.21598       \u001b[32m0.21287\u001b[0m      1.01462  2.51s\n",
      "     30       \u001b[36m0.21520\u001b[0m       \u001b[32m0.21265\u001b[0m      1.01201  2.67s\n",
      "     31       \u001b[36m0.21519\u001b[0m       0.21281      1.01118  2.79s\n",
      "     32       \u001b[36m0.21462\u001b[0m       \u001b[32m0.21243\u001b[0m      1.01034  2.47s\n",
      "     33       \u001b[36m0.21433\u001b[0m       \u001b[32m0.21240\u001b[0m      1.00909  2.84s\n",
      "     34       \u001b[36m0.21361\u001b[0m       \u001b[32m0.21211\u001b[0m      1.00706  2.41s\n",
      "     35       0.21424       \u001b[32m0.21205\u001b[0m      1.01032  2.64s\n",
      "     36       0.21393       0.21207      1.00878  2.48s\n",
      "     37       \u001b[36m0.21298\u001b[0m       \u001b[32m0.21161\u001b[0m      1.00647  2.48s\n",
      "     38       \u001b[36m0.21286\u001b[0m       0.21171      1.00545  2.76s\n",
      "     39       0.21323       0.21178      1.00686  2.38s\n",
      "     40       \u001b[36m0.21218\u001b[0m       0.21169      1.00230  2.57s\n",
      "     41       0.21240       \u001b[32m0.21149\u001b[0m      1.00430  2.69s\n",
      "     42       0.21225       \u001b[32m0.21145\u001b[0m      1.00376  2.61s\n",
      "     43       \u001b[36m0.21176\u001b[0m       \u001b[32m0.21136\u001b[0m      1.00190  2.42s\n",
      "     44       0.21184       \u001b[32m0.21123\u001b[0m      1.00289  2.63s\n",
      "     45       \u001b[36m0.21150\u001b[0m       0.21127      1.00112  2.55s\n",
      "     46       \u001b[36m0.21142\u001b[0m       0.21130      1.00057  2.87s\n",
      "     47       \u001b[36m0.21061\u001b[0m       \u001b[32m0.21109\u001b[0m      0.99775  2.50s\n",
      "     48       0.21065       \u001b[32m0.21083\u001b[0m      0.99911  2.74s\n",
      "     49       \u001b[36m0.21048\u001b[0m       \u001b[32m0.21078\u001b[0m      0.99859  2.46s\n",
      "     50       \u001b[36m0.20999\u001b[0m       0.21087      0.99579  2.57s\n",
      "     51       \u001b[36m0.20994\u001b[0m       0.21099      0.99502  2.63s\n",
      "     52       \u001b[36m0.20950\u001b[0m       \u001b[32m0.21064\u001b[0m      0.99458  2.62s\n",
      "     53       \u001b[36m0.20900\u001b[0m       0.21074      0.99171  2.57s\n",
      "     54       0.20919       0.21066      0.99304  2.71s\n",
      "     55       \u001b[36m0.20872\u001b[0m       \u001b[32m0.21047\u001b[0m      0.99168  2.45s\n",
      "     56       \u001b[36m0.20830\u001b[0m       \u001b[32m0.21029\u001b[0m      0.99055  2.42s\n",
      "     57       \u001b[36m0.20825\u001b[0m       0.21040      0.98977  2.51s\n",
      "     58       \u001b[36m0.20816\u001b[0m       \u001b[32m0.21010\u001b[0m      0.99075  2.42s\n",
      "     59       0.20834       0.21011      0.99158  3.05s\n",
      "     60       \u001b[36m0.20755\u001b[0m       0.21011      0.98783  2.70s\n",
      "     61       \u001b[36m0.20745\u001b[0m       \u001b[32m0.21001\u001b[0m      0.98784  2.51s\n",
      "     62       \u001b[36m0.20723\u001b[0m       0.21008      0.98639  2.43s\n",
      "     63       \u001b[36m0.20677\u001b[0m       \u001b[32m0.20997\u001b[0m      0.98474  2.47s\n",
      "     64       \u001b[36m0.20634\u001b[0m       0.20998      0.98265  2.37s\n",
      "     65       \u001b[36m0.20629\u001b[0m       0.21028      0.98102  2.48s\n",
      "     66       \u001b[36m0.20570\u001b[0m       \u001b[32m0.20994\u001b[0m      0.97977  2.44s\n",
      "     67       \u001b[36m0.20491\u001b[0m       \u001b[32m0.20983\u001b[0m      0.97659  2.70s\n",
      "     68       0.20557       0.20997      0.97905  2.46s\n",
      "     69       0.20511       0.20989      0.97722  2.66s\n",
      "     70       0.20509       \u001b[32m0.20975\u001b[0m      0.97778  2.56s\n",
      "     71       \u001b[36m0.20431\u001b[0m       0.20988      0.97343  2.94s\n",
      "     72       \u001b[36m0.20416\u001b[0m       0.20981      0.97307  2.76s\n",
      "     73       \u001b[36m0.20415\u001b[0m       \u001b[32m0.20965\u001b[0m      0.97378  2.59s\n",
      "     74       \u001b[36m0.20389\u001b[0m       0.20991      0.97134  2.48s\n",
      "     75       \u001b[36m0.20339\u001b[0m       0.20992      0.96894  2.43s\n",
      "     76       \u001b[36m0.20309\u001b[0m       0.20985      0.96779  2.52s\n",
      "     77       0.20312       \u001b[32m0.20952\u001b[0m      0.96945  2.39s\n",
      "     78       \u001b[36m0.20250\u001b[0m       0.20969      0.96572  2.49s\n",
      "     79       0.20259       0.20960      0.96657  2.32s\n",
      "     80       \u001b[36m0.20178\u001b[0m       0.20991      0.96129  2.45s\n",
      "     81       0.20224       0.20961      0.96486  2.39s\n",
      "     82       \u001b[36m0.20093\u001b[0m       0.20971      0.95816  2.49s\n",
      "     83       0.20195       0.20967      0.96319  2.44s\n",
      "     84       \u001b[36m0.20076\u001b[0m       0.20984      0.95675  2.76s\n",
      "     85       \u001b[36m0.20026\u001b[0m       0.20984      0.95435  2.53s\n",
      "     86       0.20038       0.20952      0.95639  2.57s\n",
      "     87       0.20057       0.20963      0.95678  2.54s\n",
      "     88       \u001b[36m0.19926\u001b[0m       \u001b[32m0.20951\u001b[0m      0.95107  2.50s\n",
      "     89       \u001b[36m0.19916\u001b[0m       \u001b[32m0.20923\u001b[0m      0.95186  2.50s\n",
      "     90       \u001b[36m0.19884\u001b[0m       0.20943      0.94943  2.36s\n",
      "     91       \u001b[36m0.19853\u001b[0m       0.20937      0.94822  2.52s\n",
      "     92       \u001b[36m0.19749\u001b[0m       0.20975      0.94159  2.36s\n",
      "     93       0.19817       0.20947      0.94605  2.56s\n",
      "     94       0.19802       0.20968      0.94437  2.39s\n",
      "     95       \u001b[36m0.19706\u001b[0m       \u001b[32m0.20921\u001b[0m      0.94190  2.42s\n",
      "     96       0.19706       0.20933      0.94137  2.57s\n",
      "     97       \u001b[36m0.19626\u001b[0m       \u001b[32m0.20902\u001b[0m      0.93897  2.40s\n",
      "     98       \u001b[36m0.19478\u001b[0m       0.20973      0.92868  2.88s\n",
      "     99       0.19555       0.20980      0.93205  2.44s\n",
      "    100       0.19512       0.20974      0.93028  2.59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/projekte/anaconda3/envs/ipynb/lib/python3.5/site-packages/nolearn/lasagne/base.py:250: UserWarning: The 'eval_size' argument has been deprecated, please use the 'train_split' parameter instead, e.g.\n",
      "train_split=TrainSplit(eval_size=0.4)\n",
      "  warn(\"The 'eval_size' argument has been deprecated, please use \"\n",
      "INFO:root:start loading the model\n",
      "INFO:gensim.utils:loading Doc2Vec object from /home/user/projekte/econstorModelling/cache/allDocs300D.model\n",
      "INFO:gensim.utils:loading docvecs recursively from /home/user/projekte/econstorModelling/cache/allDocs300D.model.docvecs.* with mmap=None\n",
      "INFO:gensim.utils:loading doctag_syn0 from /home/user/projekte/econstorModelling/cache/allDocs300D.model.docvecs.doctag_syn0.npy with mmap=None\n",
      "INFO:gensim.utils:loading syn0 from /home/user/projekte/econstorModelling/cache/allDocs300D.model.syn0.npy with mmap=None\n",
      "INFO:gensim.utils:loading syn1 from /home/user/projekte/econstorModelling/cache/allDocs300D.model.syn1.npy with mmap=None\n",
      "INFO:gensim.utils:setting ignored attribute syn0norm to None\n",
      "INFO:gensim.utils:setting ignored attribute cum_table to None\n",
      "INFO:root:loading completed\n",
      "INFO:root:building corpus...\n",
      "INFO:root:corpus complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 30302 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name       size\n",
      "---  -------  ------\n",
      "  0  input       300\n",
      "  1  hidden0     100\n",
      "  2  output        2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.24016\u001b[0m       \u001b[32m0.22699\u001b[0m      1.05799  0.56s\n",
      "      2       \u001b[36m0.22427\u001b[0m       \u001b[32m0.21748\u001b[0m      1.03124  0.44s\n",
      "      3       \u001b[36m0.21767\u001b[0m       \u001b[32m0.21280\u001b[0m      1.02288  0.42s\n",
      "      4       \u001b[36m0.21403\u001b[0m       \u001b[32m0.21040\u001b[0m      1.01721  0.42s\n",
      "      5       \u001b[36m0.21188\u001b[0m       \u001b[32m0.20907\u001b[0m      1.01344  0.42s\n",
      "      6       \u001b[36m0.21045\u001b[0m       \u001b[32m0.20823\u001b[0m      1.01068  0.55s\n",
      "      7       \u001b[36m0.20937\u001b[0m       \u001b[32m0.20762\u001b[0m      1.00843  0.42s\n",
      "      8       \u001b[36m0.20848\u001b[0m       \u001b[32m0.20715\u001b[0m      1.00642  0.44s\n",
      "      9       \u001b[36m0.20768\u001b[0m       \u001b[32m0.20676\u001b[0m      1.00440  0.42s\n",
      "     10       \u001b[36m0.20693\u001b[0m       \u001b[32m0.20643\u001b[0m      1.00242  0.44s\n",
      "     11       \u001b[36m0.20620\u001b[0m       \u001b[32m0.20614\u001b[0m      1.00031  0.41s\n",
      "     12       \u001b[36m0.20548\u001b[0m       \u001b[32m0.20588\u001b[0m      0.99808  0.42s\n",
      "     13       \u001b[36m0.20476\u001b[0m       \u001b[32m0.20563\u001b[0m      0.99576  0.46s\n",
      "     14       \u001b[36m0.20402\u001b[0m       \u001b[32m0.20540\u001b[0m      0.99330  0.41s\n",
      "     15       \u001b[36m0.20327\u001b[0m       \u001b[32m0.20517\u001b[0m      0.99074  0.44s\n",
      "     16       \u001b[36m0.20250\u001b[0m       \u001b[32m0.20496\u001b[0m      0.98798  0.40s\n",
      "     17       \u001b[36m0.20170\u001b[0m       \u001b[32m0.20476\u001b[0m      0.98509  0.43s\n",
      "     18       \u001b[36m0.20089\u001b[0m       \u001b[32m0.20458\u001b[0m      0.98196  0.53s\n",
      "     19       \u001b[36m0.20004\u001b[0m       \u001b[32m0.20443\u001b[0m      0.97851  0.45s\n",
      "     20       \u001b[36m0.19916\u001b[0m       \u001b[32m0.20430\u001b[0m      0.97481  0.46s\n",
      "     21       \u001b[36m0.19824\u001b[0m       \u001b[32m0.20417\u001b[0m      0.97094  0.42s\n",
      "     22       \u001b[36m0.19728\u001b[0m       \u001b[32m0.20405\u001b[0m      0.96682  0.50s\n",
      "     23       \u001b[36m0.19628\u001b[0m       \u001b[32m0.20395\u001b[0m      0.96238  0.48s\n",
      "     24       \u001b[36m0.19525\u001b[0m       \u001b[32m0.20388\u001b[0m      0.95766  0.44s\n",
      "     25       \u001b[36m0.19418\u001b[0m       \u001b[32m0.20384\u001b[0m      0.95259  0.46s\n",
      "     26       \u001b[36m0.19307\u001b[0m       \u001b[32m0.20383\u001b[0m      0.94722  0.46s\n",
      "     27       \u001b[36m0.19192\u001b[0m       0.20384      0.94151  0.44s\n",
      "     28       \u001b[36m0.19074\u001b[0m       0.20389      0.93550  0.46s\n",
      "     29       \u001b[36m0.18952\u001b[0m       0.20399      0.92906  0.43s\n",
      "     30       \u001b[36m0.18827\u001b[0m       0.20411      0.92241  0.61s\n",
      "     31       \u001b[36m0.18700\u001b[0m       0.20426      0.91550  0.42s\n",
      "     32       \u001b[36m0.18570\u001b[0m       0.20442      0.90841  0.45s\n",
      "     33       \u001b[36m0.18438\u001b[0m       0.20463      0.90104  0.43s\n",
      "     34       \u001b[36m0.18304\u001b[0m       0.20487      0.89346  0.41s\n",
      "     35       \u001b[36m0.18169\u001b[0m       0.20513      0.88573  0.46s\n",
      "     36       \u001b[36m0.18032\u001b[0m       0.20543      0.87777  0.41s\n",
      "Early stopping.\n",
      "Best valid loss was 0.203828 at epoch 26.\n",
      "Loaded parameters to layer 'hidden0' (shape 300x100).\n",
      "Loaded parameters to layer 'hidden0' (shape 100).\n",
      "Loaded parameters to layer 'output' (shape 100x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 90902 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name       size\n",
      "---  -------  ------\n",
      "  0  input       300\n",
      "  1  hidden0     300\n",
      "  2  output        2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.23793\u001b[0m       \u001b[32m0.22382\u001b[0m      1.06302  1.83s\n",
      "      2       \u001b[36m0.22182\u001b[0m       \u001b[32m0.21449\u001b[0m      1.03414  1.22s\n",
      "      3       \u001b[36m0.21552\u001b[0m       \u001b[32m0.21047\u001b[0m      1.02401  1.30s\n",
      "      4       \u001b[36m0.21229\u001b[0m       \u001b[32m0.20853\u001b[0m      1.01801  1.26s\n",
      "      5       \u001b[36m0.21039\u001b[0m       \u001b[32m0.20747\u001b[0m      1.01411  1.36s\n",
      "      6       \u001b[36m0.20906\u001b[0m       \u001b[32m0.20678\u001b[0m      1.01100  1.25s\n",
      "      7       \u001b[36m0.20797\u001b[0m       \u001b[32m0.20628\u001b[0m      1.00821  1.20s\n",
      "      8       \u001b[36m0.20700\u001b[0m       \u001b[32m0.20587\u001b[0m      1.00549  1.23s\n",
      "      9       \u001b[36m0.20608\u001b[0m       \u001b[32m0.20552\u001b[0m      1.00270  1.20s\n",
      "     10       \u001b[36m0.20517\u001b[0m       \u001b[32m0.20521\u001b[0m      0.99981  1.30s\n",
      "     11       \u001b[36m0.20426\u001b[0m       \u001b[32m0.20491\u001b[0m      0.99680  1.25s\n",
      "     12       \u001b[36m0.20332\u001b[0m       \u001b[32m0.20463\u001b[0m      0.99362  1.21s\n",
      "     13       \u001b[36m0.20235\u001b[0m       \u001b[32m0.20436\u001b[0m      0.99018  1.20s\n",
      "     14       \u001b[36m0.20134\u001b[0m       \u001b[32m0.20410\u001b[0m      0.98651  1.33s\n",
      "     15       \u001b[36m0.20029\u001b[0m       \u001b[32m0.20384\u001b[0m      0.98258  1.27s\n",
      "     16       \u001b[36m0.19919\u001b[0m       \u001b[32m0.20360\u001b[0m      0.97832  1.15s\n",
      "     17       \u001b[36m0.19803\u001b[0m       \u001b[32m0.20336\u001b[0m      0.97382  1.18s\n",
      "     18       \u001b[36m0.19683\u001b[0m       \u001b[32m0.20315\u001b[0m      0.96889  1.13s\n",
      "     19       \u001b[36m0.19556\u001b[0m       \u001b[32m0.20295\u001b[0m      0.96361  1.30s\n",
      "     20       \u001b[36m0.19423\u001b[0m       \u001b[32m0.20275\u001b[0m      0.95798  1.20s\n",
      "     21       \u001b[36m0.19284\u001b[0m       \u001b[32m0.20259\u001b[0m      0.95186  1.28s\n",
      "     22       \u001b[36m0.19137\u001b[0m       \u001b[32m0.20244\u001b[0m      0.94533  1.18s\n",
      "     23       \u001b[36m0.18985\u001b[0m       \u001b[32m0.20232\u001b[0m      0.93838  1.35s\n",
      "     24       \u001b[36m0.18826\u001b[0m       \u001b[32m0.20222\u001b[0m      0.93096  1.25s\n",
      "     25       \u001b[36m0.18660\u001b[0m       \u001b[32m0.20216\u001b[0m      0.92301  1.47s\n",
      "     26       \u001b[36m0.18487\u001b[0m       \u001b[32m0.20213\u001b[0m      0.91462  1.16s\n",
      "     27       \u001b[36m0.18308\u001b[0m       0.20213      0.90577  1.18s\n",
      "     28       \u001b[36m0.18124\u001b[0m       0.20218      0.89644  1.27s\n",
      "     29       \u001b[36m0.17935\u001b[0m       0.20225      0.88679  1.37s\n",
      "     30       \u001b[36m0.17742\u001b[0m       0.20235      0.87680  1.20s\n",
      "     31       \u001b[36m0.17545\u001b[0m       0.20248      0.86648  1.20s\n",
      "     32       \u001b[36m0.17343\u001b[0m       0.20266      0.85578  1.35s\n",
      "     33       \u001b[36m0.17139\u001b[0m       0.20287      0.84482  1.21s\n",
      "     34       \u001b[36m0.16931\u001b[0m       0.20311      0.83356  1.21s\n",
      "     35       \u001b[36m0.16720\u001b[0m       0.20339      0.82208  1.28s\n",
      "     36       \u001b[36m0.16508\u001b[0m       0.20370      0.81040  1.41s\n",
      "Early stopping.\n",
      "Best valid loss was 0.202128 at epoch 26.\n",
      "Loaded parameters to layer 'hidden0' (shape 300x300).\n",
      "Loaded parameters to layer 'hidden0' (shape 300).\n",
      "Loaded parameters to layer 'output' (shape 300x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 95492 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input        300\n",
      "  1  hidden0      250\n",
      "  2  dropout0     250\n",
      "  3  hidden1       80\n",
      "  4  output         2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.24148\u001b[0m       \u001b[32m0.22297\u001b[0m      1.08300  1.88s\n",
      "      2       \u001b[36m0.22666\u001b[0m       \u001b[32m0.21347\u001b[0m      1.06181  1.79s\n",
      "      3       \u001b[36m0.22045\u001b[0m       \u001b[32m0.21020\u001b[0m      1.04877  1.83s\n",
      "      4       \u001b[36m0.21758\u001b[0m       \u001b[32m0.20857\u001b[0m      1.04319  1.97s\n",
      "      5       \u001b[36m0.21525\u001b[0m       \u001b[32m0.20737\u001b[0m      1.03799  1.81s\n",
      "      6       \u001b[36m0.21421\u001b[0m       \u001b[32m0.20664\u001b[0m      1.03666  1.72s\n",
      "      7       \u001b[36m0.21260\u001b[0m       \u001b[32m0.20617\u001b[0m      1.03115  2.19s\n",
      "      8       \u001b[36m0.21127\u001b[0m       \u001b[32m0.20551\u001b[0m      1.02804  1.82s\n",
      "      9       \u001b[36m0.20996\u001b[0m       \u001b[32m0.20536\u001b[0m      1.02240  2.00s\n",
      "     10       \u001b[36m0.20896\u001b[0m       \u001b[32m0.20497\u001b[0m      1.01947  1.91s\n",
      "     11       \u001b[36m0.20855\u001b[0m       \u001b[32m0.20436\u001b[0m      1.02046  1.80s\n",
      "     12       \u001b[36m0.20815\u001b[0m       \u001b[32m0.20423\u001b[0m      1.01916  1.76s\n",
      "     13       \u001b[36m0.20686\u001b[0m       \u001b[32m0.20396\u001b[0m      1.01419  1.83s\n",
      "     14       \u001b[36m0.20641\u001b[0m       \u001b[32m0.20351\u001b[0m      1.01427  1.69s\n",
      "     15       \u001b[36m0.20503\u001b[0m       \u001b[32m0.20327\u001b[0m      1.00866  1.81s\n",
      "     16       \u001b[36m0.20471\u001b[0m       \u001b[32m0.20299\u001b[0m      1.00849  1.89s\n",
      "     17       \u001b[36m0.20346\u001b[0m       \u001b[32m0.20271\u001b[0m      1.00369  1.80s\n",
      "     18       \u001b[36m0.20317\u001b[0m       \u001b[32m0.20246\u001b[0m      1.00351  1.83s\n",
      "     19       \u001b[36m0.20201\u001b[0m       \u001b[32m0.20234\u001b[0m      0.99835  1.84s\n",
      "     20       0.20202       \u001b[32m0.20202\u001b[0m      0.99999  1.89s\n",
      "     21       \u001b[36m0.19983\u001b[0m       0.20217      0.98840  1.81s\n",
      "     22       \u001b[36m0.19957\u001b[0m       \u001b[32m0.20193\u001b[0m      0.98835  1.78s\n",
      "     23       \u001b[36m0.19834\u001b[0m       \u001b[32m0.20166\u001b[0m      0.98355  2.09s\n",
      "     24       \u001b[36m0.19737\u001b[0m       \u001b[32m0.20147\u001b[0m      0.97964  1.73s\n",
      "     25       \u001b[36m0.19634\u001b[0m       0.20160      0.97391  2.03s\n",
      "     26       \u001b[36m0.19538\u001b[0m       0.20149      0.96966  1.79s\n",
      "     27       \u001b[36m0.19436\u001b[0m       \u001b[32m0.20110\u001b[0m      0.96647  1.89s\n",
      "     28       \u001b[36m0.19379\u001b[0m       \u001b[32m0.20108\u001b[0m      0.96374  1.82s\n",
      "     29       \u001b[36m0.19253\u001b[0m       0.20110      0.95740  1.76s\n",
      "     30       \u001b[36m0.19206\u001b[0m       0.20112      0.95497  1.87s\n",
      "     31       \u001b[36m0.19062\u001b[0m       \u001b[32m0.20101\u001b[0m      0.94829  1.81s\n",
      "     32       \u001b[36m0.18901\u001b[0m       \u001b[32m0.20096\u001b[0m      0.94052  1.83s\n",
      "     33       \u001b[36m0.18808\u001b[0m       0.20104      0.93553  1.91s\n",
      "     34       \u001b[36m0.18669\u001b[0m       0.20122      0.92780  1.79s\n",
      "     35       \u001b[36m0.18561\u001b[0m       0.20114      0.92281  1.83s\n",
      "     36       \u001b[36m0.18422\u001b[0m       0.20123      0.91550  2.02s\n",
      "     37       \u001b[36m0.18370\u001b[0m       0.20101      0.91392  1.80s\n",
      "     38       \u001b[36m0.18189\u001b[0m       0.20121      0.90397  2.04s\n",
      "     39       \u001b[36m0.18044\u001b[0m       0.20132      0.89626  1.84s\n",
      "     40       \u001b[36m0.17909\u001b[0m       0.20150      0.88878  1.74s\n",
      "     41       \u001b[36m0.17755\u001b[0m       0.20176      0.88002  1.98s\n",
      "     42       \u001b[36m0.17733\u001b[0m       0.20189      0.87836  1.83s\n",
      "Early stopping.\n",
      "Best valid loss was 0.200959 at epoch 32.\n",
      "Loaded parameters to layer 'hidden0' (shape 300x250).\n",
      "Loaded parameters to layer 'hidden0' (shape 250).\n",
      "Loaded parameters to layer 'hidden1' (shape 250x80).\n",
      "Loaded parameters to layer 'hidden1' (shape 80).\n",
      "Loaded parameters to layer 'output' (shape 80x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 230982 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input        300\n",
      "  1  hidden0      500\n",
      "  2  dropout0     500\n",
      "  3  hidden1      160\n",
      "  4  output         2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.23787\u001b[0m       \u001b[32m0.22179\u001b[0m      1.07250  3.82s\n",
      "      2       \u001b[36m0.22318\u001b[0m       \u001b[32m0.21260\u001b[0m      1.04979  3.92s\n",
      "      3       \u001b[36m0.21748\u001b[0m       \u001b[32m0.20932\u001b[0m      1.03895  3.88s\n",
      "      4       \u001b[36m0.21482\u001b[0m       \u001b[32m0.20809\u001b[0m      1.03237  3.97s\n",
      "      5       \u001b[36m0.21250\u001b[0m       \u001b[32m0.20714\u001b[0m      1.02589  4.25s\n",
      "      6       \u001b[36m0.21205\u001b[0m       \u001b[32m0.20672\u001b[0m      1.02582  3.79s\n",
      "      7       \u001b[36m0.20999\u001b[0m       \u001b[32m0.20633\u001b[0m      1.01773  3.93s\n",
      "      8       \u001b[36m0.20851\u001b[0m       0.20636      1.01042  3.80s\n",
      "      9       \u001b[36m0.20793\u001b[0m       \u001b[32m0.20590\u001b[0m      1.00982  3.77s\n",
      "     10       \u001b[36m0.20697\u001b[0m       \u001b[32m0.20538\u001b[0m      1.00773  3.78s\n",
      "     11       \u001b[36m0.20577\u001b[0m       \u001b[32m0.20508\u001b[0m      1.00335  3.83s\n",
      "     12       \u001b[36m0.20406\u001b[0m       \u001b[32m0.20454\u001b[0m      0.99768  4.01s\n",
      "     13       \u001b[36m0.20353\u001b[0m       \u001b[32m0.20453\u001b[0m      0.99511  4.09s\n",
      "     14       \u001b[36m0.20273\u001b[0m       \u001b[32m0.20436\u001b[0m      0.99202  4.02s\n",
      "     15       \u001b[36m0.20154\u001b[0m       \u001b[32m0.20390\u001b[0m      0.98844  4.17s\n",
      "     16       \u001b[36m0.19986\u001b[0m       \u001b[32m0.20384\u001b[0m      0.98050  4.30s\n",
      "     17       \u001b[36m0.19901\u001b[0m       0.20393      0.97589  3.82s\n",
      "     18       \u001b[36m0.19763\u001b[0m       \u001b[32m0.20380\u001b[0m      0.96973  3.96s\n",
      "     19       \u001b[36m0.19650\u001b[0m       \u001b[32m0.20374\u001b[0m      0.96450  3.86s\n",
      "     20       \u001b[36m0.19520\u001b[0m       \u001b[32m0.20314\u001b[0m      0.96088  4.09s\n",
      "     21       \u001b[36m0.19394\u001b[0m       0.20352      0.95289  4.41s\n",
      "     22       \u001b[36m0.19179\u001b[0m       0.20389      0.94065  3.94s\n",
      "     23       \u001b[36m0.19075\u001b[0m       0.20377      0.93608  3.71s\n",
      "     24       \u001b[36m0.18911\u001b[0m       0.20374      0.92817  3.79s\n",
      "     25       \u001b[36m0.18782\u001b[0m       0.20382      0.92152  3.82s\n",
      "     26       \u001b[36m0.18552\u001b[0m       0.20404      0.90920  3.77s\n",
      "     27       \u001b[36m0.18373\u001b[0m       0.20423      0.89962  3.83s\n",
      "     28       \u001b[36m0.18186\u001b[0m       0.20373      0.89267  3.87s\n",
      "     29       \u001b[36m0.17971\u001b[0m       0.20445      0.87899  4.12s\n",
      "     30       \u001b[36m0.17904\u001b[0m       0.20532      0.87201  3.71s\n",
      "Early stopping.\n",
      "Best valid loss was 0.203141 at epoch 20.\n",
      "Loaded parameters to layer 'hidden0' (shape 300x500).\n",
      "Loaded parameters to layer 'hidden0' (shape 500).\n",
      "Loaded parameters to layer 'hidden1' (shape 500x160).\n",
      "Loaded parameters to layer 'hidden1' (shape 160).\n",
      "Loaded parameters to layer 'output' (shape 160x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 186672 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input        300\n",
      "  1  hidden0      400\n",
      "  2  dropout0     400\n",
      "  3  hidden1      150\n",
      "  4  dropout1     150\n",
      "  5  hidden2       40\n",
      "  6  output         2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.24650\u001b[0m       \u001b[32m0.23030\u001b[0m      1.07036  3.49s\n",
      "      2       \u001b[36m0.23270\u001b[0m       \u001b[32m0.21611\u001b[0m      1.07677  3.54s\n",
      "      3       \u001b[36m0.22503\u001b[0m       \u001b[32m0.21159\u001b[0m      1.06349  3.60s\n",
      "      4       \u001b[36m0.22118\u001b[0m       \u001b[32m0.20927\u001b[0m      1.05693  3.45s\n",
      "      5       \u001b[36m0.21831\u001b[0m       \u001b[32m0.20852\u001b[0m      1.04699  3.28s\n",
      "      6       \u001b[36m0.21692\u001b[0m       \u001b[32m0.20774\u001b[0m      1.04418  3.39s\n",
      "      7       \u001b[36m0.21494\u001b[0m       \u001b[32m0.20674\u001b[0m      1.03968  3.71s\n",
      "      8       \u001b[36m0.21358\u001b[0m       \u001b[32m0.20661\u001b[0m      1.03374  3.33s\n",
      "      9       \u001b[36m0.21304\u001b[0m       \u001b[32m0.20624\u001b[0m      1.03301  3.49s\n",
      "     10       \u001b[36m0.21155\u001b[0m       \u001b[32m0.20579\u001b[0m      1.02799  3.46s\n",
      "     11       \u001b[36m0.21086\u001b[0m       \u001b[32m0.20547\u001b[0m      1.02621  3.32s\n",
      "     12       \u001b[36m0.20976\u001b[0m       \u001b[32m0.20536\u001b[0m      1.02143  3.29s\n",
      "     13       \u001b[36m0.20910\u001b[0m       0.20549      1.01755  3.34s\n",
      "     14       \u001b[36m0.20750\u001b[0m       \u001b[32m0.20520\u001b[0m      1.01118  3.50s\n",
      "     15       0.20757       \u001b[32m0.20518\u001b[0m      1.01162  3.55s\n",
      "     16       \u001b[36m0.20601\u001b[0m       \u001b[32m0.20481\u001b[0m      1.00589  3.31s\n",
      "     17       \u001b[36m0.20569\u001b[0m       \u001b[32m0.20462\u001b[0m      1.00522  4.02s\n",
      "     18       \u001b[36m0.20447\u001b[0m       \u001b[32m0.20400\u001b[0m      1.00232  3.58s\n",
      "     19       \u001b[36m0.20407\u001b[0m       0.20438      0.99851  3.32s\n",
      "     20       \u001b[36m0.20371\u001b[0m       0.20418      0.99768  3.29s\n",
      "     21       \u001b[36m0.20192\u001b[0m       0.20425      0.98858  3.28s\n",
      "     22       \u001b[36m0.20117\u001b[0m       \u001b[32m0.20396\u001b[0m      0.98633  3.46s\n",
      "     23       0.20118       \u001b[32m0.20395\u001b[0m      0.98645  3.42s\n",
      "     24       \u001b[36m0.19996\u001b[0m       0.20413      0.97960  3.28s\n",
      "     25       \u001b[36m0.19880\u001b[0m       \u001b[32m0.20388\u001b[0m      0.97507  3.39s\n",
      "     26       \u001b[36m0.19784\u001b[0m       0.20402      0.96971  3.66s\n",
      "     27       \u001b[36m0.19663\u001b[0m       0.20400      0.96383  3.26s\n",
      "     28       \u001b[36m0.19579\u001b[0m       0.20443      0.95771  3.52s\n",
      "     29       \u001b[36m0.19497\u001b[0m       0.20491      0.95151  3.32s\n",
      "     30       \u001b[36m0.19360\u001b[0m       0.20487      0.94501  3.36s\n",
      "     31       \u001b[36m0.19276\u001b[0m       0.20437      0.94320  3.29s\n",
      "     32       \u001b[36m0.19095\u001b[0m       0.20458      0.93340  3.36s\n",
      "     33       \u001b[36m0.18866\u001b[0m       0.20447      0.92264  3.32s\n",
      "     34       \u001b[36m0.18853\u001b[0m       0.20515      0.91899  3.33s\n",
      "     35       \u001b[36m0.18831\u001b[0m       0.20512      0.91805  3.38s\n",
      "Early stopping.\n",
      "Best valid loss was 0.203879 at epoch 25.\n",
      "Loaded parameters to layer 'hidden0' (shape 300x400).\n",
      "Loaded parameters to layer 'hidden0' (shape 400).\n",
      "Loaded parameters to layer 'hidden1' (shape 400x150).\n",
      "Loaded parameters to layer 'hidden1' (shape 150).\n",
      "Loaded parameters to layer 'hidden2' (shape 150x40).\n",
      "Loaded parameters to layer 'hidden2' (shape 40).\n",
      "Loaded parameters to layer 'output' (shape 40x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 30302 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name       size\n",
      "---  -------  ------\n",
      "  0  input       300\n",
      "  1  hidden0     100\n",
      "  2  output        2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.24125\u001b[0m       \u001b[32m0.22657\u001b[0m      1.06477  0.44s\n",
      "      2       \u001b[36m0.22391\u001b[0m       \u001b[32m0.21692\u001b[0m      1.03224  0.45s\n",
      "      3       \u001b[36m0.21701\u001b[0m       \u001b[32m0.21253\u001b[0m      1.02109  0.44s\n",
      "      4       \u001b[36m0.21340\u001b[0m       \u001b[32m0.21035\u001b[0m      1.01450  0.43s\n",
      "      5       \u001b[36m0.21132\u001b[0m       \u001b[32m0.20915\u001b[0m      1.01039  0.43s\n",
      "      6       \u001b[36m0.20995\u001b[0m       \u001b[32m0.20839\u001b[0m      1.00750  0.43s\n",
      "      7       \u001b[36m0.20891\u001b[0m       \u001b[32m0.20789\u001b[0m      1.00494  0.44s\n",
      "      8       \u001b[36m0.20804\u001b[0m       \u001b[32m0.20751\u001b[0m      1.00258  0.71s\n",
      "      9       \u001b[36m0.20726\u001b[0m       \u001b[32m0.20720\u001b[0m      1.00026  0.45s\n",
      "     10       \u001b[36m0.20651\u001b[0m       \u001b[32m0.20693\u001b[0m      0.99797  0.41s\n",
      "     11       \u001b[36m0.20578\u001b[0m       \u001b[32m0.20671\u001b[0m      0.99550  0.44s\n",
      "     12       \u001b[36m0.20506\u001b[0m       \u001b[32m0.20653\u001b[0m      0.99288  0.41s\n",
      "     13       \u001b[36m0.20432\u001b[0m       \u001b[32m0.20633\u001b[0m      0.99026  0.42s\n",
      "     14       \u001b[36m0.20356\u001b[0m       \u001b[32m0.20614\u001b[0m      0.98748  0.42s\n",
      "     15       \u001b[36m0.20279\u001b[0m       \u001b[32m0.20596\u001b[0m      0.98459  0.43s\n",
      "     16       \u001b[36m0.20199\u001b[0m       \u001b[32m0.20579\u001b[0m      0.98155  0.41s\n",
      "     17       \u001b[36m0.20117\u001b[0m       \u001b[32m0.20565\u001b[0m      0.97824  0.40s\n",
      "     18       \u001b[36m0.20032\u001b[0m       \u001b[32m0.20552\u001b[0m      0.97471  0.42s\n",
      "     19       \u001b[36m0.19945\u001b[0m       \u001b[32m0.20540\u001b[0m      0.97102  0.41s\n",
      "     20       \u001b[36m0.19854\u001b[0m       \u001b[32m0.20529\u001b[0m      0.96712  0.43s\n",
      "     21       \u001b[36m0.19760\u001b[0m       \u001b[32m0.20518\u001b[0m      0.96303  0.44s\n",
      "     22       \u001b[36m0.19662\u001b[0m       \u001b[32m0.20509\u001b[0m      0.95869  0.44s\n",
      "     23       \u001b[36m0.19560\u001b[0m       \u001b[32m0.20502\u001b[0m      0.95408  0.43s\n",
      "     24       \u001b[36m0.19455\u001b[0m       \u001b[32m0.20498\u001b[0m      0.94912  0.42s\n",
      "     25       \u001b[36m0.19345\u001b[0m       \u001b[32m0.20497\u001b[0m      0.94381  0.44s\n",
      "     26       \u001b[36m0.19232\u001b[0m       0.20501      0.93810  0.41s\n",
      "     27       \u001b[36m0.19117\u001b[0m       0.20508      0.93218  0.44s\n",
      "     28       \u001b[36m0.18998\u001b[0m       0.20516      0.92604  0.44s\n",
      "     29       \u001b[36m0.18877\u001b[0m       0.20526      0.91967  0.43s\n",
      "     30       \u001b[36m0.18752\u001b[0m       0.20536      0.91311  0.42s\n",
      "     31       \u001b[36m0.18624\u001b[0m       0.20550      0.90628  0.41s\n",
      "     32       \u001b[36m0.18495\u001b[0m       0.20572      0.89904  0.44s\n",
      "     33       \u001b[36m0.18364\u001b[0m       0.20592      0.89181  0.40s\n",
      "     34       \u001b[36m0.18230\u001b[0m       0.20618      0.88420  0.41s\n",
      "     35       \u001b[36m0.18096\u001b[0m       0.20644      0.87658  0.43s\n",
      "Early stopping.\n",
      "Best valid loss was 0.204969 at epoch 25.\n",
      "Loaded parameters to layer 'hidden0' (shape 300x100).\n",
      "Loaded parameters to layer 'hidden0' (shape 100).\n",
      "Loaded parameters to layer 'output' (shape 100x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 90902 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name       size\n",
      "---  -------  ------\n",
      "  0  input       300\n",
      "  1  hidden0     300\n",
      "  2  output        2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.23424\u001b[0m       \u001b[32m0.21854\u001b[0m      1.07183  1.13s\n",
      "      2       \u001b[36m0.21935\u001b[0m       \u001b[32m0.21124\u001b[0m      1.03841  1.16s\n",
      "      3       \u001b[36m0.21417\u001b[0m       \u001b[32m0.20846\u001b[0m      1.02738  1.21s\n",
      "      4       \u001b[36m0.21150\u001b[0m       \u001b[32m0.20723\u001b[0m      1.02059  1.18s\n",
      "      5       \u001b[36m0.20981\u001b[0m       \u001b[32m0.20656\u001b[0m      1.01571  1.23s\n",
      "      6       \u001b[36m0.20852\u001b[0m       \u001b[32m0.20611\u001b[0m      1.01171  1.23s\n",
      "      7       \u001b[36m0.20742\u001b[0m       \u001b[32m0.20575\u001b[0m      1.00811  1.21s\n",
      "      8       \u001b[36m0.20640\u001b[0m       \u001b[32m0.20543\u001b[0m      1.00474  1.26s\n",
      "      9       \u001b[36m0.20542\u001b[0m       \u001b[32m0.20514\u001b[0m      1.00135  1.20s\n",
      "     10       \u001b[36m0.20444\u001b[0m       \u001b[32m0.20487\u001b[0m      0.99792  1.28s\n",
      "     11       \u001b[36m0.20345\u001b[0m       \u001b[32m0.20462\u001b[0m      0.99431  1.23s\n",
      "     12       \u001b[36m0.20245\u001b[0m       \u001b[32m0.20438\u001b[0m      0.99055  1.57s\n",
      "     13       \u001b[36m0.20141\u001b[0m       \u001b[32m0.20415\u001b[0m      0.98655  1.14s\n",
      "     14       \u001b[36m0.20033\u001b[0m       \u001b[32m0.20393\u001b[0m      0.98233  1.17s\n",
      "     15       \u001b[36m0.19920\u001b[0m       \u001b[32m0.20369\u001b[0m      0.97796  1.14s\n",
      "     16       \u001b[36m0.19803\u001b[0m       \u001b[32m0.20349\u001b[0m      0.97316  1.13s\n",
      "     17       \u001b[36m0.19680\u001b[0m       \u001b[32m0.20330\u001b[0m      0.96806  1.28s\n",
      "     18       \u001b[36m0.19552\u001b[0m       \u001b[32m0.20312\u001b[0m      0.96259  1.16s\n",
      "     19       \u001b[36m0.19417\u001b[0m       \u001b[32m0.20294\u001b[0m      0.95680  1.14s\n",
      "     20       \u001b[36m0.19277\u001b[0m       \u001b[32m0.20277\u001b[0m      0.95066  1.16s\n",
      "     21       \u001b[36m0.19130\u001b[0m       \u001b[32m0.20264\u001b[0m      0.94406  1.15s\n",
      "     22       \u001b[36m0.18977\u001b[0m       \u001b[32m0.20252\u001b[0m      0.93703  1.16s\n",
      "     23       \u001b[36m0.18818\u001b[0m       \u001b[32m0.20243\u001b[0m      0.92958  1.19s\n",
      "     24       \u001b[36m0.18652\u001b[0m       \u001b[32m0.20235\u001b[0m      0.92179  1.14s\n",
      "     25       \u001b[36m0.18481\u001b[0m       \u001b[32m0.20230\u001b[0m      0.91356  1.18s\n",
      "     26       \u001b[36m0.18303\u001b[0m       \u001b[32m0.20228\u001b[0m      0.90485  1.15s\n",
      "     27       \u001b[36m0.18121\u001b[0m       0.20230      0.89575  1.16s\n",
      "     28       \u001b[36m0.17931\u001b[0m       0.20233      0.88623  1.14s\n",
      "     29       \u001b[36m0.17737\u001b[0m       0.20243      0.87618  1.13s\n",
      "     30       \u001b[36m0.17537\u001b[0m       0.20255      0.86584  1.19s\n",
      "     31       \u001b[36m0.17333\u001b[0m       0.20270      0.85510  1.19s\n",
      "     32       \u001b[36m0.17124\u001b[0m       0.20291      0.84392  1.16s\n",
      "     33       \u001b[36m0.16912\u001b[0m       0.20311      0.83265  1.22s\n",
      "     34       \u001b[36m0.16696\u001b[0m       0.20336      0.82099  1.15s\n",
      "     35       \u001b[36m0.16476\u001b[0m       0.20363      0.80912  1.21s\n",
      "     36       \u001b[36m0.16255\u001b[0m       0.20393      0.79707  1.24s\n",
      "Early stopping.\n",
      "Best valid loss was 0.202282 at epoch 26.\n",
      "Loaded parameters to layer 'hidden0' (shape 300x300).\n",
      "Loaded parameters to layer 'hidden0' (shape 300).\n",
      "Loaded parameters to layer 'output' (shape 300x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 95492 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input        300\n",
      "  1  hidden0      250\n",
      "  2  dropout0     250\n",
      "  3  hidden1       80\n",
      "  4  output         2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.24418\u001b[0m       \u001b[32m0.22667\u001b[0m      1.07726  1.67s\n",
      "      2       \u001b[36m0.23113\u001b[0m       \u001b[32m0.21736\u001b[0m      1.06332  2.00s\n",
      "      3       \u001b[36m0.22612\u001b[0m       \u001b[32m0.21379\u001b[0m      1.05767  1.72s\n",
      "      4       \u001b[36m0.22308\u001b[0m       \u001b[32m0.21167\u001b[0m      1.05391  1.69s\n",
      "      5       \u001b[36m0.22011\u001b[0m       \u001b[32m0.20996\u001b[0m      1.04835  1.81s\n",
      "      6       \u001b[36m0.21873\u001b[0m       \u001b[32m0.20917\u001b[0m      1.04572  1.65s\n",
      "      7       \u001b[36m0.21761\u001b[0m       \u001b[32m0.20816\u001b[0m      1.04542  1.68s\n",
      "      8       \u001b[36m0.21641\u001b[0m       \u001b[32m0.20809\u001b[0m      1.03999  1.82s\n",
      "      9       \u001b[36m0.21516\u001b[0m       \u001b[32m0.20795\u001b[0m      1.03468  1.71s\n",
      "     10       \u001b[36m0.21419\u001b[0m       \u001b[32m0.20716\u001b[0m      1.03392  1.69s\n",
      "     11       \u001b[36m0.21272\u001b[0m       \u001b[32m0.20702\u001b[0m      1.02756  1.67s\n",
      "     12       0.21312       \u001b[32m0.20664\u001b[0m      1.03135  1.68s\n",
      "     13       \u001b[36m0.21197\u001b[0m       \u001b[32m0.20655\u001b[0m      1.02627  1.70s\n",
      "     14       \u001b[36m0.21121\u001b[0m       \u001b[32m0.20634\u001b[0m      1.02355  1.68s\n",
      "     15       \u001b[36m0.21072\u001b[0m       \u001b[32m0.20586\u001b[0m      1.02357  1.68s\n",
      "     16       \u001b[36m0.20943\u001b[0m       \u001b[32m0.20579\u001b[0m      1.01770  1.66s\n",
      "     17       0.20951       \u001b[32m0.20551\u001b[0m      1.01950  1.73s\n",
      "     18       \u001b[36m0.20871\u001b[0m       \u001b[32m0.20548\u001b[0m      1.01571  1.87s\n",
      "     19       \u001b[36m0.20825\u001b[0m       \u001b[32m0.20525\u001b[0m      1.01464  1.73s\n",
      "     20       \u001b[36m0.20696\u001b[0m       \u001b[32m0.20498\u001b[0m      1.00966  1.71s\n",
      "     21       \u001b[36m0.20681\u001b[0m       \u001b[32m0.20469\u001b[0m      1.01037  2.08s\n",
      "     22       \u001b[36m0.20622\u001b[0m       \u001b[32m0.20452\u001b[0m      1.00831  1.65s\n",
      "     23       \u001b[36m0.20617\u001b[0m       0.20463      1.00753  1.68s\n",
      "     24       \u001b[36m0.20568\u001b[0m       \u001b[32m0.20439\u001b[0m      1.00629  1.87s\n",
      "     25       \u001b[36m0.20451\u001b[0m       \u001b[32m0.20409\u001b[0m      1.00205  1.69s\n",
      "     26       \u001b[36m0.20417\u001b[0m       \u001b[32m0.20377\u001b[0m      1.00194  1.73s\n",
      "     27       \u001b[36m0.20363\u001b[0m       \u001b[32m0.20373\u001b[0m      0.99952  1.72s\n",
      "     28       \u001b[36m0.20289\u001b[0m       0.20409      0.99409  1.70s\n",
      "     29       \u001b[36m0.20274\u001b[0m       \u001b[32m0.20372\u001b[0m      0.99516  1.69s\n",
      "     30       \u001b[36m0.20216\u001b[0m       0.20385      0.99171  1.77s\n",
      "     31       \u001b[36m0.20155\u001b[0m       \u001b[32m0.20372\u001b[0m      0.98937  1.81s\n",
      "     32       \u001b[36m0.20120\u001b[0m       \u001b[32m0.20353\u001b[0m      0.98855  1.78s\n",
      "     33       \u001b[36m0.20018\u001b[0m       0.20357      0.98335  1.73s\n",
      "     34       \u001b[36m0.19948\u001b[0m       \u001b[32m0.20292\u001b[0m      0.98306  1.69s\n",
      "     35       \u001b[36m0.19929\u001b[0m       0.20310      0.98124  1.80s\n",
      "     36       \u001b[36m0.19860\u001b[0m       0.20329      0.97694  1.95s\n",
      "     37       \u001b[36m0.19795\u001b[0m       \u001b[32m0.20284\u001b[0m      0.97585  1.80s\n",
      "     38       \u001b[36m0.19710\u001b[0m       0.20291      0.97135  1.82s\n",
      "     39       0.19725       0.20322      0.97060  2.00s\n",
      "     40       \u001b[36m0.19636\u001b[0m       0.20288      0.96786  1.69s\n",
      "     41       \u001b[36m0.19577\u001b[0m       0.20323      0.96330  1.74s\n",
      "     42       \u001b[36m0.19509\u001b[0m       0.20300      0.96103  1.88s\n",
      "     43       \u001b[36m0.19478\u001b[0m       \u001b[32m0.20277\u001b[0m      0.96057  1.69s\n",
      "     44       \u001b[36m0.19350\u001b[0m       0.20288      0.95377  1.70s\n",
      "     45       \u001b[36m0.19303\u001b[0m       0.20313      0.95025  1.77s\n",
      "     46       \u001b[36m0.19288\u001b[0m       0.20300      0.95015  1.71s\n",
      "     47       \u001b[36m0.19176\u001b[0m       0.20297      0.94478  1.79s\n",
      "     48       \u001b[36m0.19092\u001b[0m       0.20297      0.94065  1.78s\n",
      "     49       \u001b[36m0.19024\u001b[0m       0.20320      0.93619  1.73s\n",
      "     50       \u001b[36m0.18964\u001b[0m       0.20330      0.93283  1.72s\n",
      "     51       \u001b[36m0.18933\u001b[0m       \u001b[32m0.20261\u001b[0m      0.93445  1.76s\n",
      "     52       \u001b[36m0.18801\u001b[0m       \u001b[32m0.20254\u001b[0m      0.92828  1.71s\n",
      "     53       \u001b[36m0.18723\u001b[0m       \u001b[32m0.20231\u001b[0m      0.92544  1.72s\n",
      "     54       \u001b[36m0.18716\u001b[0m       0.20245      0.92447  1.76s\n",
      "     55       \u001b[36m0.18647\u001b[0m       0.20259      0.92046  1.86s\n",
      "     56       0.18656       0.20285      0.91973  1.68s\n",
      "     57       \u001b[36m0.18483\u001b[0m       0.20280      0.91142  1.74s\n",
      "     58       \u001b[36m0.18450\u001b[0m       0.20303      0.90874  2.17s\n",
      "     59       \u001b[36m0.18253\u001b[0m       0.20338      0.89747  1.79s\n",
      "     60       \u001b[36m0.18179\u001b[0m       0.20374      0.89228  1.97s\n",
      "     61       \u001b[36m0.18153\u001b[0m       0.20344      0.89232  1.73s\n",
      "     62       0.18170       0.20324      0.89401  1.82s\n",
      "     63       \u001b[36m0.17986\u001b[0m       0.20338      0.88434  1.74s\n",
      "Early stopping.\n",
      "Best valid loss was 0.202311 at epoch 53.\n",
      "Loaded parameters to layer 'hidden0' (shape 300x250).\n",
      "Loaded parameters to layer 'hidden0' (shape 250).\n",
      "Loaded parameters to layer 'hidden1' (shape 250x80).\n",
      "Loaded parameters to layer 'hidden1' (shape 80).\n",
      "Loaded parameters to layer 'output' (shape 80x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 230982 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input        300\n",
      "  1  hidden0      500\n",
      "  2  dropout0     500\n",
      "  3  hidden1      160\n",
      "  4  output         2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.24125\u001b[0m       \u001b[32m0.22322\u001b[0m      1.08078  3.77s\n",
      "      2       \u001b[36m0.22708\u001b[0m       \u001b[32m0.21415\u001b[0m      1.06037  3.59s\n",
      "      3       \u001b[36m0.22179\u001b[0m       \u001b[32m0.21077\u001b[0m      1.05231  3.72s\n",
      "      4       \u001b[36m0.21901\u001b[0m       \u001b[32m0.20885\u001b[0m      1.04866  3.90s\n",
      "      5       \u001b[36m0.21672\u001b[0m       \u001b[32m0.20830\u001b[0m      1.04043  3.95s\n",
      "      6       \u001b[36m0.21513\u001b[0m       \u001b[32m0.20709\u001b[0m      1.03881  3.90s\n",
      "      7       \u001b[36m0.21420\u001b[0m       \u001b[32m0.20657\u001b[0m      1.03691  3.83s\n",
      "      8       \u001b[36m0.21314\u001b[0m       0.20665      1.03140  3.60s\n",
      "      9       \u001b[36m0.21226\u001b[0m       \u001b[32m0.20588\u001b[0m      1.03100  3.55s\n",
      "     10       \u001b[36m0.21121\u001b[0m       \u001b[32m0.20547\u001b[0m      1.02794  3.68s\n",
      "     11       \u001b[36m0.21064\u001b[0m       0.20550      1.02502  3.68s\n",
      "     12       \u001b[36m0.20978\u001b[0m       \u001b[32m0.20532\u001b[0m      1.02173  3.51s\n",
      "     13       \u001b[36m0.20864\u001b[0m       \u001b[32m0.20520\u001b[0m      1.01680  3.75s\n",
      "     14       \u001b[36m0.20765\u001b[0m       \u001b[32m0.20446\u001b[0m      1.01562  3.58s\n",
      "     15       \u001b[36m0.20728\u001b[0m       \u001b[32m0.20416\u001b[0m      1.01530  4.00s\n",
      "     16       \u001b[36m0.20630\u001b[0m       \u001b[32m0.20403\u001b[0m      1.01111  3.84s\n",
      "     17       \u001b[36m0.20558\u001b[0m       0.20410      1.00727  3.77s\n",
      "     18       \u001b[36m0.20468\u001b[0m       \u001b[32m0.20390\u001b[0m      1.00383  3.85s\n",
      "     19       \u001b[36m0.20445\u001b[0m       \u001b[32m0.20385\u001b[0m      1.00298  3.74s\n",
      "     20       \u001b[36m0.20303\u001b[0m       \u001b[32m0.20375\u001b[0m      0.99649  3.78s\n",
      "     21       \u001b[36m0.20282\u001b[0m       \u001b[32m0.20363\u001b[0m      0.99602  3.56s\n",
      "     22       \u001b[36m0.20244\u001b[0m       \u001b[32m0.20324\u001b[0m      0.99606  3.87s\n",
      "     23       \u001b[36m0.20128\u001b[0m       \u001b[32m0.20315\u001b[0m      0.99083  3.94s\n",
      "     24       \u001b[36m0.20065\u001b[0m       \u001b[32m0.20291\u001b[0m      0.98883  3.63s\n",
      "     25       \u001b[36m0.20018\u001b[0m       0.20314      0.98543  3.66s\n",
      "     26       \u001b[36m0.19911\u001b[0m       0.20317      0.98002  3.66s\n",
      "     27       \u001b[36m0.19834\u001b[0m       \u001b[32m0.20285\u001b[0m      0.97777  3.56s\n",
      "     28       \u001b[36m0.19712\u001b[0m       0.20296      0.97124  3.65s\n",
      "     29       \u001b[36m0.19690\u001b[0m       \u001b[32m0.20246\u001b[0m      0.97252  3.68s\n",
      "     30       \u001b[36m0.19540\u001b[0m       \u001b[32m0.20245\u001b[0m      0.96517  3.58s\n",
      "     31       \u001b[36m0.19429\u001b[0m       \u001b[32m0.20239\u001b[0m      0.95997  3.82s\n",
      "     32       \u001b[36m0.19415\u001b[0m       \u001b[32m0.20211\u001b[0m      0.96063  3.88s\n",
      "     33       \u001b[36m0.19286\u001b[0m       0.20222      0.95372  3.98s\n",
      "     34       \u001b[36m0.19269\u001b[0m       \u001b[32m0.20193\u001b[0m      0.95424  3.77s\n",
      "     35       \u001b[36m0.19091\u001b[0m       \u001b[32m0.20178\u001b[0m      0.94613  3.78s\n",
      "     36       \u001b[36m0.18906\u001b[0m       0.20230      0.93457  3.79s\n",
      "     37       \u001b[36m0.18895\u001b[0m       0.20236      0.93376  3.75s\n",
      "     38       \u001b[36m0.18804\u001b[0m       0.20210      0.93045  3.74s\n",
      "     39       \u001b[36m0.18777\u001b[0m       0.20271      0.92629  3.78s\n",
      "     40       \u001b[36m0.18579\u001b[0m       0.20209      0.91933  3.84s\n",
      "     41       \u001b[36m0.18436\u001b[0m       0.20261      0.90994  4.15s\n",
      "     42       \u001b[36m0.18367\u001b[0m       0.20220      0.90834  3.82s\n",
      "     43       \u001b[36m0.18308\u001b[0m       0.20232      0.90487  3.76s\n",
      "     44       \u001b[36m0.18167\u001b[0m       0.20255      0.89688  3.82s\n",
      "     45       \u001b[36m0.18032\u001b[0m       0.20226      0.89154  3.90s\n",
      "Early stopping.\n",
      "Best valid loss was 0.201779 at epoch 35.\n",
      "Loaded parameters to layer 'hidden0' (shape 300x500).\n",
      "Loaded parameters to layer 'hidden0' (shape 500).\n",
      "Loaded parameters to layer 'hidden1' (shape 500x160).\n",
      "Loaded parameters to layer 'hidden1' (shape 160).\n",
      "Loaded parameters to layer 'output' (shape 160x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 186672 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input        300\n",
      "  1  hidden0      400\n",
      "  2  dropout0     400\n",
      "  3  hidden1      150\n",
      "  4  dropout1     150\n",
      "  5  hidden2       40\n",
      "  6  output         2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.24907\u001b[0m       \u001b[32m0.24665\u001b[0m      1.00983  3.37s\n",
      "      2       \u001b[36m0.24278\u001b[0m       \u001b[32m0.23662\u001b[0m      1.02603  3.40s\n",
      "      3       \u001b[36m0.23635\u001b[0m       \u001b[32m0.22789\u001b[0m      1.03710  3.61s\n",
      "      4       \u001b[36m0.23096\u001b[0m       \u001b[32m0.22354\u001b[0m      1.03319  3.34s\n",
      "      5       \u001b[36m0.22748\u001b[0m       \u001b[32m0.22182\u001b[0m      1.02556  3.48s\n",
      "      6       \u001b[36m0.22485\u001b[0m       \u001b[32m0.21964\u001b[0m      1.02372  3.47s\n",
      "      7       \u001b[36m0.22418\u001b[0m       \u001b[32m0.21770\u001b[0m      1.02974  3.45s\n",
      "      8       \u001b[36m0.22078\u001b[0m       \u001b[32m0.21572\u001b[0m      1.02345  3.43s\n",
      "      9       \u001b[36m0.21976\u001b[0m       \u001b[32m0.21460\u001b[0m      1.02405  3.48s\n",
      "     10       \u001b[36m0.21897\u001b[0m       \u001b[32m0.21362\u001b[0m      1.02506  3.36s\n",
      "     11       \u001b[36m0.21770\u001b[0m       \u001b[32m0.21239\u001b[0m      1.02498  3.44s\n",
      "     12       \u001b[36m0.21697\u001b[0m       \u001b[32m0.21237\u001b[0m      1.02164  3.46s\n",
      "     13       \u001b[36m0.21605\u001b[0m       \u001b[32m0.21160\u001b[0m      1.02100  3.75s\n",
      "     14       \u001b[36m0.21557\u001b[0m       0.21177      1.01795  3.48s\n",
      "     15       \u001b[36m0.21545\u001b[0m       \u001b[32m0.21057\u001b[0m      1.02314  3.49s\n",
      "     16       \u001b[36m0.21447\u001b[0m       \u001b[32m0.20987\u001b[0m      1.02192  3.33s\n",
      "     17       \u001b[36m0.21344\u001b[0m       \u001b[32m0.20977\u001b[0m      1.01751  3.61s\n",
      "     18       \u001b[36m0.21265\u001b[0m       \u001b[32m0.20949\u001b[0m      1.01505  3.38s\n",
      "     19       \u001b[36m0.21248\u001b[0m       \u001b[32m0.20932\u001b[0m      1.01511  3.60s\n",
      "     20       \u001b[36m0.21233\u001b[0m       0.20944      1.01381  3.52s\n",
      "     21       \u001b[36m0.21140\u001b[0m       \u001b[32m0.20891\u001b[0m      1.01190  3.48s\n",
      "     22       \u001b[36m0.21096\u001b[0m       0.20899      1.00940  3.84s\n",
      "     23       \u001b[36m0.21026\u001b[0m       \u001b[32m0.20838\u001b[0m      1.00901  3.59s\n",
      "     24       \u001b[36m0.20909\u001b[0m       \u001b[32m0.20835\u001b[0m      1.00356  3.62s\n",
      "     25       0.20950       \u001b[32m0.20834\u001b[0m      1.00554  3.50s\n",
      "     26       \u001b[36m0.20883\u001b[0m       \u001b[32m0.20808\u001b[0m      1.00360  3.36s\n",
      "     27       \u001b[36m0.20775\u001b[0m       \u001b[32m0.20801\u001b[0m      0.99874  3.42s\n",
      "     28       \u001b[36m0.20762\u001b[0m       \u001b[32m0.20781\u001b[0m      0.99911  3.42s\n",
      "     29       \u001b[36m0.20743\u001b[0m       0.20792      0.99763  3.40s\n",
      "     30       \u001b[36m0.20695\u001b[0m       0.20793      0.99527  3.34s\n",
      "     31       \u001b[36m0.20582\u001b[0m       \u001b[32m0.20761\u001b[0m      0.99141  3.66s\n",
      "     32       \u001b[36m0.20582\u001b[0m       0.20781      0.99045  3.66s\n",
      "     33       \u001b[36m0.20515\u001b[0m       0.20794      0.98657  3.30s\n",
      "     34       \u001b[36m0.20486\u001b[0m       \u001b[32m0.20721\u001b[0m      0.98867  3.32s\n",
      "     35       \u001b[36m0.20447\u001b[0m       0.20729      0.98638  3.41s\n",
      "     36       \u001b[36m0.20359\u001b[0m       0.20808      0.97844  3.36s\n",
      "     37       \u001b[36m0.20294\u001b[0m       0.20790      0.97615  3.42s\n",
      "     38       \u001b[36m0.20286\u001b[0m       0.20771      0.97669  3.52s\n",
      "     39       \u001b[36m0.20228\u001b[0m       \u001b[32m0.20711\u001b[0m      0.97671  3.59s\n",
      "     40       \u001b[36m0.20190\u001b[0m       0.20729      0.97399  3.60s\n",
      "     41       \u001b[36m0.20095\u001b[0m       \u001b[32m0.20708\u001b[0m      0.97038  3.32s\n",
      "     42       \u001b[36m0.20055\u001b[0m       \u001b[32m0.20631\u001b[0m      0.97207  3.84s\n",
      "     43       \u001b[36m0.19977\u001b[0m       0.20671      0.96642  3.78s\n",
      "     44       \u001b[36m0.19930\u001b[0m       0.20700      0.96277  3.52s\n",
      "     45       0.19932       0.20666      0.96448  3.39s\n",
      "     46       \u001b[36m0.19789\u001b[0m       0.20714      0.95533  3.67s\n",
      "     47       \u001b[36m0.19733\u001b[0m       \u001b[32m0.20618\u001b[0m      0.95709  3.44s\n",
      "     48       \u001b[36m0.19732\u001b[0m       0.20677      0.95426  3.52s\n",
      "     49       \u001b[36m0.19593\u001b[0m       0.20635      0.94950  3.75s\n",
      "     50       0.19620       0.20673      0.94905  3.48s\n",
      "     51       \u001b[36m0.19376\u001b[0m       0.20619      0.93974  3.43s\n",
      "     52       0.19412       \u001b[32m0.20612\u001b[0m      0.94181  3.43s\n",
      "     53       0.19385       0.20693      0.93679  3.37s\n",
      "     54       \u001b[36m0.19206\u001b[0m       0.20694      0.92812  3.35s\n",
      "     55       \u001b[36m0.19125\u001b[0m       0.20702      0.92380  3.35s\n",
      "     56       \u001b[36m0.19017\u001b[0m       \u001b[32m0.20581\u001b[0m      0.92399  3.39s\n",
      "     57       \u001b[36m0.18944\u001b[0m       0.20583      0.92037  3.34s\n",
      "     58       \u001b[36m0.18921\u001b[0m       0.20593      0.91883  3.55s\n",
      "     59       \u001b[36m0.18779\u001b[0m       0.20660      0.90893  3.32s\n",
      "     60       \u001b[36m0.18708\u001b[0m       0.20646      0.90610  3.74s\n",
      "     61       \u001b[36m0.18562\u001b[0m       0.20786      0.89305  3.36s\n",
      "     62       \u001b[36m0.18463\u001b[0m       0.20660      0.89365  3.34s\n",
      "     63       \u001b[36m0.18444\u001b[0m       0.20631      0.89399  3.21s\n",
      "     64       \u001b[36m0.18266\u001b[0m       0.20674      0.88352  3.30s\n",
      "     65       \u001b[36m0.18189\u001b[0m       0.20609      0.88257  3.31s\n",
      "     66       \u001b[36m0.18095\u001b[0m       0.20694      0.87441  3.45s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:start loading the model\n",
      "INFO:gensim.utils:loading Doc2Vec object from /home/user/projekte/econstorModelling/cache/allDocs600D.model\n",
      "INFO:gensim.utils:loading docvecs recursively from /home/user/projekte/econstorModelling/cache/allDocs600D.model.docvecs.* with mmap=None\n",
      "INFO:gensim.utils:loading doctag_syn0 from /home/user/projekte/econstorModelling/cache/allDocs600D.model.docvecs.doctag_syn0.npy with mmap=None\n",
      "INFO:gensim.utils:loading syn1 from /home/user/projekte/econstorModelling/cache/allDocs600D.model.syn1.npy with mmap=None\n",
      "INFO:gensim.utils:loading syn0 from /home/user/projekte/econstorModelling/cache/allDocs600D.model.syn0.npy with mmap=None\n",
      "INFO:gensim.utils:setting ignored attribute syn0norm to None\n",
      "INFO:gensim.utils:setting ignored attribute cum_table to None\n",
      "INFO:root:loading completed\n",
      "INFO:root:building corpus...\n",
      "INFO:root:corpus complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping.\n",
      "Best valid loss was 0.205815 at epoch 56.\n",
      "Loaded parameters to layer 'hidden0' (shape 300x400).\n",
      "Loaded parameters to layer 'hidden0' (shape 400).\n",
      "Loaded parameters to layer 'hidden1' (shape 400x150).\n",
      "Loaded parameters to layer 'hidden1' (shape 150).\n",
      "Loaded parameters to layer 'hidden2' (shape 150x40).\n",
      "Loaded parameters to layer 'hidden2' (shape 40).\n",
      "Loaded parameters to layer 'output' (shape 40x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 60302 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name       size\n",
      "---  -------  ------\n",
      "  0  input       600\n",
      "  1  hidden0     100\n",
      "  2  output        2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.23706\u001b[0m       \u001b[32m0.22830\u001b[0m      1.03836  0.83s\n",
      "      2       \u001b[36m0.22067\u001b[0m       \u001b[32m0.21978\u001b[0m      1.00408  0.76s\n",
      "      3       \u001b[36m0.21381\u001b[0m       \u001b[32m0.21530\u001b[0m      0.99308  0.82s\n",
      "      4       \u001b[36m0.20994\u001b[0m       \u001b[32m0.21281\u001b[0m      0.98649  0.80s\n",
      "      5       \u001b[36m0.20744\u001b[0m       \u001b[32m0.21141\u001b[0m      0.98123  0.78s\n",
      "      6       \u001b[36m0.20563\u001b[0m       \u001b[32m0.21055\u001b[0m      0.97661  1.11s\n",
      "      7       \u001b[36m0.20418\u001b[0m       \u001b[32m0.21003\u001b[0m      0.97213  0.79s\n",
      "      8       \u001b[36m0.20295\u001b[0m       \u001b[32m0.20968\u001b[0m      0.96789  0.78s\n",
      "      9       \u001b[36m0.20183\u001b[0m       \u001b[32m0.20945\u001b[0m      0.96360  0.75s\n",
      "     10       \u001b[36m0.20077\u001b[0m       \u001b[32m0.20928\u001b[0m      0.95933  0.74s\n",
      "     11       \u001b[36m0.19972\u001b[0m       \u001b[32m0.20915\u001b[0m      0.95492  0.72s\n",
      "     12       \u001b[36m0.19868\u001b[0m       \u001b[32m0.20904\u001b[0m      0.95042  0.81s\n",
      "     13       \u001b[36m0.19762\u001b[0m       \u001b[32m0.20894\u001b[0m      0.94581  0.88s\n",
      "     14       \u001b[36m0.19652\u001b[0m       \u001b[32m0.20882\u001b[0m      0.94110  0.72s\n",
      "     15       \u001b[36m0.19538\u001b[0m       \u001b[32m0.20872\u001b[0m      0.93611  0.76s\n",
      "     16       \u001b[36m0.19420\u001b[0m       \u001b[32m0.20861\u001b[0m      0.93092  0.74s\n",
      "     17       \u001b[36m0.19296\u001b[0m       \u001b[32m0.20851\u001b[0m      0.92542  0.74s\n",
      "     18       \u001b[36m0.19165\u001b[0m       \u001b[32m0.20841\u001b[0m      0.91956  0.72s\n",
      "     19       \u001b[36m0.19026\u001b[0m       \u001b[32m0.20831\u001b[0m      0.91336  0.76s\n",
      "     20       \u001b[36m0.18881\u001b[0m       \u001b[32m0.20822\u001b[0m      0.90678  0.77s\n",
      "     21       \u001b[36m0.18728\u001b[0m       \u001b[32m0.20813\u001b[0m      0.89985  0.76s\n",
      "     22       \u001b[36m0.18568\u001b[0m       \u001b[32m0.20806\u001b[0m      0.89243  0.74s\n",
      "     23       \u001b[36m0.18401\u001b[0m       \u001b[32m0.20804\u001b[0m      0.88451  0.85s\n",
      "     24       \u001b[36m0.18226\u001b[0m       \u001b[32m0.20801\u001b[0m      0.87622  0.80s\n",
      "     25       \u001b[36m0.18042\u001b[0m       0.20803      0.86729  0.82s\n",
      "     26       \u001b[36m0.17852\u001b[0m       0.20805      0.85804  0.80s\n",
      "     27       \u001b[36m0.17653\u001b[0m       0.20810      0.84831  0.77s\n",
      "     28       \u001b[36m0.17449\u001b[0m       0.20820      0.83808  0.75s\n",
      "     29       \u001b[36m0.17237\u001b[0m       0.20832      0.82745  0.77s\n",
      "     30       \u001b[36m0.17019\u001b[0m       0.20843      0.81654  0.73s\n",
      "     31       \u001b[36m0.16795\u001b[0m       0.20859      0.80520  0.73s\n",
      "     32       \u001b[36m0.16566\u001b[0m       0.20877      0.79350  0.74s\n",
      "     33       \u001b[36m0.16331\u001b[0m       0.20899      0.78143  0.77s\n",
      "     34       \u001b[36m0.16092\u001b[0m       0.20927      0.76897  0.74s\n",
      "Early stopping.\n",
      "Best valid loss was 0.208008 at epoch 24.\n",
      "Loaded parameters to layer 'hidden0' (shape 600x100).\n",
      "Loaded parameters to layer 'hidden0' (shape 100).\n",
      "Loaded parameters to layer 'output' (shape 100x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 180902 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name       size\n",
      "---  -------  ------\n",
      "  0  input       600\n",
      "  1  hidden0     300\n",
      "  2  output        2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.23672\u001b[0m       \u001b[32m0.22670\u001b[0m      1.04421  2.13s\n",
      "      2       \u001b[36m0.21947\u001b[0m       \u001b[32m0.21845\u001b[0m      1.00463  2.06s\n",
      "      3       \u001b[36m0.21251\u001b[0m       \u001b[32m0.21425\u001b[0m      0.99190  2.23s\n",
      "      4       \u001b[36m0.20857\u001b[0m       \u001b[32m0.21189\u001b[0m      0.98433  2.20s\n",
      "      5       \u001b[36m0.20598\u001b[0m       \u001b[32m0.21051\u001b[0m      0.97847  2.44s\n",
      "      6       \u001b[36m0.20402\u001b[0m       \u001b[32m0.20963\u001b[0m      0.97323  2.23s\n",
      "      7       \u001b[36m0.20238\u001b[0m       \u001b[32m0.20904\u001b[0m      0.96814  2.27s\n",
      "      8       \u001b[36m0.20090\u001b[0m       \u001b[32m0.20862\u001b[0m      0.96301  2.19s\n",
      "      9       \u001b[36m0.19950\u001b[0m       \u001b[32m0.20830\u001b[0m      0.95775  2.17s\n",
      "     10       \u001b[36m0.19814\u001b[0m       \u001b[32m0.20805\u001b[0m      0.95235  2.26s\n",
      "     11       \u001b[36m0.19676\u001b[0m       \u001b[32m0.20782\u001b[0m      0.94677  2.21s\n",
      "     12       \u001b[36m0.19535\u001b[0m       \u001b[32m0.20761\u001b[0m      0.94094  2.15s\n",
      "     13       \u001b[36m0.19388\u001b[0m       \u001b[32m0.20741\u001b[0m      0.93474  2.14s\n",
      "     14       \u001b[36m0.19234\u001b[0m       \u001b[32m0.20721\u001b[0m      0.92826  2.22s\n",
      "     15       \u001b[36m0.19072\u001b[0m       \u001b[32m0.20701\u001b[0m      0.92129  2.17s\n",
      "     16       \u001b[36m0.18899\u001b[0m       \u001b[32m0.20682\u001b[0m      0.91380  2.05s\n",
      "     17       \u001b[36m0.18715\u001b[0m       \u001b[32m0.20661\u001b[0m      0.90580  2.12s\n",
      "     18       \u001b[36m0.18518\u001b[0m       \u001b[32m0.20640\u001b[0m      0.89719  2.13s\n",
      "     19       \u001b[36m0.18307\u001b[0m       \u001b[32m0.20618\u001b[0m      0.88788  2.09s\n",
      "     20       \u001b[36m0.18082\u001b[0m       \u001b[32m0.20599\u001b[0m      0.87779  2.03s\n",
      "     21       \u001b[36m0.17842\u001b[0m       \u001b[32m0.20579\u001b[0m      0.86699  2.47s\n",
      "     22       \u001b[36m0.17587\u001b[0m       \u001b[32m0.20561\u001b[0m      0.85536  2.11s\n",
      "     23       \u001b[36m0.17316\u001b[0m       \u001b[32m0.20544\u001b[0m      0.84287  2.37s\n",
      "     24       \u001b[36m0.17032\u001b[0m       \u001b[32m0.20531\u001b[0m      0.82954  2.17s\n",
      "     25       \u001b[36m0.16731\u001b[0m       \u001b[32m0.20522\u001b[0m      0.81530  2.12s\n",
      "     26       \u001b[36m0.16419\u001b[0m       \u001b[32m0.20516\u001b[0m      0.80029  2.15s\n",
      "     27       \u001b[36m0.16094\u001b[0m       0.20517      0.78440  2.16s\n",
      "     28       \u001b[36m0.15758\u001b[0m       0.20522      0.76783  2.14s\n",
      "     29       \u001b[36m0.15411\u001b[0m       0.20536      0.75045  2.12s\n",
      "     30       \u001b[36m0.15056\u001b[0m       0.20553      0.73256  2.12s\n",
      "     31       \u001b[36m0.14694\u001b[0m       0.20574      0.71419  2.10s\n",
      "     32       \u001b[36m0.14325\u001b[0m       0.20600      0.69537  2.25s\n",
      "     33       \u001b[36m0.13952\u001b[0m       0.20631      0.67623  2.15s\n",
      "     34       \u001b[36m0.13575\u001b[0m       0.20667      0.65686  2.28s\n",
      "     35       \u001b[36m0.13196\u001b[0m       0.20706      0.63730  2.16s\n",
      "     36       \u001b[36m0.12816\u001b[0m       0.20746      0.61774  2.43s\n",
      "Early stopping.\n",
      "Best valid loss was 0.205161 at epoch 26.\n",
      "Loaded parameters to layer 'hidden0' (shape 600x300).\n",
      "Loaded parameters to layer 'hidden0' (shape 300).\n",
      "Loaded parameters to layer 'output' (shape 300x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 170492 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input        600\n",
      "  1  hidden0      250\n",
      "  2  dropout0     250\n",
      "  3  hidden1       80\n",
      "  4  output         2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.24012\u001b[0m       \u001b[32m0.22706\u001b[0m      1.05751  2.62s\n",
      "      2       \u001b[36m0.22420\u001b[0m       \u001b[32m0.21764\u001b[0m      1.03015  2.57s\n",
      "      3       \u001b[36m0.21800\u001b[0m       \u001b[32m0.21342\u001b[0m      1.02150  2.46s\n",
      "      4       \u001b[36m0.21433\u001b[0m       \u001b[32m0.21129\u001b[0m      1.01442  2.67s\n",
      "      5       \u001b[36m0.21118\u001b[0m       \u001b[32m0.20982\u001b[0m      1.00645  2.47s\n",
      "      6       \u001b[36m0.20947\u001b[0m       \u001b[32m0.20907\u001b[0m      1.00191  2.47s\n",
      "      7       \u001b[36m0.20738\u001b[0m       \u001b[32m0.20843\u001b[0m      0.99497  2.39s\n",
      "      8       \u001b[36m0.20588\u001b[0m       \u001b[32m0.20815\u001b[0m      0.98910  2.50s\n",
      "      9       \u001b[36m0.20455\u001b[0m       \u001b[32m0.20793\u001b[0m      0.98373  2.37s\n",
      "     10       \u001b[36m0.20370\u001b[0m       \u001b[32m0.20792\u001b[0m      0.97971  2.59s\n",
      "     11       \u001b[36m0.20223\u001b[0m       \u001b[32m0.20759\u001b[0m      0.97415  2.40s\n",
      "     12       \u001b[36m0.20082\u001b[0m       \u001b[32m0.20727\u001b[0m      0.96888  2.77s\n",
      "     13       \u001b[36m0.20000\u001b[0m       0.20746      0.96405  2.41s\n",
      "     14       \u001b[36m0.19859\u001b[0m       \u001b[32m0.20718\u001b[0m      0.95850  2.64s\n",
      "     15       \u001b[36m0.19647\u001b[0m       0.20732      0.94766  2.53s\n",
      "     16       \u001b[36m0.19584\u001b[0m       0.20772      0.94281  2.52s\n",
      "     17       \u001b[36m0.19376\u001b[0m       0.20737      0.93436  2.51s\n",
      "     18       \u001b[36m0.19292\u001b[0m       0.20756      0.92948  2.54s\n",
      "     19       \u001b[36m0.19129\u001b[0m       0.20779      0.92060  2.54s\n",
      "     20       \u001b[36m0.18963\u001b[0m       0.20751      0.91382  2.53s\n",
      "     21       \u001b[36m0.18771\u001b[0m       0.20767      0.90391  2.62s\n",
      "     22       \u001b[36m0.18714\u001b[0m       0.20762      0.90136  2.53s\n",
      "     23       \u001b[36m0.18397\u001b[0m       0.20810      0.88408  2.65s\n",
      "     24       \u001b[36m0.18229\u001b[0m       0.20807      0.87609  2.51s\n",
      "Early stopping.\n",
      "Best valid loss was 0.207184 at epoch 14.\n",
      "Loaded parameters to layer 'hidden0' (shape 600x250).\n",
      "Loaded parameters to layer 'hidden0' (shape 250).\n",
      "Loaded parameters to layer 'hidden1' (shape 250x80).\n",
      "Loaded parameters to layer 'hidden1' (shape 80).\n",
      "Loaded parameters to layer 'output' (shape 80x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 380982 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input        600\n",
      "  1  hidden0      500\n",
      "  2  dropout0     500\n",
      "  3  hidden1      160\n",
      "  4  output         2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.24079\u001b[0m       \u001b[32m0.22683\u001b[0m      1.06152  5.17s\n",
      "      2       \u001b[36m0.22318\u001b[0m       \u001b[32m0.21635\u001b[0m      1.03157  5.16s\n",
      "      3       \u001b[36m0.21630\u001b[0m       \u001b[32m0.21198\u001b[0m      1.02040  5.11s\n",
      "      4       \u001b[36m0.21147\u001b[0m       \u001b[32m0.20966\u001b[0m      1.00864  5.07s\n",
      "      5       \u001b[36m0.20912\u001b[0m       \u001b[32m0.20880\u001b[0m      1.00150  5.35s\n",
      "      6       \u001b[36m0.20727\u001b[0m       \u001b[32m0.20804\u001b[0m      0.99629  5.75s\n",
      "      7       \u001b[36m0.20565\u001b[0m       \u001b[32m0.20769\u001b[0m      0.99016  5.37s\n",
      "      8       \u001b[36m0.20419\u001b[0m       \u001b[32m0.20735\u001b[0m      0.98478  5.28s\n",
      "      9       \u001b[36m0.20185\u001b[0m       \u001b[32m0.20714\u001b[0m      0.97444  5.23s\n",
      "     10       \u001b[36m0.20089\u001b[0m       \u001b[32m0.20681\u001b[0m      0.97138  5.28s\n",
      "     11       \u001b[36m0.19904\u001b[0m       0.20685      0.96224  5.40s\n",
      "     12       \u001b[36m0.19725\u001b[0m       0.20700      0.95289  5.30s\n",
      "     13       \u001b[36m0.19568\u001b[0m       \u001b[32m0.20679\u001b[0m      0.94629  5.40s\n",
      "     14       \u001b[36m0.19377\u001b[0m       \u001b[32m0.20662\u001b[0m      0.93782  5.35s\n",
      "     15       \u001b[36m0.19254\u001b[0m       0.20670      0.93151  5.12s\n",
      "     16       \u001b[36m0.19090\u001b[0m       \u001b[32m0.20661\u001b[0m      0.92397  5.40s\n",
      "     17       \u001b[36m0.18795\u001b[0m       0.20669      0.90930  5.13s\n",
      "     18       \u001b[36m0.18620\u001b[0m       \u001b[32m0.20646\u001b[0m      0.90188  5.31s\n",
      "     19       \u001b[36m0.18425\u001b[0m       0.20692      0.89043  5.62s\n",
      "     20       \u001b[36m0.18208\u001b[0m       0.20751      0.87747  5.36s\n",
      "     21       \u001b[36m0.17905\u001b[0m       0.20761      0.86244  5.18s\n",
      "     22       \u001b[36m0.17655\u001b[0m       0.20737      0.85139  5.20s\n",
      "     23       \u001b[36m0.17302\u001b[0m       0.20760      0.83343  5.39s\n",
      "     24       \u001b[36m0.17017\u001b[0m       0.20793      0.81841  5.33s\n",
      "     25       \u001b[36m0.16696\u001b[0m       0.20780      0.80349  5.50s\n",
      "     26       \u001b[36m0.16381\u001b[0m       0.20847      0.78577  5.38s\n",
      "     27       \u001b[36m0.15943\u001b[0m       0.20915      0.76227  5.20s\n",
      "     28       \u001b[36m0.15647\u001b[0m       0.20919      0.74797  5.21s\n",
      "Early stopping.\n",
      "Best valid loss was 0.206457 at epoch 18.\n",
      "Loaded parameters to layer 'hidden0' (shape 600x500).\n",
      "Loaded parameters to layer 'hidden0' (shape 500).\n",
      "Loaded parameters to layer 'hidden1' (shape 500x160).\n",
      "Loaded parameters to layer 'hidden1' (shape 160).\n",
      "Loaded parameters to layer 'output' (shape 160x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 306672 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input        600\n",
      "  1  hidden0      400\n",
      "  2  dropout0     400\n",
      "  3  hidden1      150\n",
      "  4  dropout1     150\n",
      "  5  hidden2       40\n",
      "  6  output         2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.24800\u001b[0m       \u001b[32m0.23826\u001b[0m      1.04088  4.25s\n",
      "      2       \u001b[36m0.23339\u001b[0m       \u001b[32m0.22298\u001b[0m      1.04667  4.58s\n",
      "      3       \u001b[36m0.22411\u001b[0m       \u001b[32m0.21779\u001b[0m      1.02899  4.59s\n",
      "      4       \u001b[36m0.21927\u001b[0m       \u001b[32m0.21488\u001b[0m      1.02041  4.54s\n",
      "      5       \u001b[36m0.21527\u001b[0m       \u001b[32m0.21283\u001b[0m      1.01149  4.41s\n",
      "      6       \u001b[36m0.21232\u001b[0m       \u001b[32m0.21146\u001b[0m      1.00405  4.51s\n",
      "      7       \u001b[36m0.21061\u001b[0m       \u001b[32m0.21018\u001b[0m      1.00205  4.28s\n",
      "      8       \u001b[36m0.20878\u001b[0m       0.21021      0.99323  4.40s\n",
      "      9       \u001b[36m0.20744\u001b[0m       \u001b[32m0.20976\u001b[0m      0.98895  4.46s\n",
      "     10       \u001b[36m0.20599\u001b[0m       \u001b[32m0.20966\u001b[0m      0.98247  4.35s\n",
      "     11       \u001b[36m0.20461\u001b[0m       \u001b[32m0.20904\u001b[0m      0.97881  4.90s\n",
      "     12       \u001b[36m0.20293\u001b[0m       0.20906      0.97068  4.48s\n",
      "     13       \u001b[36m0.20183\u001b[0m       \u001b[32m0.20894\u001b[0m      0.96598  4.40s\n",
      "     14       \u001b[36m0.20131\u001b[0m       \u001b[32m0.20820\u001b[0m      0.96687  4.46s\n",
      "     15       \u001b[36m0.19949\u001b[0m       \u001b[32m0.20810\u001b[0m      0.95861  4.24s\n",
      "     16       \u001b[36m0.19782\u001b[0m       0.20828      0.94977  4.56s\n",
      "     17       \u001b[36m0.19687\u001b[0m       0.20875      0.94308  4.84s\n",
      "     18       \u001b[36m0.19509\u001b[0m       0.20825      0.93680  4.69s\n",
      "     19       \u001b[36m0.19405\u001b[0m       0.20852      0.93064  4.60s\n",
      "     20       \u001b[36m0.19200\u001b[0m       0.20844      0.92111  4.48s\n",
      "     21       \u001b[36m0.19026\u001b[0m       0.20830      0.91341  4.37s\n",
      "     22       \u001b[36m0.18919\u001b[0m       0.20844      0.90764  4.41s\n",
      "     23       \u001b[36m0.18675\u001b[0m       0.20823      0.89682  4.58s\n",
      "     24       \u001b[36m0.18386\u001b[0m       \u001b[32m0.20806\u001b[0m      0.88371  4.47s\n",
      "     25       \u001b[36m0.18223\u001b[0m       0.20882      0.87265  4.53s\n",
      "     26       \u001b[36m0.17989\u001b[0m       0.20898      0.86081  4.25s\n",
      "     27       \u001b[36m0.17796\u001b[0m       0.20947      0.84960  4.35s\n",
      "     28       \u001b[36m0.17483\u001b[0m       0.20847      0.83866  4.22s\n",
      "     29       \u001b[36m0.17158\u001b[0m       0.20925      0.82000  4.26s\n",
      "     30       \u001b[36m0.16865\u001b[0m       0.21033      0.80183  4.23s\n",
      "     31       \u001b[36m0.16553\u001b[0m       0.21050      0.78637  4.18s\n",
      "     32       \u001b[36m0.16235\u001b[0m       0.21082      0.77009  4.60s\n",
      "     33       \u001b[36m0.15909\u001b[0m       0.21181      0.75109  4.82s\n",
      "     34       \u001b[36m0.15503\u001b[0m       0.21262      0.72915  4.49s\n",
      "Early stopping.\n",
      "Best valid loss was 0.208058 at epoch 24.\n",
      "Loaded parameters to layer 'hidden0' (shape 600x400).\n",
      "Loaded parameters to layer 'hidden0' (shape 400).\n",
      "Loaded parameters to layer 'hidden1' (shape 400x150).\n",
      "Loaded parameters to layer 'hidden1' (shape 150).\n",
      "Loaded parameters to layer 'hidden2' (shape 150x40).\n",
      "Loaded parameters to layer 'hidden2' (shape 40).\n",
      "Loaded parameters to layer 'output' (shape 40x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 60302 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name       size\n",
      "---  -------  ------\n",
      "  0  input       600\n",
      "  1  hidden0     100\n",
      "  2  output        2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.23808\u001b[0m       \u001b[32m0.22737\u001b[0m      1.04710  0.77s\n",
      "      2       \u001b[36m0.22126\u001b[0m       \u001b[32m0.21867\u001b[0m      1.01186  0.75s\n",
      "      3       \u001b[36m0.21417\u001b[0m       \u001b[32m0.21429\u001b[0m      0.99947  0.72s\n",
      "      4       \u001b[36m0.21015\u001b[0m       \u001b[32m0.21197\u001b[0m      0.99141  0.74s\n",
      "      5       \u001b[36m0.20760\u001b[0m       \u001b[32m0.21075\u001b[0m      0.98505  0.74s\n",
      "      6       \u001b[36m0.20578\u001b[0m       \u001b[32m0.21009\u001b[0m      0.97950  0.76s\n",
      "      7       \u001b[36m0.20436\u001b[0m       \u001b[32m0.20971\u001b[0m      0.97448  0.76s\n",
      "      8       \u001b[36m0.20315\u001b[0m       \u001b[32m0.20948\u001b[0m      0.96976  0.72s\n",
      "      9       \u001b[36m0.20206\u001b[0m       \u001b[32m0.20934\u001b[0m      0.96523  0.76s\n",
      "     10       \u001b[36m0.20102\u001b[0m       \u001b[32m0.20924\u001b[0m      0.96071  0.75s\n",
      "     11       \u001b[36m0.20002\u001b[0m       \u001b[32m0.20918\u001b[0m      0.95620  0.72s\n",
      "     12       \u001b[36m0.19902\u001b[0m       \u001b[32m0.20912\u001b[0m      0.95170  0.75s\n",
      "     13       \u001b[36m0.19799\u001b[0m       \u001b[32m0.20905\u001b[0m      0.94712  0.74s\n",
      "     14       \u001b[36m0.19694\u001b[0m       \u001b[32m0.20897\u001b[0m      0.94244  0.76s\n",
      "     15       \u001b[36m0.19584\u001b[0m       \u001b[32m0.20888\u001b[0m      0.93754  0.74s\n",
      "     16       \u001b[36m0.19467\u001b[0m       \u001b[32m0.20881\u001b[0m      0.93227  0.72s\n",
      "     17       \u001b[36m0.19344\u001b[0m       \u001b[32m0.20871\u001b[0m      0.92686  0.73s\n",
      "     18       \u001b[36m0.19214\u001b[0m       \u001b[32m0.20860\u001b[0m      0.92108  0.77s\n",
      "     19       \u001b[36m0.19076\u001b[0m       \u001b[32m0.20849\u001b[0m      0.91494  0.72s\n",
      "     20       \u001b[36m0.18930\u001b[0m       \u001b[32m0.20839\u001b[0m      0.90841  0.73s\n",
      "     21       \u001b[36m0.18777\u001b[0m       \u001b[32m0.20825\u001b[0m      0.90164  0.72s\n",
      "     22       \u001b[36m0.18615\u001b[0m       \u001b[32m0.20812\u001b[0m      0.89441  0.72s\n",
      "     23       \u001b[36m0.18444\u001b[0m       \u001b[32m0.20802\u001b[0m      0.88665  0.71s\n",
      "     24       \u001b[36m0.18265\u001b[0m       \u001b[32m0.20788\u001b[0m      0.87859  0.81s\n",
      "     25       \u001b[36m0.18076\u001b[0m       \u001b[32m0.20779\u001b[0m      0.86994  0.75s\n",
      "     26       \u001b[36m0.17879\u001b[0m       \u001b[32m0.20766\u001b[0m      0.86095  0.81s\n",
      "     27       \u001b[36m0.17674\u001b[0m       \u001b[32m0.20759\u001b[0m      0.85140  0.72s\n",
      "     28       \u001b[36m0.17461\u001b[0m       \u001b[32m0.20752\u001b[0m      0.84142  0.71s\n",
      "     29       \u001b[36m0.17240\u001b[0m       \u001b[32m0.20751\u001b[0m      0.83080  0.75s\n",
      "     30       \u001b[36m0.17012\u001b[0m       0.20753      0.81972  0.75s\n",
      "     31       \u001b[36m0.16777\u001b[0m       0.20759      0.80820  0.97s\n",
      "     32       \u001b[36m0.16536\u001b[0m       0.20766      0.79631  0.76s\n",
      "     33       \u001b[36m0.16290\u001b[0m       0.20775      0.78411  0.75s\n",
      "     34       \u001b[36m0.16039\u001b[0m       0.20792      0.77142  0.72s\n",
      "     35       \u001b[36m0.15784\u001b[0m       0.20811      0.75847  0.73s\n",
      "     36       \u001b[36m0.15526\u001b[0m       0.20833      0.74525  1.01s\n",
      "     37       \u001b[36m0.15264\u001b[0m       0.20863      0.73161  0.87s\n",
      "     38       \u001b[36m0.14998\u001b[0m       0.20893      0.71786  0.72s\n",
      "     39       \u001b[36m0.14732\u001b[0m       0.20925      0.70403  0.73s\n",
      "Early stopping.\n",
      "Best valid loss was 0.207514 at epoch 29.\n",
      "Loaded parameters to layer 'hidden0' (shape 600x100).\n",
      "Loaded parameters to layer 'hidden0' (shape 100).\n",
      "Loaded parameters to layer 'output' (shape 100x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 180902 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name       size\n",
      "---  -------  ------\n",
      "  0  input       600\n",
      "  1  hidden0     300\n",
      "  2  output        2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.23612\u001b[0m       \u001b[32m0.22586\u001b[0m      1.04544  2.12s\n",
      "      2       \u001b[36m0.21937\u001b[0m       \u001b[32m0.21762\u001b[0m      1.00804  2.24s\n",
      "      3       \u001b[36m0.21272\u001b[0m       \u001b[32m0.21339\u001b[0m      0.99685  2.15s\n",
      "      4       \u001b[36m0.20888\u001b[0m       \u001b[32m0.21107\u001b[0m      0.98960  2.13s\n",
      "      5       \u001b[36m0.20632\u001b[0m       \u001b[32m0.20976\u001b[0m      0.98362  2.12s\n",
      "      6       \u001b[36m0.20439\u001b[0m       \u001b[32m0.20897\u001b[0m      0.97805  2.15s\n",
      "      7       \u001b[36m0.20278\u001b[0m       \u001b[32m0.20848\u001b[0m      0.97266  2.11s\n",
      "      8       \u001b[36m0.20134\u001b[0m       \u001b[32m0.20814\u001b[0m      0.96732  2.19s\n",
      "      9       \u001b[36m0.19998\u001b[0m       \u001b[32m0.20788\u001b[0m      0.96197  2.13s\n",
      "     10       \u001b[36m0.19865\u001b[0m       \u001b[32m0.20767\u001b[0m      0.95654  2.26s\n",
      "     11       \u001b[36m0.19731\u001b[0m       \u001b[32m0.20748\u001b[0m      0.95097  2.10s\n",
      "     12       \u001b[36m0.19593\u001b[0m       \u001b[32m0.20729\u001b[0m      0.94520  2.51s\n",
      "     13       \u001b[36m0.19450\u001b[0m       \u001b[32m0.20710\u001b[0m      0.93918  2.09s\n",
      "     14       \u001b[36m0.19300\u001b[0m       \u001b[32m0.20690\u001b[0m      0.93284  2.17s\n",
      "     15       \u001b[36m0.19141\u001b[0m       \u001b[32m0.20669\u001b[0m      0.92610  2.37s\n",
      "     16       \u001b[36m0.18972\u001b[0m       \u001b[32m0.20646\u001b[0m      0.91891  2.14s\n",
      "     17       \u001b[36m0.18791\u001b[0m       \u001b[32m0.20623\u001b[0m      0.91118  2.09s\n",
      "     18       \u001b[36m0.18598\u001b[0m       \u001b[32m0.20598\u001b[0m      0.90290  2.08s\n",
      "     19       \u001b[36m0.18391\u001b[0m       \u001b[32m0.20572\u001b[0m      0.89401  2.11s\n",
      "     20       \u001b[36m0.18171\u001b[0m       \u001b[32m0.20545\u001b[0m      0.88443  2.15s\n",
      "     21       \u001b[36m0.17935\u001b[0m       \u001b[32m0.20518\u001b[0m      0.87415  2.12s\n",
      "     22       \u001b[36m0.17685\u001b[0m       \u001b[32m0.20491\u001b[0m      0.86307  2.14s\n",
      "     23       \u001b[36m0.17419\u001b[0m       \u001b[32m0.20465\u001b[0m      0.85116  2.12s\n",
      "     24       \u001b[36m0.17139\u001b[0m       \u001b[32m0.20442\u001b[0m      0.83839  2.11s\n",
      "     25       \u001b[36m0.16843\u001b[0m       \u001b[32m0.20421\u001b[0m      0.82480  2.14s\n",
      "     26       \u001b[36m0.16533\u001b[0m       \u001b[32m0.20404\u001b[0m      0.81032  2.25s\n",
      "     27       \u001b[36m0.16211\u001b[0m       \u001b[32m0.20387\u001b[0m      0.79515  2.13s\n",
      "     28       \u001b[36m0.15876\u001b[0m       \u001b[32m0.20375\u001b[0m      0.77917  2.42s\n",
      "     29       \u001b[36m0.15530\u001b[0m       \u001b[32m0.20371\u001b[0m      0.76237  2.13s\n",
      "     30       \u001b[36m0.15175\u001b[0m       \u001b[32m0.20368\u001b[0m      0.74503  2.25s\n",
      "     31       \u001b[36m0.14812\u001b[0m       0.20369      0.72719  2.14s\n",
      "     32       \u001b[36m0.14443\u001b[0m       0.20372      0.70897  2.20s\n",
      "     33       \u001b[36m0.14069\u001b[0m       0.20378      0.69041  2.11s\n",
      "     34       \u001b[36m0.13692\u001b[0m       0.20389      0.67152  2.12s\n",
      "     35       \u001b[36m0.13311\u001b[0m       0.20405      0.65234  2.08s\n",
      "     36       \u001b[36m0.12930\u001b[0m       0.20426      0.63300  2.10s\n",
      "     37       \u001b[36m0.12547\u001b[0m       0.20450      0.61355  2.11s\n",
      "     38       \u001b[36m0.12165\u001b[0m       0.20478      0.59409  2.12s\n",
      "     39       \u001b[36m0.11786\u001b[0m       0.20506      0.57474  2.09s\n",
      "     40       \u001b[36m0.11409\u001b[0m       0.20541      0.55543  2.08s\n",
      "Early stopping.\n",
      "Best valid loss was 0.203685 at epoch 30.\n",
      "Loaded parameters to layer 'hidden0' (shape 600x300).\n",
      "Loaded parameters to layer 'hidden0' (shape 300).\n",
      "Loaded parameters to layer 'output' (shape 300x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 170492 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input        600\n",
      "  1  hidden0      250\n",
      "  2  dropout0     250\n",
      "  3  hidden1       80\n",
      "  4  output         2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.24347\u001b[0m       \u001b[32m0.23313\u001b[0m      1.04436  2.56s\n",
      "      2       \u001b[36m0.23113\u001b[0m       \u001b[32m0.22457\u001b[0m      1.02923  2.74s\n",
      "      3       \u001b[36m0.22390\u001b[0m       \u001b[32m0.21984\u001b[0m      1.01846  2.45s\n",
      "      4       \u001b[36m0.22011\u001b[0m       \u001b[32m0.21775\u001b[0m      1.01080  2.57s\n",
      "      5       \u001b[36m0.21668\u001b[0m       \u001b[32m0.21585\u001b[0m      1.00384  2.51s\n",
      "      6       \u001b[36m0.21509\u001b[0m       \u001b[32m0.21424\u001b[0m      1.00401  2.44s\n",
      "      7       \u001b[36m0.21308\u001b[0m       \u001b[32m0.21306\u001b[0m      1.00013  2.44s\n",
      "      8       \u001b[36m0.21155\u001b[0m       \u001b[32m0.21238\u001b[0m      0.99607  2.49s\n",
      "      9       \u001b[36m0.21018\u001b[0m       \u001b[32m0.21214\u001b[0m      0.99074  2.40s\n",
      "     10       \u001b[36m0.20903\u001b[0m       \u001b[32m0.21135\u001b[0m      0.98903  2.43s\n",
      "     11       \u001b[36m0.20781\u001b[0m       \u001b[32m0.21124\u001b[0m      0.98376  2.41s\n",
      "     12       \u001b[36m0.20671\u001b[0m       \u001b[32m0.21046\u001b[0m      0.98216  2.39s\n",
      "     13       \u001b[36m0.20540\u001b[0m       \u001b[32m0.21011\u001b[0m      0.97762  2.52s\n",
      "     14       \u001b[36m0.20429\u001b[0m       \u001b[32m0.21007\u001b[0m      0.97248  2.60s\n",
      "     15       \u001b[36m0.20378\u001b[0m       \u001b[32m0.20973\u001b[0m      0.97165  2.88s\n",
      "     16       \u001b[36m0.20296\u001b[0m       \u001b[32m0.20926\u001b[0m      0.96986  2.40s\n",
      "     17       \u001b[36m0.20229\u001b[0m       \u001b[32m0.20902\u001b[0m      0.96782  2.60s\n",
      "     18       \u001b[36m0.20168\u001b[0m       0.20926      0.96376  2.42s\n",
      "     19       \u001b[36m0.19957\u001b[0m       \u001b[32m0.20877\u001b[0m      0.95591  2.46s\n",
      "     20       \u001b[36m0.19914\u001b[0m       \u001b[32m0.20850\u001b[0m      0.95511  2.46s\n",
      "     21       \u001b[36m0.19861\u001b[0m       0.20855      0.95234  2.47s\n",
      "     22       \u001b[36m0.19722\u001b[0m       \u001b[32m0.20824\u001b[0m      0.94707  2.45s\n",
      "     23       \u001b[36m0.19611\u001b[0m       0.20854      0.94039  2.37s\n",
      "     24       \u001b[36m0.19471\u001b[0m       0.20862      0.93331  2.43s\n",
      "     25       \u001b[36m0.19445\u001b[0m       \u001b[32m0.20762\u001b[0m      0.93656  2.52s\n",
      "     26       \u001b[36m0.19320\u001b[0m       0.20844      0.92690  2.52s\n",
      "     27       \u001b[36m0.19189\u001b[0m       0.20835      0.92100  2.62s\n",
      "     28       \u001b[36m0.19052\u001b[0m       0.20826      0.91482  2.38s\n",
      "     29       0.19069       0.20795      0.91700  2.75s\n",
      "     30       \u001b[36m0.18817\u001b[0m       0.20781      0.90553  2.54s\n",
      "     31       \u001b[36m0.18732\u001b[0m       0.20868      0.89765  2.59s\n",
      "     32       \u001b[36m0.18570\u001b[0m       0.20810      0.89236  2.36s\n",
      "     33       \u001b[36m0.18450\u001b[0m       0.20810      0.88660  2.48s\n",
      "     34       \u001b[36m0.18288\u001b[0m       \u001b[32m0.20759\u001b[0m      0.88097  2.37s\n",
      "     35       \u001b[36m0.18193\u001b[0m       0.20809      0.87428  2.41s\n",
      "     36       0.18198       0.20813      0.87437  2.42s\n",
      "     37       \u001b[36m0.17948\u001b[0m       0.20809      0.86248  2.38s\n",
      "     38       \u001b[36m0.17750\u001b[0m       0.20863      0.85081  2.43s\n",
      "     39       \u001b[36m0.17650\u001b[0m       0.20846      0.84670  2.40s\n",
      "     40       \u001b[36m0.17478\u001b[0m       0.20840      0.83865  3.20s\n",
      "     41       \u001b[36m0.17303\u001b[0m       0.20940      0.82633  2.48s\n",
      "     42       \u001b[36m0.17097\u001b[0m       0.20892      0.81837  2.69s\n",
      "     43       \u001b[36m0.17018\u001b[0m       0.20919      0.81352  2.47s\n",
      "     44       \u001b[36m0.16801\u001b[0m       0.20922      0.80305  2.62s\n",
      "Early stopping.\n",
      "Best valid loss was 0.207589 at epoch 34.\n",
      "Loaded parameters to layer 'hidden0' (shape 600x250).\n",
      "Loaded parameters to layer 'hidden0' (shape 250).\n",
      "Loaded parameters to layer 'hidden1' (shape 250x80).\n",
      "Loaded parameters to layer 'hidden1' (shape 80).\n",
      "Loaded parameters to layer 'output' (shape 80x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 380982 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input        600\n",
      "  1  hidden0      500\n",
      "  2  dropout0     500\n",
      "  3  hidden1      160\n",
      "  4  output         2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.24353\u001b[0m       \u001b[32m0.23294\u001b[0m      1.04547  4.99s\n",
      "      2       \u001b[36m0.22895\u001b[0m       \u001b[32m0.22099\u001b[0m      1.03601  5.27s\n",
      "      3       \u001b[36m0.22151\u001b[0m       \u001b[32m0.21626\u001b[0m      1.02424  4.87s\n",
      "      4       \u001b[36m0.21757\u001b[0m       \u001b[32m0.21353\u001b[0m      1.01888  5.11s\n",
      "      5       \u001b[36m0.21459\u001b[0m       \u001b[32m0.21202\u001b[0m      1.01213  5.24s\n",
      "      6       \u001b[36m0.21297\u001b[0m       \u001b[32m0.21069\u001b[0m      1.01081  5.31s\n",
      "      7       \u001b[36m0.21056\u001b[0m       \u001b[32m0.21022\u001b[0m      1.00159  5.01s\n",
      "      8       \u001b[36m0.20890\u001b[0m       \u001b[32m0.20958\u001b[0m      0.99674  5.01s\n",
      "      9       \u001b[36m0.20793\u001b[0m       \u001b[32m0.20897\u001b[0m      0.99501  4.94s\n",
      "     10       \u001b[36m0.20627\u001b[0m       \u001b[32m0.20855\u001b[0m      0.98904  5.07s\n",
      "     11       \u001b[36m0.20468\u001b[0m       \u001b[32m0.20840\u001b[0m      0.98211  5.26s\n",
      "     12       \u001b[36m0.20398\u001b[0m       \u001b[32m0.20809\u001b[0m      0.98028  5.31s\n",
      "     13       \u001b[36m0.20284\u001b[0m       \u001b[32m0.20797\u001b[0m      0.97529  5.00s\n",
      "     14       \u001b[36m0.20188\u001b[0m       \u001b[32m0.20785\u001b[0m      0.97129  5.01s\n",
      "     15       \u001b[36m0.20112\u001b[0m       \u001b[32m0.20763\u001b[0m      0.96865  4.96s\n",
      "     16       \u001b[36m0.19956\u001b[0m       0.20793      0.95973  5.11s\n",
      "     17       \u001b[36m0.19823\u001b[0m       \u001b[32m0.20748\u001b[0m      0.95542  5.17s\n",
      "     18       \u001b[36m0.19727\u001b[0m       0.20754      0.95052  5.12s\n",
      "     19       \u001b[36m0.19614\u001b[0m       0.20798      0.94307  5.40s\n",
      "     20       \u001b[36m0.19600\u001b[0m       0.20753      0.94440  4.96s\n",
      "     21       \u001b[36m0.19391\u001b[0m       0.20773      0.93345  4.81s\n",
      "     22       \u001b[36m0.19210\u001b[0m       \u001b[32m0.20743\u001b[0m      0.92611  4.81s\n",
      "     23       \u001b[36m0.19171\u001b[0m       \u001b[32m0.20700\u001b[0m      0.92614  4.99s\n",
      "     24       \u001b[36m0.18932\u001b[0m       0.20772      0.91144  5.03s\n",
      "     25       \u001b[36m0.18865\u001b[0m       0.20732      0.90996  5.24s\n",
      "     26       \u001b[36m0.18657\u001b[0m       0.20784      0.89765  5.15s\n",
      "     27       \u001b[36m0.18534\u001b[0m       0.20784      0.89174  4.88s\n",
      "     28       \u001b[36m0.18373\u001b[0m       0.20813      0.88280  5.18s\n",
      "     29       \u001b[36m0.18244\u001b[0m       0.20840      0.87539  4.95s\n",
      "     30       \u001b[36m0.18027\u001b[0m       0.20768      0.86802  5.17s\n",
      "     31       \u001b[36m0.17852\u001b[0m       0.20807      0.85796  5.07s\n",
      "     32       \u001b[36m0.17635\u001b[0m       0.20772      0.84895  5.27s\n",
      "     33       \u001b[36m0.17467\u001b[0m       0.20705      0.84361  5.14s\n",
      "Early stopping.\n",
      "Best valid loss was 0.207003 at epoch 23.\n",
      "Loaded parameters to layer 'hidden0' (shape 600x500).\n",
      "Loaded parameters to layer 'hidden0' (shape 500).\n",
      "Loaded parameters to layer 'hidden1' (shape 500x160).\n",
      "Loaded parameters to layer 'hidden1' (shape 160).\n",
      "Loaded parameters to layer 'output' (shape 160x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n",
      "# Neural Network with 306672 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  --------  ------\n",
      "  0  input        600\n",
      "  1  hidden0      400\n",
      "  2  dropout0     400\n",
      "  3  hidden1      150\n",
      "  4  dropout1     150\n",
      "  5  hidden2       40\n",
      "  6  output         2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.25148\u001b[0m       \u001b[32m0.24493\u001b[0m      1.02673  4.58s\n",
      "      2       \u001b[36m0.24395\u001b[0m       \u001b[32m0.23458\u001b[0m      1.03995  4.61s\n",
      "      3       \u001b[36m0.23720\u001b[0m       \u001b[32m0.22648\u001b[0m      1.04733  4.69s\n",
      "      4       \u001b[36m0.23029\u001b[0m       \u001b[32m0.22264\u001b[0m      1.03434  4.53s\n",
      "      5       \u001b[36m0.22712\u001b[0m       \u001b[32m0.22015\u001b[0m      1.03167  4.78s\n",
      "      6       \u001b[36m0.22344\u001b[0m       \u001b[32m0.21786\u001b[0m      1.02561  4.52s\n",
      "      7       \u001b[36m0.22018\u001b[0m       \u001b[32m0.21679\u001b[0m      1.01564  4.42s\n",
      "      8       \u001b[36m0.21811\u001b[0m       \u001b[32m0.21554\u001b[0m      1.01192  4.45s\n",
      "      9       \u001b[36m0.21694\u001b[0m       \u001b[32m0.21441\u001b[0m      1.01184  4.49s\n",
      "     10       \u001b[36m0.21542\u001b[0m       \u001b[32m0.21362\u001b[0m      1.00842  4.65s\n",
      "     11       \u001b[36m0.21476\u001b[0m       \u001b[32m0.21279\u001b[0m      1.00924  4.63s\n",
      "     12       \u001b[36m0.21290\u001b[0m       \u001b[32m0.21241\u001b[0m      1.00231  4.61s\n",
      "     13       \u001b[36m0.21230\u001b[0m       \u001b[32m0.21219\u001b[0m      1.00051  4.73s\n",
      "     14       \u001b[36m0.21082\u001b[0m       \u001b[32m0.21136\u001b[0m      0.99748  4.45s\n",
      "     15       \u001b[36m0.21030\u001b[0m       \u001b[32m0.21081\u001b[0m      0.99755  4.48s\n",
      "     16       \u001b[36m0.20954\u001b[0m       \u001b[32m0.21066\u001b[0m      0.99469  4.31s\n",
      "     17       \u001b[36m0.20834\u001b[0m       0.21068      0.98890  4.48s\n",
      "     18       \u001b[36m0.20739\u001b[0m       \u001b[32m0.21030\u001b[0m      0.98617  4.44s\n",
      "     19       \u001b[36m0.20676\u001b[0m       \u001b[32m0.21001\u001b[0m      0.98452  4.51s\n",
      "     20       \u001b[36m0.20498\u001b[0m       \u001b[32m0.20954\u001b[0m      0.97821  4.82s\n",
      "     21       0.20557       0.20966      0.98053  4.59s\n",
      "     22       \u001b[36m0.20480\u001b[0m       \u001b[32m0.20949\u001b[0m      0.97759  4.35s\n",
      "     23       \u001b[36m0.20315\u001b[0m       0.20990      0.96787  4.45s\n",
      "     24       0.20363       0.20971      0.97102  4.43s\n",
      "     25       \u001b[36m0.20238\u001b[0m       \u001b[32m0.20908\u001b[0m      0.96793  4.50s\n",
      "     26       \u001b[36m0.20027\u001b[0m       0.20918      0.95741  4.73s\n",
      "     27       0.20029       0.20948      0.95614  4.77s\n",
      "     28       \u001b[36m0.19918\u001b[0m       0.20921      0.95209  4.58s\n",
      "     29       \u001b[36m0.19886\u001b[0m       \u001b[32m0.20879\u001b[0m      0.95246  4.42s\n",
      "     30       \u001b[36m0.19814\u001b[0m       0.20894      0.94829  4.40s\n",
      "     31       \u001b[36m0.19702\u001b[0m       0.20905      0.94243  4.49s\n",
      "     32       \u001b[36m0.19620\u001b[0m       0.20888      0.93926  4.39s\n",
      "     33       \u001b[36m0.19446\u001b[0m       \u001b[32m0.20856\u001b[0m      0.93240  4.41s\n",
      "     34       \u001b[36m0.19444\u001b[0m       \u001b[32m0.20824\u001b[0m      0.93374  4.50s\n",
      "     35       \u001b[36m0.19322\u001b[0m       0.20862      0.92616  4.75s\n",
      "     36       \u001b[36m0.19175\u001b[0m       0.20838      0.92019  4.69s\n",
      "     37       \u001b[36m0.19113\u001b[0m       0.20845      0.91689  4.46s\n",
      "     38       \u001b[36m0.18930\u001b[0m       0.20912      0.90521  4.42s\n",
      "     39       \u001b[36m0.18812\u001b[0m       0.20944      0.89821  4.49s\n",
      "     40       \u001b[36m0.18629\u001b[0m       0.20889      0.89182  4.55s\n",
      "     41       \u001b[36m0.18615\u001b[0m       0.20867      0.89207  4.79s\n",
      "     42       \u001b[36m0.18416\u001b[0m       0.20864      0.88266  4.76s\n",
      "     43       \u001b[36m0.18238\u001b[0m       0.20890      0.87307  4.55s\n",
      "     44       \u001b[36m0.18006\u001b[0m       0.20902      0.86144  4.38s\n",
      "Early stopping.\n",
      "Best valid loss was 0.208236 at epoch 34.\n",
      "Loaded parameters to layer 'hidden0' (shape 600x400).\n",
      "Loaded parameters to layer 'hidden0' (shape 400).\n",
      "Loaded parameters to layer 'hidden1' (shape 400x150).\n",
      "Loaded parameters to layer 'hidden1' (shape 150).\n",
      "Loaded parameters to layer 'hidden2' (shape 150x40).\n",
      "Loaded parameters to layer 'hidden2' (shape 40).\n",
      "Loaded parameters to layer 'output' (shape 40x2).\n",
      "Loaded parameters to layer 'output' (shape 2).\n"
     ]
    }
   ],
   "source": [
    "# automated nn testing\n",
    "from collections import namedtuple\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# predefined network architectures\n",
    "archs = ((100, 2), (300, 2), (250, 80, 2), (500, 160, 2), (400, 150, 40, 2))\n",
    "\n",
    "for inputDim in (100, 300, 600):\n",
    "    for dropout in (.4, .6):\n",
    "        for arch in archs:\n",
    "            net, trainTestData = genNNclf(inputDim=inputDim, arch=arch, dropout_p=dropout, regression=True)\n",
    "            evalRes = evalPrediction(net, trainTestData)\n",
    "            candidate = NNCandidate(inputDim, dropout, arch, evalRes)\n",
    "            with open(os.path.join(NNcandidatesPath, str(inputDim) + str(dropout) + str(arch) + '.pickle'), 'wb') as fh:\n",
    "                pickle.dump(candidate, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NNCandidate(inputDim=100, dropout=0.6, arch=(500, 160, 2), evalRes=EvalResults(All=5693, Pos=7580, Neg=-1887, SuccRate=1.3314596873353242, TrainLoss=array([ 0.23842354,  0.22742157,  0.22373831,  0.2216201 ,  0.22063251,\n",
       "        0.21901459,  0.2185963 ,  0.21824024,  0.21725851,  0.21698963,\n",
       "        0.21572417,  0.21534843,  0.21465683,  0.21469975,  0.21388686,\n",
       "        0.21405772,  0.2131976 ,  0.21290237,  0.21250232,  0.21191771,\n",
       "        0.2116985 ,  0.21107503,  0.21062557,  0.21010931,  0.21010531,\n",
       "        0.20949028,  0.20937581,  0.20860382,  0.20832875,  0.20765756,\n",
       "        0.20740431,  0.20753411,  0.20686926,  0.20645427,  0.20604676,\n",
       "        0.20568448,  0.20487067,  0.20492596,  0.20458856,  0.20318048,\n",
       "        0.20339227,  0.20393796,  0.20288928,  0.20301046,  0.20212378,\n",
       "        0.20143992,  0.20139709,  0.20064219,  0.20025184,  0.20055178,\n",
       "        0.20048304]), ValidLoss=array([ 0.22378682,  0.21804184,  0.21568605,  0.21467107,  0.21423917,\n",
       "        0.21361867,  0.21316013,  0.21288103,  0.21258103,  0.21238052,\n",
       "        0.21229919,  0.2122179 ,  0.21190179,  0.21179335,  0.2116751 ,\n",
       "        0.21157438,  0.21140098,  0.21113977,  0.21109904,  0.21107028,\n",
       "        0.2110321 ,  0.21080093,  0.21080569,  0.21068194,  0.21044391,\n",
       "        0.21051915,  0.2104343 ,  0.21031529,  0.21003415,  0.21013968,\n",
       "        0.2100125 ,  0.21017851,  0.21007267,  0.21004674,  0.21004647,\n",
       "        0.21007871,  0.20999852,  0.20988661,  0.2098277 ,  0.2097606 ,\n",
       "        0.2099672 ,  0.20985695,  0.20989173,  0.20983007,  0.20978489,\n",
       "        0.21009814,  0.21011618,  0.21027063,  0.21024309,  0.20978106,\n",
       "        0.20988163])))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pick the best performing NN\n",
    "import os\n",
    "import pickle\n",
    "from collections import namedtuple\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, p in enumerate(os.listdir(NNcandidatesPath)):\n",
    "    with open(os.path.join(NNcandidatesPath, p), 'rb') as fh:\n",
    "        candidate = pickle.load(fh)\n",
    "    results.append(candidate)\n",
    "    \n",
    "results = sorted(results, key=lambda x: x.evalRes.SuccRate)\n",
    "results[-21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'inputDim=600\\narch=(500, 160, 2)\\ndropout_p=.6\\nregression=False\\n\\nnet, trainTestData = genNNclf(inputDim=inputDim, arch=arch, dropout_p=dropout_p, regression=regression)\\nevalRes = evalPrediction(net, trainTestData)\\ncandidate = NNCandidate(inputDim, dropout_p, arch, evalRes)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# playing with regression, rather than classification\n",
    "'''inputDim=600\n",
    "arch=(500, 160, 2)\n",
    "dropout_p=.6\n",
    "regression=False\n",
    "\n",
    "net, trainTestData = genNNclf(inputDim=inputDim, arch=arch, dropout_p=dropout_p, regression=regression)\n",
    "evalRes = evalPrediction(net, trainTestData)\n",
    "candidate = NNCandidate(inputDim, dropout_p, arch, evalRes)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bad input shape (51231, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-b93cfe0fffed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# let's try a SVM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainTestData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenSVMclf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputDim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mevalRes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevalPrediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainTestData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'SVM success rate: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevalRes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSuccRate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-167cfc0d9867>\u001b[0m in \u001b[0;36mgenSVMclf\u001b[1;34m(inputDim, evalSize)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# carry out train/test split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevalSize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTrainTestData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/user/projekte/anaconda3/envs/ipynb/lib/python3.5/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         sample_weight = np.asarray([]\n",
      "\u001b[1;32m/home/user/projekte/anaconda3/envs/ipynb/lib/python3.5/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_validate_targets\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m         \u001b[0my_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m         \u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/user/projekte/anaconda3/envs/ipynb/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, warn)\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bad input shape {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: bad input shape (51231, 2)"
     ]
    }
   ],
   "source": [
    "# let's try a SVM\n",
    "clf, trainTestData = genSVMclf(inputDim=600)\n",
    "evalRes = evalPrediction(clf, trainTestData)\n",
    "print('SVM success rate: {}'.format(evalRes.SuccRate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bad input shape (51231, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-ba18121ccdac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# and finally a kNN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainTestData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenKNNclf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputDim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mevalRes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevalPrediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainTestData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'kNN success rate: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevalRes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSuccRate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-167cfc0d9867>\u001b[0m in \u001b[0;36mgenKNNclf\u001b[1;34m(inputDim, evalSize)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m# carry out train/test split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevalSize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTrainTestData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/user/projekte/anaconda3/envs/ipynb/lib/python3.5/site-packages/sklearn/neighbors/nearest_centroid.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    101\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'csc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m         \u001b[0mis_X_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_X_sparse\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshrink_threshold\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/user/projekte/anaconda3/envs/ipynb/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    513\u001b[0m                         dtype=None)\n\u001b[0;32m    514\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    516\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'O'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/user/projekte/anaconda3/envs/ipynb/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, warn)\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bad input shape {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: bad input shape (51231, 2)"
     ]
    }
   ],
   "source": [
    "# and finally a kNN\n",
    "clf, trainTestData = genKNNclf(inputDim=600)\n",
    "evalRes = evalPrediction(clf, trainTestData)\n",
    "print('kNN success rate: {}'.format(evalRes.SuccRate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['tanh']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEKCAYAAAAGvn7fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJM6osIuIxBkVdhGROPP/AQjgdWndAQr/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f36bc31c978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the training progress\n",
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#train_loss = np.array([i[\"train_loss\"] for i in net.train_history_])\n",
    "#valid_loss = np.array([i[\"valid_loss\"] for i in net.train_history_])\n",
    "train_loss = results[-1].evalRes.TrainLoss\n",
    "valid_loss = results[-1].evalRes.ValidLoss\n",
    "\n",
    "marginFactor = 1.2\n",
    "train_min = min(train_loss)\n",
    "train_max = max(train_loss)\n",
    "valid_min = min(valid_loss)\n",
    "valid_max = max(valid_loss)\n",
    "y_min = min(train_min, valid_min)\n",
    "y_max = min(train_max, valid_max)\n",
    "\n",
    "plt.plot(train_loss, linewidth=3, label=\"train\")\n",
    "plt.plot(valid_loss, linewidth=3, label=\"valid\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.ylim(y_min * 1/marginFactor, y_max * marginFactor)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:start loading the model\n",
      "INFO:gensim.utils:loading Doc2Vec object from /home/user/projekte/econstorModelling/cache/allDocs100D.model\n",
      "INFO:gensim.utils:loading docvecs recursively from /home/user/projekte/econstorModelling/cache/allDocs100D.model.docvecs.* with mmap=None\n",
      "INFO:gensim.utils:loading syn0 from /home/user/projekte/econstorModelling/cache/allDocs100D.model.syn0.npy with mmap=None\n",
      "INFO:gensim.utils:loading syn1 from /home/user/projekte/econstorModelling/cache/allDocs100D.model.syn1.npy with mmap=None\n",
      "INFO:gensim.utils:setting ignored attribute syn0norm to None\n",
      "INFO:gensim.utils:setting ignored attribute cum_table to None\n",
      "INFO:root:loading completed\n",
      "INFO:root:building corpus...\n",
      "INFO:root:corpus complete\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fac3271e320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import manifold\n",
    "\n",
    "X, y = loadXy(inputDim=100, regression=False)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.1, random_state=42)\n",
    "tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
    "\n",
    "try:\n",
    "    x\n",
    "except NameError:\n",
    "    x = tsne.fit_transform(X_test)\n",
    "    \n",
    "plt.scatter(x[:, 0], x[:, 1], c=y_test, cmap=plt.cm.Spectral)\n",
    "plt.title(\"t-SNE\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# more t-sne\n",
    "from loadCorpus import loadModel, loadCorpus\n",
    "model = loadModel(dim=600)\n",
    "\n",
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import norm\n",
    "\n",
    "tsneIfo = tsneDocs[:len(ifoPresidents), :]\n",
    "tsneSamples = tsneDocs[len(ifoPresidents):, :]\n",
    "\n",
    "plt.figure(figsize=(15, 12), dpi=100)\n",
    "plt.scatter(tsneIfo[:, 0], tsneIfo[:, 1], s=250, c=ifoPresidentsColors, alpha=.8, cmap=plt.cm.Spectral)\n",
    "plt.scatter(tsneSamples[:, 0], tsneSamples[:, 1], s=50, c='black', alpha=.05, cmap=plt.cm.Spectral)\n",
    "plt.title(\"t-SNE\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
